// generated by Dendro-GR SymPyGR code gernation framework
//date: 2018-09-11 09:58:39


#include "rhs_bssn.cuh"
namespace cuda { 




/** computes rhs a_rhs*/
__global__ void __compute_a_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={8,8,8};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double K[512];
	__shared__ double alpha[512];
	__shared__ double beta2[512];
	__shared__ double beta0[512];
	__shared__ double beta1[512];
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	__shared__ double agrad_2_alpha[512];
	__shared__ double agrad_1_alpha[512];
	__shared__ double agrad_0_alpha[512];
	 // deriv vars end
	 // output vars begin
	__shared__ double a_rhs[512];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_alpha[offset]),(double *) agrad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_alpha[offset]),(double *) agrad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_alpha[offset]),(double *) agrad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 12
		      // Dendro: printing temp variables
		      // Dendro: printing variables

		      a_rhs[pp] = -2*K[pp]*alpha[pp] + lambda[0]*(beta0[pp]*agrad_0_alpha[pp] + beta1[pp]*agrad_1_alpha[pp] + beta2[pp]*agrad_2_alpha[pp]);
		      // Dendro: reduced ops: 12
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(a_rhs, &__unzipOutVar[cuda::VAR::U_ALPHA][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
/** computes rhs b_rhs*/
__global__ void __compute_b_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={5,5,5};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double alpha[125];
	__shared__ double beta2[125];
	__shared__ double B2[125];
	__shared__ double beta0[125];
	__shared__ double B1[125];
	__shared__ double beta1[125];
	__shared__ double B0[125];
	 //input vars end
	 // staged vars begin
	__shared__ double b_rhs3[125];
	__shared__ double b_rhs4[125];
	__shared__ double b_rhs5[125];
	 // staged vars end
	 // deriv vars begin
	__shared__ double agrad_1_beta1[125];
	__shared__ double agrad_1_beta2[125];
	__shared__ double kograd_1_beta0[125];
	__shared__ double kograd_0_beta2[125];
	__shared__ double kograd_2_beta2[125];
	__shared__ double kograd_2_beta1[125];
	__shared__ double kograd_1_beta1[125];
	__shared__ double agrad_0_beta1[125];
	__shared__ double agrad_2_beta0[125];
	__shared__ double kograd_0_beta1[125];
	__shared__ double kograd_1_beta2[125];
	__shared__ double kograd_2_beta0[125];
	__shared__ double agrad_1_beta0[125];
	__shared__ double agrad_0_beta0[125];
	__shared__ double agrad_0_beta2[125];
	__shared__ double agrad_2_beta1[125];
	__shared__ double agrad_2_beta2[125];
	__shared__ double kograd_0_beta0[125];
	 // deriv vars end
	 // output vars begin
	__shared__ double b_rhs1[125];
	__shared__ double b_rhs0[125];
	__shared__ double b_rhs2[125];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_B2][offset],(double *) B2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_B1][offset],(double *) B1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_B0][offset],(double *) B0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_beta1[offset]),(double *) agrad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_beta2[offset]),(double *) agrad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_1_beta0[offset]),(double *) kograd_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_0_beta2[offset]),(double *) kograd_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_2_beta2[offset]),(double *) kograd_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_2_beta1[offset]),(double *) kograd_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_1_beta1[offset]),(double *) kograd_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_beta1[offset]),(double *) agrad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_beta0[offset]),(double *) agrad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_0_beta1[offset]),(double *) kograd_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_1_beta2[offset]),(double *) kograd_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_2_beta0[offset]),(double *) kograd_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_beta0[offset]),(double *) agrad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_beta0[offset]),(double *) agrad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_beta2[offset]),(double *) agrad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_beta1[offset]),(double *) agrad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_beta2[offset]),(double *) agrad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__kograd_0_beta0[offset]),(double *) kograd_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 66
		      // Dendro: printing temp variables
		   double 		DENDRO_0 = (3.0/4.0)*alpha[pp]*lambda_f[1] + (3.0/4.0)*lambda_f[0];
		      // Dendro: printing variables

		      b_rhs0[pp] = B0[pp]*DENDRO_0 + lambda[1]*(beta0[pp]*agrad_0_beta0[pp] + beta1[pp]*agrad_1_beta0[pp] + beta2[pp]*agrad_2_beta0[pp]);
		      b_rhs1[pp] = B1[pp]*DENDRO_0 + lambda[1]*(beta0[pp]*agrad_0_beta1[pp] + beta1[pp]*agrad_1_beta1[pp] + beta2[pp]*agrad_2_beta1[pp]);
		      b_rhs2[pp] = B2[pp]*DENDRO_0 + lambda[1]*(beta0[pp]*agrad_0_beta2[pp] + beta1[pp]*agrad_1_beta2[pp] + beta2[pp]*agrad_2_beta2[pp]);
		      b_rhs3[pp] = kograd_0_beta0[pp] + kograd_1_beta0[pp] + kograd_2_beta0[pp];
		      b_rhs4[pp] = kograd_0_beta1[pp] + kograd_1_beta1[pp] + kograd_2_beta1[pp];
		      b_rhs5[pp] = kograd_0_beta2[pp] + kograd_1_beta2[pp] + kograd_2_beta2[pp];
		      // Dendro: reduced ops: 54
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(b_rhs1, &__unzipOutVar[cuda::VAR::U_BETA1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(b_rhs0, &__unzipOutVar[cuda::VAR::U_BETA0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(b_rhs2, &__unzipOutVar[cuda::VAR::U_BETA2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
/** computes rhs gt_rhs*/
__global__ void __compute_gt_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={4,4,4};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double gt2[64];
	__shared__ double gt3[64];
	__shared__ double At3[64];
	__shared__ double gt1[64];
	__shared__ double alpha[64];
	__shared__ double At0[64];
	__shared__ double beta2[64];
	__shared__ double At4[64];
	__shared__ double beta0[64];
	__shared__ double At2[64];
	__shared__ double At1[64];
	__shared__ double gt4[64];
	__shared__ double beta1[64];
	__shared__ double gt5[64];
	__shared__ double At5[64];
	__shared__ double gt0[64];
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	__shared__ double agrad_1_gt3[64];
	__shared__ double agrad_0_gt3[64];
	__shared__ double grad_1_beta2[64];
	__shared__ double agrad_1_gt1[64];
	__shared__ double agrad_1_gt5[64];
	__shared__ double grad_0_beta2[64];
	__shared__ double agrad_2_gt5[64];
	__shared__ double agrad_0_gt4[64];
	__shared__ double agrad_0_gt1[64];
	__shared__ double agrad_2_gt1[64];
	__shared__ double agrad_1_gt4[64];
	__shared__ double grad_1_beta1[64];
	__shared__ double grad_0_beta0[64];
	__shared__ double agrad_2_gt2[64];
	__shared__ double grad_1_beta0[64];
	__shared__ double grad_2_beta2[64];
	__shared__ double agrad_0_gt0[64];
	__shared__ double agrad_2_gt0[64];
	__shared__ double agrad_2_gt3[64];
	__shared__ double grad_0_beta1[64];
	__shared__ double agrad_1_gt0[64];
	__shared__ double agrad_0_gt5[64];
	__shared__ double agrad_0_gt2[64];
	__shared__ double agrad_1_gt2[64];
	__shared__ double grad_2_beta1[64];
	__shared__ double agrad_2_gt4[64];
	__shared__ double grad_2_beta0[64];
	 // deriv vars end
	 // output vars begin
	__shared__ double gt_rhs01[64];
	__shared__ double gt_rhs11[64];
	__shared__ double gt_rhs12[64];
	__shared__ double gt_rhs22[64];
	__shared__ double gt_rhs02[64];
	__shared__ double gt_rhs00[64];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_gt3[offset]),(double *) agrad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_gt3[offset]),(double *) agrad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta2[offset]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_gt1[offset]),(double *) agrad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_gt5[offset]),(double *) agrad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta2[offset]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_gt5[offset]),(double *) agrad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_gt4[offset]),(double *) agrad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_gt1[offset]),(double *) agrad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_gt1[offset]),(double *) agrad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_gt4[offset]),(double *) agrad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta1[offset]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta0[offset]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_gt2[offset]),(double *) agrad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta0[offset]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta2[offset]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_gt0[offset]),(double *) agrad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_gt0[offset]),(double *) agrad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_gt3[offset]),(double *) agrad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta1[offset]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_gt0[offset]),(double *) agrad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_gt5[offset]),(double *) agrad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_gt2[offset]),(double *) agrad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_gt2[offset]),(double *) agrad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta1[offset]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_gt4[offset]),(double *) agrad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta0[offset]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 210
		      // Dendro: printing temp variables
		   double 		DENDRO_0 = 2*alpha[pp];
		   double 		DENDRO_1 = grad_0_beta0[pp];
		   double 		DENDRO_2 = grad_1_beta1[pp];
		   double 		DENDRO_3 = (2.0/3.0)*gt0[pp];
		   double 		DENDRO_4 = grad_2_beta2[pp];
		   double 		DENDRO_5 = grad_0_beta1[pp];
		   double 		DENDRO_6 = 2*gt1[pp];
		   double 		DENDRO_7 = grad_0_beta2[pp];
		   double 		DENDRO_8 = 2*gt2[pp];
		   double 		DENDRO_9 = grad_1_beta0[pp];
		   double 		DENDRO_10 = grad_1_beta2[pp];
		   double 		DENDRO_11 = (1.0/3.0)*gt1[pp];
		   double 		DENDRO_12 = (2.0/3.0)*DENDRO_4;
		   double 		DENDRO_13 = grad_2_beta0[pp];
		   double 		DENDRO_14 = grad_2_beta1[pp];
		   double 		DENDRO_15 = (1.0/3.0)*gt2[pp];
		   double 		DENDRO_16 = (2.0/3.0)*DENDRO_2;
		   double 		DENDRO_17 = (2.0/3.0)*DENDRO_1;
		   double 		DENDRO_18 = 2*gt4[pp];
		   double 		DENDRO_19 = (1.0/3.0)*gt4[pp];
		      // Dendro: printing variables

		      gt_rhs00[pp] = -At0[pp]*DENDRO_0 + (4.0/3.0)*DENDRO_1*gt0[pp] - DENDRO_2*DENDRO_3 - DENDRO_3*DENDRO_4 + DENDRO_5*DENDRO_6 + DENDRO_7*DENDRO_8 + beta0[pp]*agrad_0_gt0[pp] + beta1[pp]*agrad_1_gt0[pp] + beta2[pp]*agrad_2_gt0[pp];
		      gt_rhs01[pp] = -At1[pp]*DENDRO_0 + DENDRO_1*DENDRO_11 + DENDRO_10*gt2[pp] + DENDRO_11*DENDRO_2 - DENDRO_12*gt1[pp] + DENDRO_5*gt3[pp] + DENDRO_7*gt4[pp] + DENDRO_9*gt0[pp] + beta0[pp]*agrad_0_gt1[pp] + beta1[pp]*agrad_1_gt1[pp] + beta2[pp]*agrad_2_gt1[pp];
		      gt_rhs02[pp] = -At2[pp]*DENDRO_0 + DENDRO_1*DENDRO_15 + DENDRO_13*gt0[pp] + DENDRO_14*gt1[pp] + DENDRO_15*DENDRO_4 - DENDRO_16*gt2[pp] + DENDRO_5*gt4[pp] + DENDRO_7*gt5[pp] + beta0[pp]*agrad_0_gt2[pp] + beta1[pp]*agrad_1_gt2[pp] + beta2[pp]*agrad_2_gt2[pp];
		      gt_rhs11[pp] = -At3[pp]*DENDRO_0 + DENDRO_10*DENDRO_18 - DENDRO_12*gt3[pp] - DENDRO_17*gt3[pp] + (4.0/3.0)*DENDRO_2*gt3[pp] + DENDRO_6*DENDRO_9 + beta0[pp]*agrad_0_gt3[pp] + beta1[pp]*agrad_1_gt3[pp] + beta2[pp]*agrad_2_gt3[pp];
		      gt_rhs12[pp] = -At4[pp]*DENDRO_0 + DENDRO_10*gt5[pp] + DENDRO_13*gt1[pp] + DENDRO_14*gt3[pp] - DENDRO_17*gt4[pp] + DENDRO_19*DENDRO_2 + DENDRO_19*DENDRO_4 + DENDRO_9*gt2[pp] + beta0[pp]*agrad_0_gt4[pp] + beta1[pp]*agrad_1_gt4[pp] + beta2[pp]*agrad_2_gt4[pp];
		      gt_rhs22[pp] = -At5[pp]*DENDRO_0 + DENDRO_13*DENDRO_8 + DENDRO_14*DENDRO_18 - DENDRO_16*gt5[pp] - DENDRO_17*gt5[pp] + (4.0/3.0)*DENDRO_4*gt5[pp] + beta0[pp]*agrad_0_gt5[pp] + beta1[pp]*agrad_1_gt5[pp] + beta2[pp]*agrad_2_gt5[pp];
		      // Dendro: reduced ops: 162
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(gt_rhs01, &__unzipOutVar[cuda::VAR::U_SYMGT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(gt_rhs11, &__unzipOutVar[cuda::VAR::U_SYMGT3][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(gt_rhs12, &__unzipOutVar[cuda::VAR::U_SYMGT4][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(gt_rhs22, &__unzipOutVar[cuda::VAR::U_SYMGT5][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(gt_rhs02, &__unzipOutVar[cuda::VAR::U_SYMGT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(gt_rhs00, &__unzipOutVar[cuda::VAR::U_SYMGT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
/** computes rhs chi_rhs*/
__global__ void __compute_chi_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={7,7,7};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double K[343];
	__shared__ double chi[343];
	__shared__ double alpha[343];
	__shared__ double beta2[343];
	__shared__ double beta0[343];
	__shared__ double beta1[343];
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	__shared__ double grad_1_beta1[343];
	__shared__ double agrad_0_chi[343];
	__shared__ double grad_0_beta0[343];
	__shared__ double agrad_1_chi[343];
	__shared__ double agrad_2_chi[343];
	__shared__ double grad_2_beta2[343];
	 // deriv vars end
	 // output vars begin
	__shared__ double chi_rhs[343];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta1[offset]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_chi[offset]),(double *) agrad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta0[offset]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_chi[offset]),(double *) agrad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_chi[offset]),(double *) agrad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta2[offset]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 22
		      // Dendro: printing temp variables
		   double 		DENDRO_0 = (2.0/3.0)*chi[pp];
		      // Dendro: printing variables

		      chi_rhs[pp] = DENDRO_0*K[pp]*alpha[pp] - DENDRO_0*(grad_0_beta0[pp] + grad_1_beta1[pp] + grad_2_beta2[pp]) + beta0[pp]*agrad_0_chi[pp] + beta1[pp]*agrad_1_chi[pp] + beta2[pp]*agrad_2_chi[pp];
		      // Dendro: reduced ops: 20
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(chi_rhs, &__unzipOutVar[cuda::VAR::U_CHI][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
/** computes rhs At_rhs*/
__global__ void __compute_At_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={3,3,3};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double K[27];
	__shared__ double gt3[27];
	__shared__ double gt2[27];
	__shared__ double chi[27];
	__shared__ double gt1[27];
	__shared__ double alpha[27];
	__shared__ double At0[27];
	__shared__ double beta2[27];
	__shared__ double At3[27];
	__shared__ double At4[27];
	__shared__ double At2[27];
	__shared__ double beta0[27];
	__shared__ double At1[27];
	__shared__ double gt4[27];
	__shared__ double beta1[27];
	__shared__ double gt5[27];
	__shared__ double At5[27];
	__shared__ double gt0[27];
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	__shared__ double grad_2_Gt2[27];
	__shared__ double grad_1_beta2[27];
	__shared__ double grad2_0_2_gt3[27];
	__shared__ double agrad_1_At1[27];
	__shared__ double grad2_0_1_alpha[27];
	__shared__ double grad_2_gt2[27];
	__shared__ double grad2_2_2_gt1[27];
	__shared__ double grad2_0_1_gt4[27];
	__shared__ double grad_0_gt1[27];
	__shared__ double grad2_1_1_gt1[27];
	__shared__ double grad_0_gt0[27];
	__shared__ double grad2_1_2_gt3[27];
	__shared__ double grad2_1_2_chi[27];
	__shared__ double grad_1_gt1[27];
	__shared__ double grad_1_Gt2[27];
	__shared__ double grad2_0_2_gt0[27];
	__shared__ double grad_0_Gt0[27];
	__shared__ double grad2_0_2_gt2[27];
	__shared__ double agrad_0_At1[27];
	__shared__ double grad_2_beta0[27];
	__shared__ double grad2_0_0_gt5[27];
	__shared__ double grad2_1_2_gt2[27];
	__shared__ double agrad_1_At5[27];
	__shared__ double grad2_2_2_gt2[27];
	__shared__ double agrad_1_At3[27];
	__shared__ double grad_1_gt2[27];
	__shared__ double grad2_2_2_gt4[27];
	__shared__ double grad2_0_1_gt0[27];
	__shared__ double grad_1_gt3[27];
	__shared__ double agrad_2_At0[27];
	__shared__ double agrad_1_At0[27];
	__shared__ double agrad_0_At2[27];
	__shared__ double grad_2_gt4[27];
	__shared__ double grad2_0_0_gt2[27];
	__shared__ double agrad_2_At1[27];
	__shared__ double grad2_0_1_gt1[27];
	__shared__ double grad_2_gt3[27];
	__shared__ double grad_0_beta0[27];
	__shared__ double grad2_1_1_gt2[27];
	__shared__ double grad_1_gt4[27];
	__shared__ double grad2_0_1_gt2[27];
	__shared__ double grad_1_Gt1[27];
	__shared__ double grad2_2_2_chi[27];
	__shared__ double grad2_1_1_gt0[27];
	__shared__ double agrad_0_At5[27];
	__shared__ double grad_0_beta1[27];
	__shared__ double grad2_1_1_chi[27];
	__shared__ double grad2_1_2_gt5[27];
	__shared__ double grad2_0_0_gt1[27];
	__shared__ double grad2_1_1_gt5[27];
	__shared__ double grad2_1_2_gt1[27];
	__shared__ double grad2_0_0_gt3[27];
	__shared__ double grad2_2_2_gt0[27];
	__shared__ double grad2_2_2_alpha[27];
	__shared__ double grad2_2_2_gt3[27];
	__shared__ double agrad_2_At5[27];
	__shared__ double grad_2_gt0[27];
	__shared__ double grad_0_gt2[27];
	__shared__ double grad2_0_1_gt5[27];
	__shared__ double grad2_0_1_gt3[27];
	__shared__ double agrad_2_At3[27];
	__shared__ double grad_1_alpha[27];
	__shared__ double grad_1_gt0[27];
	__shared__ double grad2_0_1_chi[27];
	__shared__ double grad2_1_1_gt4[27];
	__shared__ double grad_1_beta1[27];
	__shared__ double grad2_1_1_gt3[27];
	__shared__ double grad_2_beta2[27];
	__shared__ double grad_2_alpha[27];
	__shared__ double grad2_1_2_gt4[27];
	__shared__ double grad_2_Gt1[27];
	__shared__ double grad2_1_2_alpha[27];
	__shared__ double grad_2_Gt0[27];
	__shared__ double grad_2_gt5[27];
	__shared__ double grad2_0_0_gt4[27];
	__shared__ double agrad_1_At2[27];
	__shared__ double grad_2_beta1[27];
	__shared__ double grad2_0_2_gt4[27];
	__shared__ double grad2_0_2_gt1[27];
	__shared__ double grad2_0_2_gt5[27];
	__shared__ double grad_0_alpha[27];
	__shared__ double grad_1_Gt0[27];
	__shared__ double grad2_0_0_gt0[27];
	__shared__ double agrad_2_At4[27];
	__shared__ double grad2_0_2_chi[27];
	__shared__ double grad_0_gt4[27];
	__shared__ double grad2_2_2_gt5[27];
	__shared__ double grad2_0_0_alpha[27];
	__shared__ double agrad_0_At0[27];
	__shared__ double agrad_2_At2[27];
	__shared__ double grad_0_Gt2[27];
	__shared__ double grad_0_gt5[27];
	__shared__ double grad_0_beta2[27];
	__shared__ double grad2_1_1_alpha[27];
	__shared__ double grad2_0_2_alpha[27];
	__shared__ double agrad_0_At3[27];
	__shared__ double grad_1_beta0[27];
	__shared__ double grad_1_gt5[27];
	__shared__ double grad_2_gt1[27];
	__shared__ double grad2_0_0_chi[27];
	__shared__ double grad_0_Gt1[27];
	__shared__ double grad_2_chi[27];
	__shared__ double grad_0_chi[27];
	__shared__ double agrad_0_At4[27];
	__shared__ double grad_1_chi[27];
	__shared__ double grad2_1_2_gt0[27];
	__shared__ double agrad_1_At4[27];
	__shared__ double grad_0_gt3[27];
	 // deriv vars end
	 // output vars begin
	__shared__ double At_rhs11[27];
	__shared__ double At_rhs00[27];
	__shared__ double At_rhs01[27];
	__shared__ double At_rhs02[27];
	__shared__ double At_rhs12[27];
	__shared__ double At_rhs22[27];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_Gt2[offset]),(double *) grad_2_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta2[offset]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_gt3[offset]),(double *) grad2_0_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_At1[offset]),(double *) agrad_1_At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_alpha[offset]),(double *) grad2_0_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt2[offset]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_gt1[offset]),(double *) grad2_2_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_gt4[offset]),(double *) grad2_0_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt1[offset]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_gt1[offset]),(double *) grad2_1_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt0[offset]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_gt3[offset]),(double *) grad2_1_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_chi[offset]),(double *) grad2_1_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt1[offset]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_Gt2[offset]),(double *) grad_1_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_gt0[offset]),(double *) grad2_0_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_Gt0[offset]),(double *) grad_0_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_gt2[offset]),(double *) grad2_0_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_At1[offset]),(double *) agrad_0_At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta0[offset]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_gt5[offset]),(double *) grad2_0_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_gt2[offset]),(double *) grad2_1_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_At5[offset]),(double *) agrad_1_At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_gt2[offset]),(double *) grad2_2_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_At3[offset]),(double *) agrad_1_At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt2[offset]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_gt4[offset]),(double *) grad2_2_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_gt0[offset]),(double *) grad2_0_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt3[offset]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_At0[offset]),(double *) agrad_2_At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_At0[offset]),(double *) agrad_1_At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_At2[offset]),(double *) agrad_0_At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt4[offset]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_gt2[offset]),(double *) grad2_0_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_At1[offset]),(double *) agrad_2_At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_gt1[offset]),(double *) grad2_0_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt3[offset]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta0[offset]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_gt2[offset]),(double *) grad2_1_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt4[offset]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_gt2[offset]),(double *) grad2_0_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_Gt1[offset]),(double *) grad_1_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_chi[offset]),(double *) grad2_2_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_gt0[offset]),(double *) grad2_1_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_At5[offset]),(double *) agrad_0_At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta1[offset]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_chi[offset]),(double *) grad2_1_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_gt5[offset]),(double *) grad2_1_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_gt1[offset]),(double *) grad2_0_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_gt5[offset]),(double *) grad2_1_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_gt1[offset]),(double *) grad2_1_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_gt3[offset]),(double *) grad2_0_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_gt0[offset]),(double *) grad2_2_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_alpha[offset]),(double *) grad2_2_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_gt3[offset]),(double *) grad2_2_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_At5[offset]),(double *) agrad_2_At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt0[offset]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt2[offset]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_gt5[offset]),(double *) grad2_0_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_gt3[offset]),(double *) grad2_0_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_At3[offset]),(double *) agrad_2_At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_alpha[offset]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt0[offset]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_chi[offset]),(double *) grad2_0_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_gt4[offset]),(double *) grad2_1_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta1[offset]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_gt3[offset]),(double *) grad2_1_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta2[offset]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_alpha[offset]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_gt4[offset]),(double *) grad2_1_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_Gt1[offset]),(double *) grad_2_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_alpha[offset]),(double *) grad2_1_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_Gt0[offset]),(double *) grad_2_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt5[offset]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_gt4[offset]),(double *) grad2_0_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_At2[offset]),(double *) agrad_1_At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta1[offset]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_gt4[offset]),(double *) grad2_0_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_gt1[offset]),(double *) grad2_0_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_gt5[offset]),(double *) grad2_0_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_alpha[offset]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_Gt0[offset]),(double *) grad_1_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_gt0[offset]),(double *) grad2_0_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_At4[offset]),(double *) agrad_2_At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_chi[offset]),(double *) grad2_0_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt4[offset]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_gt5[offset]),(double *) grad2_2_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_alpha[offset]),(double *) grad2_0_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_At0[offset]),(double *) agrad_0_At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_At2[offset]),(double *) agrad_2_At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_Gt2[offset]),(double *) grad_0_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt5[offset]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta2[offset]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_alpha[offset]),(double *) grad2_1_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_alpha[offset]),(double *) grad2_0_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_At3[offset]),(double *) agrad_0_At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta0[offset]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt5[offset]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt1[offset]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_chi[offset]),(double *) grad2_0_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_Gt1[offset]),(double *) grad_0_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_chi[offset]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_chi[offset]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_At4[offset]),(double *) agrad_0_At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_chi[offset]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_gt0[offset]),(double *) grad2_1_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_At4[offset]),(double *) agrad_1_At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt3[offset]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 630012
		      // Dendro: printing temp variables
		   double 		DENDRO_0 = grad_0_beta0[pp];
		   double 		DENDRO_1 = grad_1_beta1[pp];
		   double 		DENDRO_2 = (2.0/3.0)*At0[pp];
		   double 		DENDRO_3 = grad_2_beta2[pp];
		   double 		DENDRO_4 = grad_0_beta1[pp];
		   double 		DENDRO_5 = 2*At1[pp];
		   double 		DENDRO_6 = grad_0_beta2[pp];
		   double 		DENDRO_7 = 2*At2[pp];
		   double 		DENDRO_8 = gt2[pp]*gt4[pp];
		   double 		DENDRO_9 = -DENDRO_8 + gt1[pp]*gt5[pp];
		   double 		DENDRO_10 = gt0[pp]*gt4[pp] - gt1[pp]*gt2[pp];
		   double 		DENDRO_11 = gt0[pp]*gt5[pp];
		   double 		DENDRO_12 = pow(gt2[pp], 2);
		   double 		DENDRO_13 = DENDRO_11 - DENDRO_12;
		   double 		DENDRO_14 = pow(gt4[pp], 2);
		   double 		DENDRO_15 = pow(gt1[pp], 2);
		   double 		DENDRO_16 = gt3[pp]*gt5[pp];
		   double 		DENDRO_17 = DENDRO_12*gt3[pp] + DENDRO_14*gt0[pp] + DENDRO_15*gt5[pp] - DENDRO_16*gt0[pp] - 2*DENDRO_8*gt1[pp];
		   double 		DENDRO_18 = 1.0/DENDRO_17;
		   double 		DENDRO_19 = DENDRO_18*DENDRO_5;
		   double 		DENDRO_20 = At1[pp]*DENDRO_9;
		   double 		DENDRO_21 = gt1[pp]*gt4[pp];
		   double 		DENDRO_22 = gt2[pp]*gt3[pp];
		   double 		DENDRO_23 = DENDRO_21 - DENDRO_22;
		   double 		DENDRO_24 = -At2[pp]*DENDRO_23;
		   double 		DENDRO_25 = -DENDRO_14 + DENDRO_16;
		   double 		DENDRO_26 = 2*DENDRO_18;
		   double 		DENDRO_27 = At0[pp]*DENDRO_26;
		   double 		DENDRO_28 = gt0[pp]*gt3[pp];
		   double 		DENDRO_29 = -DENDRO_15 + DENDRO_28;
		   double 		DENDRO_30 = DENDRO_18*DENDRO_7;
		   double 		DENDRO_31 = grad2_0_0_alpha[pp];
		   double 		DENDRO_32 = 1.0/chi[pp];
		   double 		DENDRO_33 = grad_1_chi[pp];
		   double 		DENDRO_34 = grad_2_chi[pp];
		   double 		DENDRO_35 = grad_0_chi[pp];
		   double 		DENDRO_36 = DENDRO_10*DENDRO_34 + DENDRO_35*DENDRO_9;
		   double 		DENDRO_37 = -DENDRO_13*DENDRO_33 + DENDRO_36;
		   double 		DENDRO_38 = DENDRO_32*DENDRO_37;
		   double 		DENDRO_39 = 0.5*gt0[pp];
		   double 		DENDRO_40 = grad_0_gt1[pp];
		   double 		DENDRO_41 = 1.0*DENDRO_40;
		   double 		DENDRO_42 = grad_1_gt0[pp];
		   double 		DENDRO_43 = 0.5*DENDRO_42;
		   double 		DENDRO_44 = DENDRO_41 - DENDRO_43;
		   double 		DENDRO_45 = grad_0_gt2[pp];
		   double 		DENDRO_46 = 1.0*DENDRO_45;
		   double 		DENDRO_47 = grad_2_gt0[pp];
		   double 		DENDRO_48 = 0.5*DENDRO_47;
		   double 		DENDRO_49 = DENDRO_46 - DENDRO_48;
		   double 		DENDRO_50 = grad_0_gt0[pp];
		   double 		DENDRO_51 = 0.5*DENDRO_50;
		   double 		DENDRO_52 = DENDRO_10*DENDRO_49 + DENDRO_51*DENDRO_9;
		   double 		DENDRO_53 = -DENDRO_13*DENDRO_44 + DENDRO_52;
		   double 		DENDRO_54 = DENDRO_38*DENDRO_39 + DENDRO_53;
		   double 		DENDRO_55 = grad_1_alpha[pp];
		   double 		DENDRO_56 = 12*DENDRO_55;
		   double 		DENDRO_57 = DENDRO_18*DENDRO_56;
		   double 		DENDRO_58 = DENDRO_10*DENDRO_33;
		   double 		DENDRO_59 = DENDRO_23*DENDRO_35;
		   double 		DENDRO_60 = DENDRO_29*DENDRO_34;
		   double 		DENDRO_61 = DENDRO_32*(DENDRO_58 - DENDRO_59 - DENDRO_60);
		   double 		DENDRO_62 = DENDRO_39*DENDRO_61;
		   double 		DENDRO_63 = DENDRO_23*DENDRO_51;
		   double 		DENDRO_64 = DENDRO_29*DENDRO_49;
		   double 		DENDRO_65 = DENDRO_10*DENDRO_44;
		   double 		DENDRO_66 = DENDRO_63 + DENDRO_64 - DENDRO_65;
		   double 		DENDRO_67 = grad_2_alpha[pp];
		   double 		DENDRO_68 = 12*DENDRO_67;
		   double 		DENDRO_69 = DENDRO_18*DENDRO_68;
		   double 		DENDRO_70 = DENDRO_25*DENDRO_51;
		   double 		DENDRO_71 = DENDRO_18*DENDRO_70;
		   double 		DENDRO_72 = DENDRO_23*DENDRO_49;
		   double 		DENDRO_73 = DENDRO_18*DENDRO_72;
		   double 		DENDRO_74 = DENDRO_44*DENDRO_9;
		   double 		DENDRO_75 = DENDRO_18*DENDRO_74;
		   double 		DENDRO_76 = -DENDRO_21 + DENDRO_22;
		   double 		DENDRO_77 = DENDRO_33*DENDRO_9;
		   double 		DENDRO_78 = DENDRO_14 - DENDRO_16;
		   double 		DENDRO_79 = DENDRO_34*DENDRO_76 + DENDRO_35*DENDRO_78 + DENDRO_77;
		   double 		DENDRO_80 = DENDRO_18*gt0[pp];
		   double 		DENDRO_81 = DENDRO_32*(-1.0*DENDRO_35 + 0.5*DENDRO_79*DENDRO_80);
		   double 		DENDRO_82 = grad_0_alpha[pp];
		   double 		DENDRO_83 = 12*DENDRO_82;
		   double 		DENDRO_84 = grad2_0_0_chi[pp];
		   double 		DENDRO_85 = -DENDRO_84;
		   double 		DENDRO_86 = -DENDRO_63 - DENDRO_64 + DENDRO_65;
		   double 		DENDRO_87 = DENDRO_18*DENDRO_34;
		   double 		DENDRO_88 = DENDRO_18*DENDRO_33;
		   double 		DENDRO_89 = -DENDRO_70 - DENDRO_72 + DENDRO_74;
		   double 		DENDRO_90 = DENDRO_18*DENDRO_35;
		   double 		DENDRO_91 = 2*DENDRO_32;
		   double 		DENDRO_92 = grad_0_gt3[pp];
		   double 		DENDRO_93 = 0.5*DENDRO_92;
		   double 		DENDRO_94 = grad_1_gt1[pp];
		   double 		DENDRO_95 = 1.0*DENDRO_94;
		   double 		DENDRO_96 = -DENDRO_95;
		   double 		DENDRO_97 = DENDRO_93 + DENDRO_96;
		   double 		DENDRO_98 = grad_0_gt4[pp];
		   double 		DENDRO_99 = grad_2_gt1[pp];
		   double 		DENDRO_100 = grad_1_gt2[pp];
		   double 		DENDRO_101 = -DENDRO_100 + DENDRO_98 + DENDRO_99;
		   double 		DENDRO_102 = grad_0_gt5[pp];
		   double 		DENDRO_103 = DENDRO_10*DENDRO_102 + DENDRO_47*DENDRO_9;
		   double 		DENDRO_104 = -DENDRO_101*DENDRO_13 + DENDRO_103;
		   double 		DENDRO_105 = DENDRO_104*DENDRO_97;
		   double 		DENDRO_106 = DENDRO_13*DENDRO_92;
		   double 		DENDRO_107 = DENDRO_100 + DENDRO_98 - DENDRO_99;
		   double 		DENDRO_108 = DENDRO_10*DENDRO_107;
		   double 		DENDRO_109 = DENDRO_42*DENDRO_9;
		   double 		DENDRO_110 = DENDRO_108 + DENDRO_109;
		   double 		DENDRO_111 = -DENDRO_106 + DENDRO_110;
		   double 		DENDRO_112 = DENDRO_101*DENDRO_111;
		   double 		DENDRO_113 = 0.25*DENDRO_112;
		   double 		DENDRO_114 = pow(DENDRO_17, -2);
		   double 		DENDRO_115 = DENDRO_10*DENDRO_114;
		   double 		DENDRO_116 = 4*DENDRO_115;
		   double 		DENDRO_117 = 0.5*DENDRO_102;
		   double 		DENDRO_118 = grad_2_gt2[pp];
		   double 		DENDRO_119 = 1.0*DENDRO_118;
		   double 		DENDRO_120 = -DENDRO_119;
		   double 		DENDRO_121 = DENDRO_117 + DENDRO_120;
		   double 		DENDRO_122 = DENDRO_10*DENDRO_92;
		   double 		DENDRO_123 = DENDRO_23*DENDRO_42;
		   double 		DENDRO_124 = DENDRO_107*DENDRO_29;
		   double 		DENDRO_125 = DENDRO_122 - DENDRO_123 - DENDRO_124;
		   double 		DENDRO_126 = DENDRO_121*DENDRO_125;
		   double 		DENDRO_127 = DENDRO_23*DENDRO_47;
		   double 		DENDRO_128 = DENDRO_102*DENDRO_29;
		   double 		DENDRO_129 = DENDRO_10*DENDRO_101;
		   double 		DENDRO_130 = -DENDRO_127 - DENDRO_128 + DENDRO_129;
		   double 		DENDRO_131 = DENDRO_107*DENDRO_130;
		   double 		DENDRO_132 = 0.25*DENDRO_131;
		   double 		DENDRO_133 = -DENDRO_132;
		   double 		DENDRO_134 = -DENDRO_122 + DENDRO_123 + DENDRO_124;
		   double 		DENDRO_135 = 0.25*DENDRO_102;
		   double 		DENDRO_136 = DENDRO_134*DENDRO_135;
		   double 		DENDRO_137 = DENDRO_100 - DENDRO_98 + DENDRO_99;
		   double 		DENDRO_138 = DENDRO_127 + DENDRO_128 - DENDRO_129;
		   double 		DENDRO_139 = 0.5*DENDRO_138;
		   double 		DENDRO_140 = DENDRO_9*DENDRO_92;
		   double 		DENDRO_141 = DENDRO_25*DENDRO_42;
		   double 		DENDRO_142 = DENDRO_107*DENDRO_23;
		   double 		DENDRO_143 = -DENDRO_140 + DENDRO_141 + DENDRO_142;
		   double 		DENDRO_144 = 0.25*DENDRO_47;
		   double 		DENDRO_145 = DENDRO_143*DENDRO_144;
		   double 		DENDRO_146 = DENDRO_102*DENDRO_23;
		   double 		DENDRO_147 = DENDRO_25*DENDRO_47;
		   double 		DENDRO_148 = DENDRO_101*DENDRO_9;
		   double 		DENDRO_149 = DENDRO_146 + DENDRO_147 - DENDRO_148;
		   double 		DENDRO_150 = 0.25*DENDRO_42;
		   double 		DENDRO_151 = DENDRO_149*DENDRO_150;
		   double 		DENDRO_152 = 2*DENDRO_121;
		   double 		DENDRO_153 = DENDRO_114*DENDRO_23;
		   double 		DENDRO_154 = 4*DENDRO_153;
		   double 		DENDRO_155 = DENDRO_143*DENDRO_50;
		   double 		DENDRO_156 = 0.25*DENDRO_155;
		   double 		DENDRO_157 = DENDRO_70 + DENDRO_72 - DENDRO_74;
		   double 		DENDRO_158 = DENDRO_157*DENDRO_42;
		   double 		DENDRO_159 = DENDRO_114*DENDRO_9;
		   double 		DENDRO_160 = 4*DENDRO_159;
		   double 		DENDRO_161 = 0.5*DENDRO_49;
		   double 		DENDRO_162 = DENDRO_149*DENDRO_50;
		   double 		DENDRO_163 = 0.25*DENDRO_162;
		   double 		DENDRO_164 = DENDRO_157*DENDRO_47;
		   double 		DENDRO_165 = DENDRO_138*DENDRO_47;
		   double 		DENDRO_166 = DENDRO_102*DENDRO_66;
		   double 		DENDRO_167 = 2.0*DENDRO_153;
		   double 		DENDRO_168 = DENDRO_134*DENDRO_47;
		   double 		DENDRO_169 = DENDRO_107*DENDRO_66;
		   double 		DENDRO_170 = 2.0*DENDRO_159;
		   double 		DENDRO_171 = DENDRO_104*DENDRO_23;
		   double 		DENDRO_172 = grad_2_gt3[pp];
		   double 		DENDRO_173 = DENDRO_13*DENDRO_172;
		   double 		DENDRO_174 = grad_1_gt5[pp];
		   double 		DENDRO_175 = DENDRO_10*DENDRO_174;
		   double 		DENDRO_176 = DENDRO_137*DENDRO_9;
		   double 		DENDRO_177 = DENDRO_175 + DENDRO_176;
		   double 		DENDRO_178 = -DENDRO_173 + DENDRO_177;
		   double 		DENDRO_179 = DENDRO_10*DENDRO_178;
		   double 		DENDRO_180 = DENDRO_111*DENDRO_9;
		   double 		DENDRO_181 = grad_2_gt5[pp];
		   double 		DENDRO_182 = 0.5*DENDRO_181;
		   double 		DENDRO_183 = DENDRO_10*DENDRO_182;
		   double 		DENDRO_184 = 0.5*DENDRO_174;
		   double 		DENDRO_185 = grad_2_gt4[pp];
		   double 		DENDRO_186 = 1.0*DENDRO_185;
		   double 		DENDRO_187 = -DENDRO_186;
		   double 		DENDRO_188 = DENDRO_184 + DENDRO_187;
		   double 		DENDRO_189 = -DENDRO_121*DENDRO_9 + DENDRO_13*DENDRO_188 + DENDRO_183;
		   double 		DENDRO_190 = DENDRO_189*DENDRO_29;
		   double 		DENDRO_191 = grad_1_gt3[pp];
		   double 		DENDRO_192 = 0.5*DENDRO_191;
		   double 		DENDRO_193 = DENDRO_13*DENDRO_192;
		   double 		DENDRO_194 = grad_1_gt4[pp];
		   double 		DENDRO_195 = 1.0*DENDRO_194;
		   double 		DENDRO_196 = 0.5*DENDRO_172;
		   double 		DENDRO_197 = DENDRO_195 - DENDRO_196;
		   double 		DENDRO_198 = DENDRO_10*DENDRO_197;
		   double 		DENDRO_199 = DENDRO_9*DENDRO_97;
		   double 		DENDRO_200 = -DENDRO_193 + DENDRO_198 - DENDRO_199;
		   double 		DENDRO_201 = DENDRO_13*DENDRO_200;
		   double 		DENDRO_202 = DENDRO_25*DENDRO_53;
		   double 		DENDRO_203 = DENDRO_171 - 1.0*DENDRO_179 - 1.0*DENDRO_180 + DENDRO_190 + DENDRO_201 + DENDRO_202;
		   double 		DENDRO_204 = 2.0*DENDRO_114;
		   double 		DENDRO_205 = DENDRO_204*DENDRO_42;
		   double 		DENDRO_206 = -DENDRO_146 - DENDRO_147 + DENDRO_148;
		   double 		DENDRO_207 = DENDRO_206*DENDRO_23;
		   double 		DENDRO_208 = DENDRO_172*DENDRO_9;
		   double 		DENDRO_209 = DENDRO_174*DENDRO_23;
		   double 		DENDRO_210 = DENDRO_137*DENDRO_25;
		   double 		DENDRO_211 = DENDRO_208 - DENDRO_209 - DENDRO_210;
		   double 		DENDRO_212 = DENDRO_10*DENDRO_211;
		   double 		DENDRO_213 = DENDRO_140 - DENDRO_141 - DENDRO_142;
		   double 		DENDRO_214 = DENDRO_213*DENDRO_9;
		   double 		DENDRO_215 = DENDRO_182*DENDRO_23;
		   double 		DENDRO_216 = DENDRO_188*DENDRO_9;
		   double 		DENDRO_217 = DENDRO_121*DENDRO_25;
		   double 		DENDRO_218 = -DENDRO_215 - DENDRO_216 + DENDRO_217;
		   double 		DENDRO_219 = DENDRO_218*DENDRO_29;
		   double 		DENDRO_220 = DENDRO_192*DENDRO_9;
		   double 		DENDRO_221 = -DENDRO_197*DENDRO_23 + DENDRO_220 + DENDRO_25*DENDRO_97;
		   double 		DENDRO_222 = DENDRO_13*DENDRO_221;
		   double 		DENDRO_223 = DENDRO_25*DENDRO_89;
		   double 		DENDRO_224 = DENDRO_207 - 1.0*DENDRO_212 - 1.0*DENDRO_214 + DENDRO_219 + DENDRO_222 + DENDRO_223;
		   double 		DENDRO_225 = DENDRO_204*DENDRO_50;
		   double 		DENDRO_226 = DENDRO_130*DENDRO_23;
		   double 		DENDRO_227 = DENDRO_10*DENDRO_172;
		   double 		DENDRO_228 = DENDRO_174*DENDRO_29;
		   double 		DENDRO_229 = DENDRO_137*DENDRO_23;
		   double 		DENDRO_230 = DENDRO_227 - DENDRO_228 - DENDRO_229;
		   double 		DENDRO_231 = DENDRO_10*DENDRO_230;
		   double 		DENDRO_232 = DENDRO_125*DENDRO_9;
		   double 		DENDRO_233 = DENDRO_182*DENDRO_29;
		   double 		DENDRO_234 = DENDRO_121*DENDRO_23;
		   double 		DENDRO_235 = DENDRO_10*DENDRO_188;
		   double 		DENDRO_236 = -DENDRO_233 + DENDRO_234 - DENDRO_235;
		   double 		DENDRO_237 = DENDRO_236*DENDRO_29;
		   double 		DENDRO_238 = DENDRO_10*DENDRO_192;
		   double 		DENDRO_239 = -DENDRO_197*DENDRO_29 + DENDRO_23*DENDRO_97 + DENDRO_238;
		   double 		DENDRO_240 = DENDRO_13*DENDRO_239;
		   double 		DENDRO_241 = DENDRO_25*DENDRO_86;
		   double 		DENDRO_242 = DENDRO_226 - 1.0*DENDRO_231 - 1.0*DENDRO_232 + DENDRO_237 + DENDRO_240 + DENDRO_241;
		   double 		DENDRO_243 = DENDRO_204*DENDRO_47;
		   double 		DENDRO_244 = grad2_2_2_chi[pp];
		   double 		DENDRO_245 = pow(DENDRO_34, 2);
		   double 		DENDRO_246 = 3*DENDRO_32;
		   double 		DENDRO_247 = DENDRO_29*(2*DENDRO_244 - DENDRO_245*DENDRO_246);
		   double 		DENDRO_248 = grad2_1_1_chi[pp];
		   double 		DENDRO_249 = pow(DENDRO_33, 2);
		   double 		DENDRO_250 = DENDRO_13*(-DENDRO_246*DENDRO_249 + 2*DENDRO_248);
		   double 		DENDRO_251 = pow(DENDRO_35, 2);
		   double 		DENDRO_252 = DENDRO_25*(-DENDRO_246*DENDRO_251 + 2*DENDRO_84);
		   double 		DENDRO_253 = grad2_1_2_chi[pp];
		   double 		DENDRO_254 = DENDRO_246*DENDRO_34;
		   double 		DENDRO_255 = 2*DENDRO_10*(2*DENDRO_253 - DENDRO_254*DENDRO_33);
		   double 		DENDRO_256 = grad2_0_2_chi[pp];
		   double 		DENDRO_257 = 2*DENDRO_23*(-DENDRO_254*DENDRO_35 + 2*DENDRO_256);
		   double 		DENDRO_258 = grad2_0_1_chi[pp];
		   double 		DENDRO_259 = DENDRO_33*DENDRO_35;
		   double 		DENDRO_260 = 2*DENDRO_9*(-DENDRO_246*DENDRO_259 + 2*DENDRO_258);
		   double 		DENDRO_261 = -1.0*DENDRO_171 + DENDRO_179 + DENDRO_180 - DENDRO_190 - DENDRO_201 - DENDRO_202;
		   double 		DENDRO_262 = 2*DENDRO_261*DENDRO_88;
		   double 		DENDRO_263 = -1.0*DENDRO_226 + DENDRO_231 + DENDRO_232 - DENDRO_237 - DENDRO_240 - DENDRO_241;
		   double 		DENDRO_264 = 2*DENDRO_263*DENDRO_87;
		   double 		DENDRO_265 = -1.0*DENDRO_207 + DENDRO_212 + DENDRO_214 - DENDRO_219 - DENDRO_222 - DENDRO_223;
		   double 		DENDRO_266 = 2*DENDRO_265*DENDRO_90;
		   double 		DENDRO_267 = DENDRO_247 + DENDRO_250 + DENDRO_252 - DENDRO_255 + DENDRO_257 - DENDRO_260 + DENDRO_262 + DENDRO_264 + DENDRO_266;
		   double 		DENDRO_268 = DENDRO_32*DENDRO_80;
		   double 		DENDRO_269 = DENDRO_114*DENDRO_29;
		   double 		DENDRO_270 = 4*DENDRO_269;
		   double 		DENDRO_271 = DENDRO_130*DENDRO_270;
		   double 		DENDRO_272 = 0.25*DENDRO_92;
		   double 		DENDRO_273 = DENDRO_114*DENDRO_13;
		   double 		DENDRO_274 = 4*DENDRO_273;
		   double 		DENDRO_275 = DENDRO_111*DENDRO_274;
		   double 		DENDRO_276 = 0.25*DENDRO_98;
		   double 		DENDRO_277 = -DENDRO_276;
		   double 		DENDRO_278 = 0.75*DENDRO_100;
		   double 		DENDRO_279 = 0.25*DENDRO_99;
		   double 		DENDRO_280 = DENDRO_274*(DENDRO_277 + DENDRO_278 + DENDRO_279);
		   double 		DENDRO_281 = DENDRO_46 + DENDRO_48;
		   double 		DENDRO_282 = DENDRO_114*DENDRO_25;
		   double 		DENDRO_283 = 4*DENDRO_282;
		   double 		DENDRO_284 = DENDRO_149*DENDRO_47;
		   double 		DENDRO_285 = 3.0*DENDRO_269;
		   double 		DENDRO_286 = DENDRO_143*DENDRO_42;
		   double 		DENDRO_287 = 3.0*DENDRO_273;
		   double 		DENDRO_288 = 6.0*DENDRO_50;
		   double 		DENDRO_289 = pow(chi[pp], -2);
		   double 		DENDRO_290 = grad_0_Gt0[pp];
		   double 		DENDRO_291 = grad_0_Gt1[pp];
		   double 		DENDRO_292 = 4*gt1[pp];
		   double 		DENDRO_293 = grad_0_Gt2[pp];
		   double 		DENDRO_294 = 4*gt2[pp];
		   double 		DENDRO_295 = 0.5*DENDRO_44;
		   double 		DENDRO_296 = DENDRO_104*DENDRO_295;
		   double 		DENDRO_297 = 4*DENDRO_18*DENDRO_23;
		   double 		DENDRO_298 = DENDRO_104*DENDRO_272;
		   double 		DENDRO_299 = 0.5*DENDRO_137;
		   double 		DENDRO_300 = DENDRO_111*DENDRO_295;
		   double 		DENDRO_301 = 2.0*DENDRO_18;
		   double 		DENDRO_302 = DENDRO_29*DENDRO_301;
		   double 		DENDRO_303 = DENDRO_13*DENDRO_301;
		   double 		DENDRO_304 = DENDRO_25*DENDRO_301;
		   double 		DENDRO_305 = DENDRO_111*DENDRO_42;
		   double 		DENDRO_306 = DENDRO_53*DENDRO_92;
		   double 		DENDRO_307 = DENDRO_104*DENDRO_42;
		   double 		DENDRO_308 = DENDRO_101*DENDRO_53;
		   double 		DENDRO_309 = 4.0*DENDRO_18;
		   double 		DENDRO_310 = DENDRO_10*DENDRO_309;
		   double 		DENDRO_311 = DENDRO_309*DENDRO_9;
		   double 		DENDRO_312 = 0.25*DENDRO_100;
		   double 		DENDRO_313 = 0.75*DENDRO_99;
		   double 		DENDRO_314 = 4*DENDRO_114;
		   double 		DENDRO_315 = -DENDRO_104*DENDRO_270*(DENDRO_277 + DENDRO_312 + DENDRO_313) + DENDRO_116*(DENDRO_111*DENDRO_299 + DENDRO_298) - DENDRO_154*(DENDRO_137*DENDRO_53 + DENDRO_296) + DENDRO_160*(DENDRO_300 - 2*DENDRO_53*DENDRO_97) - DENDRO_167*(DENDRO_307 + DENDRO_308) + DENDRO_170*(DENDRO_305 + DENDRO_306) - DENDRO_202*DENDRO_314*(DENDRO_41 + DENDRO_43) - DENDRO_251*DENDRO_289 + 4*DENDRO_290*gt0[pp] + DENDRO_291*DENDRO_292 + DENDRO_293*DENDRO_294 + DENDRO_297*grad2_0_2_gt0[pp] + DENDRO_302*grad2_2_2_gt0[pp] + DENDRO_303*grad2_1_1_gt0[pp] + DENDRO_304*grad2_0_0_gt0[pp] - DENDRO_310*grad2_1_2_gt0[pp] - DENDRO_311*grad2_0_1_gt0[pp];
		   double 		DENDRO_316 = 3*alpha[pp];
		   double 		DENDRO_317 = grad2_2_2_alpha[pp];
		   double 		DENDRO_318 = 0.5*gt5[pp];
		   double 		DENDRO_319 = DENDRO_189 + DENDRO_318*DENDRO_38;
		   double 		DENDRO_320 = 4*DENDRO_55;
		   double 		DENDRO_321 = DENDRO_18*DENDRO_320;
		   double 		DENDRO_322 = DENDRO_23*DENDRO_34;
		   double 		DENDRO_323 = DENDRO_25*DENDRO_35;
		   double 		DENDRO_324 = DENDRO_32*(-DENDRO_322 - DENDRO_323 + DENDRO_77);
		   double 		DENDRO_325 = DENDRO_318*DENDRO_324;
		   double 		DENDRO_326 = 4*DENDRO_82;
		   double 		DENDRO_327 = DENDRO_18*DENDRO_326;
		   double 		DENDRO_328 = DENDRO_18*DENDRO_233;
		   double 		DENDRO_329 = DENDRO_18*DENDRO_234;
		   double 		DENDRO_330 = DENDRO_18*DENDRO_235;
		   double 		DENDRO_331 = DENDRO_15 - DENDRO_28;
		   double 		DENDRO_332 = DENDRO_331*DENDRO_34 + DENDRO_35*DENDRO_76 + DENDRO_58;
		   double 		DENDRO_333 = DENDRO_18*gt5[pp];
		   double 		DENDRO_334 = DENDRO_32*(0.5*DENDRO_332*DENDRO_333 - 1.0*DENDRO_34);
		   double 		DENDRO_335 = 4*DENDRO_67;
		   double 		DENDRO_336 = -DENDRO_244;
		   double 		DENDRO_337 = -DENDRO_184;
		   double 		DENDRO_338 = DENDRO_186 + DENDRO_337;
		   double 		DENDRO_339 = -DENDRO_117;
		   double 		DENDRO_340 = DENDRO_119 + DENDRO_339;
		   double 		DENDRO_341 = -DENDRO_11 + DENDRO_12;
		   double 		DENDRO_342 = 0.5*DENDRO_188;
		   double 		DENDRO_343 = DENDRO_104*DENDRO_342;
		   double 		DENDRO_344 = -DENDRO_343;
		   double 		DENDRO_345 = DENDRO_107*DENDRO_189;
		   double 		DENDRO_346 = 0.5*DENDRO_121;
		   double 		DENDRO_347 = -DENDRO_206*DENDRO_346;
		   double 		DENDRO_348 = 2*DENDRO_49;
		   double 		DENDRO_349 = DENDRO_130*DENDRO_181;
		   double 		DENDRO_350 = 0.25*DENDRO_349;
		   double 		DENDRO_351 = DENDRO_102*DENDRO_236;
		   double 		DENDRO_352 = DENDRO_211*DENDRO_346;
		   double 		DENDRO_353 = -DENDRO_352;
		   double 		DENDRO_354 = DENDRO_107*DENDRO_218;
		   double 		DENDRO_355 = DENDRO_181*DENDRO_230;
		   double 		DENDRO_356 = 0.25*DENDRO_355;
		   double 		DENDRO_357 = DENDRO_174*DENDRO_236;
		   double 		DENDRO_358 = DENDRO_211*DENDRO_49;
		   double 		DENDRO_359 = DENDRO_137*DENDRO_206;
		   double 		DENDRO_360 = 0.25*DENDRO_359;
		   double 		DENDRO_361 = 0.25*DENDRO_174;
		   double 		DENDRO_362 = DENDRO_130*DENDRO_361;
		   double 		DENDRO_363 = DENDRO_135*DENDRO_230;
		   double 		DENDRO_364 = DENDRO_144*DENDRO_211;
		   double 		DENDRO_365 = 0.5*DENDRO_107;
		   double 		DENDRO_366 = DENDRO_137*DENDRO_218;
		   double 		DENDRO_367 = 2.0*DENDRO_115;
		   double 		DENDRO_368 = DENDRO_204*DENDRO_261;
		   double 		DENDRO_369 = DENDRO_204*DENDRO_263;
		   double 		DENDRO_370 = DENDRO_204*DENDRO_265;
		   double 		DENDRO_371 = DENDRO_218*DENDRO_47;
		   double 		DENDRO_372 = -DENDRO_247 - DENDRO_250 - DENDRO_252 + DENDRO_255 - DENDRO_257 + DENDRO_260 - DENDRO_262 - DENDRO_264 - DENDRO_266;
		   double 		DENDRO_373 = DENDRO_32*DENDRO_372;
		   double 		DENDRO_374 = DENDRO_219*DENDRO_314;
		   double 		DENDRO_375 = DENDRO_190*DENDRO_314;
		   double 		DENDRO_376 = -DENDRO_279;
		   double 		DENDRO_377 = DENDRO_274*(DENDRO_276 + DENDRO_278 + DENDRO_376);
		   double 		DENDRO_378 = DENDRO_283*(-DENDRO_144 + DENDRO_46);
		   double 		DENDRO_379 = DENDRO_174*DENDRO_230;
		   double 		DENDRO_380 = DENDRO_102*DENDRO_130;
		   double 		DENDRO_381 = 3.0*DENDRO_282;
		   double 		DENDRO_382 = 6.0*DENDRO_114;
		   double 		DENDRO_383 = grad_2_Gt0[pp];
		   double 		DENDRO_384 = grad_2_Gt1[pp];
		   double 		DENDRO_385 = 4*gt4[pp];
		   double 		DENDRO_386 = grad_2_Gt2[pp];
		   double 		DENDRO_387 = -DENDRO_178*DENDRO_342;
		   double 		DENDRO_388 = DENDRO_104*DENDRO_197;
		   double 		DENDRO_389 = DENDRO_101*DENDRO_178;
		   double 		DENDRO_390 = 0.25*DENDRO_389;
		   double 		DENDRO_391 = 0.25*DENDRO_172;
		   double 		DENDRO_392 = DENDRO_104*DENDRO_391;
		   double 		DENDRO_393 = DENDRO_174*DENDRO_178;
		   double 		DENDRO_394 = DENDRO_172*DENDRO_189;
		   double 		DENDRO_395 = DENDRO_104*DENDRO_174;
		   double 		DENDRO_396 = DENDRO_101*DENDRO_189;
		   double 		DENDRO_397 = 0.75*DENDRO_98;
		   double 		DENDRO_398 = -DENDRO_104*DENDRO_283*(DENDRO_312 + DENDRO_376 + DENDRO_397) + DENDRO_116*(2*DENDRO_189*DENDRO_197 + DENDRO_387) + DENDRO_160*(DENDRO_388 + DENDRO_390) + DENDRO_160*(DENDRO_178*DENDRO_365 + DENDRO_392) - DENDRO_167*(DENDRO_395 + DENDRO_396) - DENDRO_178*DENDRO_274*(DENDRO_195 - DENDRO_391) - DENDRO_245*DENDRO_289 + DENDRO_294*DENDRO_383 + DENDRO_297*grad2_0_2_gt5[pp] + DENDRO_302*grad2_2_2_gt5[pp] + DENDRO_303*grad2_1_1_gt5[pp] + DENDRO_304*grad2_0_0_gt5[pp] - DENDRO_310*grad2_1_2_gt5[pp] - DENDRO_311*grad2_0_1_gt5[pp] + DENDRO_367*(DENDRO_393 + DENDRO_394) + DENDRO_384*DENDRO_385 + 4*DENDRO_386*gt5[pp];
		   double 		DENDRO_399 = grad2_1_1_alpha[pp];
		   double 		DENDRO_400 = 0.5*gt3[pp];
		   double 		DENDRO_401 = DENDRO_18*DENDRO_335;
		   double 		DENDRO_402 = -1.0*DENDRO_33;
		   double 		DENDRO_403 = DENDRO_33*DENDRO_341 + DENDRO_36;
		   double 		DENDRO_404 = DENDRO_18*gt3[pp];
		   double 		DENDRO_405 = 0.5*DENDRO_404;
		   double 		DENDRO_406 = -DENDRO_18*DENDRO_193 + DENDRO_18*DENDRO_198 - DENDRO_18*DENDRO_199;
		   double 		DENDRO_407 = -DENDRO_248;
		   double 		DENDRO_408 = -DENDRO_93;
		   double 		DENDRO_409 = DENDRO_408 + DENDRO_95;
		   double 		DENDRO_410 = DENDRO_211*DENDRO_44;
		   double 		DENDRO_411 = DENDRO_137*DENDRO_213;
		   double 		DENDRO_412 = 0.25*DENDRO_411;
		   double 		DENDRO_413 = DENDRO_125*DENDRO_188;
		   double 		DENDRO_414 = DENDRO_107*DENDRO_230;
		   double 		DENDRO_415 = 0.25*DENDRO_414;
		   double 		DENDRO_416 = DENDRO_125*DENDRO_361;
		   double 		DENDRO_417 = 0.5*DENDRO_101;
		   double 		DENDRO_418 = DENDRO_150*DENDRO_211;
		   double 		DENDRO_419 = 0.5*DENDRO_97;
		   double 		DENDRO_420 = DENDRO_211*DENDRO_419;
		   double 		DENDRO_421 = -DENDRO_420;
		   double 		DENDRO_422 = DENDRO_101*DENDRO_221;
		   double 		DENDRO_423 = 0.5*DENDRO_197;
		   double 		DENDRO_424 = DENDRO_230*DENDRO_423;
		   double 		DENDRO_425 = 2*DENDRO_188*DENDRO_239;
		   double 		DENDRO_426 = DENDRO_178*DENDRO_191;
		   double 		DENDRO_427 = 0.25*DENDRO_426;
		   double 		DENDRO_428 = DENDRO_172*DENDRO_200;
		   double 		DENDRO_429 = DENDRO_125*DENDRO_423;
		   double 		DENDRO_430 = DENDRO_101*DENDRO_239;
		   double 		DENDRO_431 = -DENDRO_213*DENDRO_419;
		   double 		DENDRO_432 = 2*DENDRO_221*DENDRO_44;
		   double 		DENDRO_433 = DENDRO_111*DENDRO_191;
		   double 		DENDRO_434 = 0.25*DENDRO_433;
		   double 		DENDRO_435 = DENDRO_200*DENDRO_92;
		   double 		DENDRO_436 = DENDRO_137*DENDRO_221;
		   double 		DENDRO_437 = DENDRO_174*DENDRO_239;
		   double 		DENDRO_438 = DENDRO_107*DENDRO_239;
		   double 		DENDRO_439 = DENDRO_221*DENDRO_42;
		   double 		DENDRO_440 = DENDRO_230*DENDRO_270;
		   double 		DENDRO_441 = -DENDRO_312;
		   double 		DENDRO_442 = DENDRO_270*(DENDRO_276 + DENDRO_313 + DENDRO_441);
		   double 		DENDRO_443 = DENDRO_222*DENDRO_314;
		   double 		DENDRO_444 = DENDRO_283*(-DENDRO_150 + DENDRO_41);
		   double 		DENDRO_445 = DENDRO_283*(DENDRO_279 + DENDRO_397 + DENDRO_441);
		   double 		DENDRO_446 = grad_1_Gt0[pp];
		   double 		DENDRO_447 = grad_1_Gt1[pp];
		   double 		DENDRO_448 = grad_1_Gt2[pp];
		   double 		DENDRO_449 = DENDRO_111*DENDRO_391;
		   double 		DENDRO_450 = DENDRO_178*DENDRO_272;
		   double 		DENDRO_451 = DENDRO_172*DENDRO_178;
		   double 		DENDRO_452 = DENDRO_111*DENDRO_92;
		   double 		DENDRO_453 = -DENDRO_154*(DENDRO_111*DENDRO_196 + DENDRO_450) - DENDRO_154*(DENDRO_178*DENDRO_93 + DENDRO_449) - DENDRO_240*DENDRO_314*(DENDRO_195 + DENDRO_196) - DENDRO_249*DENDRO_289 - DENDRO_285*DENDRO_451 + DENDRO_292*DENDRO_446 + DENDRO_297*grad2_0_2_gt3[pp] + DENDRO_302*grad2_2_2_gt3[pp] + DENDRO_303*grad2_1_1_gt3[pp] + DENDRO_304*grad2_0_0_gt3[pp] - DENDRO_310*grad2_1_2_gt3[pp] - DENDRO_311*grad2_0_1_gt3[pp] - DENDRO_381*DENDRO_452 + DENDRO_385*DENDRO_448 + 4*DENDRO_447*gt3[pp];
		   double 		DENDRO_454 = DENDRO_130*DENDRO_161;
		   double 		DENDRO_455 = DENDRO_206*DENDRO_50;
		   double 		DENDRO_456 = 0.25*DENDRO_455;
		   double 		DENDRO_457 = DENDRO_47*DENDRO_89;
		   double 		DENDRO_458 = DENDRO_125*DENDRO_135;
		   double 		DENDRO_459 = DENDRO_150*DENDRO_206;
		   double 		DENDRO_460 = DENDRO_144*DENDRO_213;
		   double 		DENDRO_461 = DENDRO_125*DENDRO_161;
		   double 		DENDRO_462 = DENDRO_213*DENDRO_50;
		   double 		DENDRO_463 = 0.25*DENDRO_462;
		   double 		DENDRO_464 = DENDRO_42*DENDRO_89;
		   double 		DENDRO_465 = DENDRO_107*DENDRO_86;
		   double 		DENDRO_466 = DENDRO_102*DENDRO_86;
		   double 		DENDRO_467 = DENDRO_206*DENDRO_47;
		   double 		DENDRO_468 = DENDRO_213*DENDRO_42;
		   double 		DENDRO_469 = DENDRO_230*DENDRO_47;
		   double 		DENDRO_470 = DENDRO_102*DENDRO_125;
		   double 		DENDRO_471 = DENDRO_131 + DENDRO_470;
		   double 		DENDRO_472 = DENDRO_178*DENDRO_42;
		   double 		DENDRO_473 = DENDRO_107*DENDRO_111;
		   double 		DENDRO_474 = DENDRO_104*DENDRO_92;
		   double 		DENDRO_475 = DENDRO_473 + DENDRO_474;
		   double 		DENDRO_476 = DENDRO_135*DENDRO_206;
		   double 		DENDRO_477 = DENDRO_121*DENDRO_236;
		   double 		DENDRO_478 = -DENDRO_477;
		   double 		DENDRO_479 = DENDRO_189*DENDRO_299 + 0.25*DENDRO_395;
		   double 		DENDRO_480 = DENDRO_107*DENDRO_213;
		   double 		DENDRO_481 = 0.25*DENDRO_480;
		   double 		DENDRO_482 = DENDRO_111*DENDRO_423;
		   double 		DENDRO_483 = -DENDRO_178*DENDRO_419;
		   double 		DENDRO_484 = DENDRO_482 + DENDRO_483;
		   double 		DENDRO_485 = DENDRO_49*DENDRO_89;
		   double 		DENDRO_486 = DENDRO_130*DENDRO_144;
		   double 		DENDRO_487 = 0.25*DENDRO_307 + DENDRO_365*DENDRO_53;
		   double 		DENDRO_488 = 0.25*DENDRO_104;
		   double 		DENDRO_489 = DENDRO_137*DENDRO_488 + DENDRO_184*DENDRO_53;
		   double 		DENDRO_490 = DENDRO_182*DENDRO_86;
		   double 		DENDRO_491 = -DENDRO_130*DENDRO_346;
		   double 		DENDRO_492 = DENDRO_101*DENDRO_488;
		   double 		DENDRO_493 = DENDRO_107*DENDRO_488 + DENDRO_189*DENDRO_43;
		   double 		DENDRO_494 = DENDRO_144*DENDRO_206;
		   double 		DENDRO_495 = DENDRO_218*DENDRO_51;
		   double 		DENDRO_496 = DENDRO_161*DENDRO_206 + DENDRO_495;
		   double 		DENDRO_497 = DENDRO_189*DENDRO_97;
		   double 		DENDRO_498 = 0.5*DENDRO_388;
		   double 		DENDRO_499 = -DENDRO_497 + DENDRO_498;
		   double 		DENDRO_500 = DENDRO_137*DENDRO_178;
		   double 		DENDRO_501 = 0.25*DENDRO_500;
		   double 		DENDRO_502 = DENDRO_189*DENDRO_93;
		   double 		DENDRO_503 = DENDRO_111*DENDRO_361 + DENDRO_502;
		   double 		DENDRO_504 = 0.25*DENDRO_107;
		   double 		DENDRO_505 = DENDRO_218*DENDRO_43;
		   double 		DENDRO_506 = DENDRO_206*DENDRO_504 + DENDRO_505;
		   double 		DENDRO_507 = DENDRO_236*DENDRO_299;
		   double 		DENDRO_508 = DENDRO_362 + DENDRO_363;
		   double 		DENDRO_509 = DENDRO_230*DENDRO_346;
		   double 		DENDRO_510 = -DENDRO_509;
		   double 		DENDRO_511 = 0.25*DENDRO_125;
		   double 		DENDRO_512 = DENDRO_181*DENDRO_511;
		   double 		DENDRO_513 = DENDRO_236*DENDRO_365 + DENDRO_512;
		   double 		DENDRO_514 = DENDRO_135*DENDRO_213 + DENDRO_505;
		   double 		DENDRO_515 = DENDRO_178*DENDRO_295;
		   double 		DENDRO_516 = -0.5*DENDRO_105 + DENDRO_197*DENDRO_53;
		   double 		DENDRO_517 = DENDRO_184*DENDRO_86;
		   double 		DENDRO_518 = DENDRO_161*DENDRO_230;
		   double 		DENDRO_519 = 0.25*DENDRO_137;
		   double 		DENDRO_520 = DENDRO_130*DENDRO_519;
		   double 		DENDRO_521 = 0.25*DENDRO_211;
		   double 		DENDRO_522 = DENDRO_50*DENDRO_521;
		   double 		DENDRO_523 = DENDRO_161*DENDRO_213;
		   double 		DENDRO_524 = DENDRO_522 + DENDRO_523;
		   double 		DENDRO_525 = DENDRO_365*DENDRO_89 + DENDRO_459;
		   double 		DENDRO_526 = DENDRO_137*DENDRO_230;
		   double 		DENDRO_527 = DENDRO_125*DENDRO_174;
		   double 		DENDRO_528 = DENDRO_414 + DENDRO_527;
		   double 		DENDRO_529 = 1.0*DENDRO_273;
		   double 		DENDRO_530 = -DENDRO_256;
		   double 		DENDRO_531 = 0.5*DENDRO_87;
		   double 		DENDRO_532 = 0.5*DENDRO_88;
		   double 		DENDRO_533 = 0.5*DENDRO_90;
		   double 		DENDRO_534 = 2.0*DENDRO_383;
		   double 		DENDRO_535 = DENDRO_534*gt0[pp];
		   double 		DENDRO_536 = 2.0*DENDRO_384;
		   double 		DENDRO_537 = DENDRO_536*gt1[pp];
		   double 		DENDRO_538 = 2.0*gt2[pp];
		   double 		DENDRO_539 = DENDRO_290*DENDRO_538;
		   double 		DENDRO_540 = DENDRO_386*DENDRO_538;
		   double 		DENDRO_541 = 2.0*gt4[pp];
		   double 		DENDRO_542 = DENDRO_291*DENDRO_541;
		   double 		DENDRO_543 = 2.0*gt5[pp];
		   double 		DENDRO_544 = DENDRO_293*DENDRO_543;
		   double 		DENDRO_545 = DENDRO_289*DENDRO_34;
		   double 		DENDRO_546 = -DENDRO_35*DENDRO_545;
		   double 		DENDRO_547 = DENDRO_297*grad2_0_2_gt2[pp];
		   double 		DENDRO_548 = DENDRO_302*grad2_2_2_gt2[pp];
		   double 		DENDRO_549 = DENDRO_303*grad2_1_1_gt2[pp];
		   double 		DENDRO_550 = DENDRO_304*grad2_0_0_gt2[pp];
		   double 		DENDRO_551 = -DENDRO_310*grad2_1_2_gt2[pp];
		   double 		DENDRO_552 = -DENDRO_311*grad2_0_1_gt2[pp];
		   double 		DENDRO_553 = DENDRO_18*gt2[pp];
		   double 		DENDRO_554 = DENDRO_100*DENDRO_368 + DENDRO_118*DENDRO_369 + DENDRO_370*DENDRO_45 + DENDRO_373*DENDRO_553 + DENDRO_535 + DENDRO_537 + DENDRO_539 + DENDRO_540 + DENDRO_542 + DENDRO_544 + DENDRO_546 + DENDRO_547 + DENDRO_548 + DENDRO_549 + DENDRO_550 + DENDRO_551 + DENDRO_552 - DENDRO_91*(DENDRO_530 + DENDRO_531*(DENDRO_102*DENDRO_331 + DENDRO_129 + DENDRO_47*DENDRO_76) + DENDRO_532*(DENDRO_101*DENDRO_341 + DENDRO_103) + DENDRO_533*(DENDRO_102*DENDRO_76 + DENDRO_148 + DENDRO_47*DENDRO_78));
		   double 		DENDRO_555 = grad2_0_2_alpha[pp];
		   double 		DENDRO_556 = DENDRO_127*DENDRO_18;
		   double 		DENDRO_557 = DENDRO_128*DENDRO_18;
		   double 		DENDRO_558 = DENDRO_129*DENDRO_18;
		   double 		DENDRO_559 = -DENDRO_35;
		   double 		DENDRO_560 = DENDRO_32*(DENDRO_332*DENDRO_553 + DENDRO_559);
		   double 		DENDRO_561 = 2.0*DENDRO_67;
		   double 		DENDRO_562 = DENDRO_146*DENDRO_18;
		   double 		DENDRO_563 = DENDRO_147*DENDRO_18;
		   double 		DENDRO_564 = DENDRO_148*DENDRO_18;
		   double 		DENDRO_565 = -DENDRO_34;
		   double 		DENDRO_566 = DENDRO_32*(DENDRO_553*DENDRO_79 + DENDRO_565);
		   double 		DENDRO_567 = 2.0*DENDRO_82;
		   double 		DENDRO_568 = 2.0*DENDRO_55;
		   double 		DENDRO_569 = DENDRO_18*(DENDRO_104 + DENDRO_38*gt2[pp]);
		   double 		DENDRO_570 = -4*DENDRO_555 + DENDRO_561*(-DENDRO_556 - DENDRO_557 + DENDRO_558 + DENDRO_560) + DENDRO_567*(-DENDRO_562 - DENDRO_563 + DENDRO_564 + DENDRO_566) + DENDRO_568*DENDRO_569;
		   double 		DENDRO_571 = DENDRO_211*DENDRO_47;
		   double 		DENDRO_572 = DENDRO_102*DENDRO_213 + DENDRO_571;
		   double 		DENDRO_573 = 0.5*DENDRO_349;
		   double 		DENDRO_574 = 0.25*DENDRO_526;
		   double 		DENDRO_575 = DENDRO_130*DENDRO_135 + DENDRO_490;
		   double 		DENDRO_576 = DENDRO_111*DENDRO_342;
		   double 		DENDRO_577 = -DENDRO_576;
		   double 		DENDRO_578 = -DENDRO_213*DENDRO_346;
		   double 		DENDRO_579 = DENDRO_362 + DENDRO_512;
		   double 		DENDRO_580 = DENDRO_458 + DENDRO_517;
		   double 		DENDRO_581 = DENDRO_144*DENDRO_230;
		   double 		DENDRO_582 = DENDRO_299*DENDRO_89;
		   double 		DENDRO_583 = DENDRO_211*DENDRO_42;
		   double 		DENDRO_584 = DENDRO_480 + DENDRO_583;
		   double 		DENDRO_585 = DENDRO_104*DENDRO_172;
		   double 		DENDRO_586 = DENDRO_111*DENDRO_174 + DENDRO_585;
		   double 		DENDRO_587 = 0.25*DENDRO_473;
		   double 		DENDRO_588 = DENDRO_196*DENDRO_53;
		   double 		DENDRO_589 = DENDRO_150*DENDRO_178 + DENDRO_588;
		   double 		DENDRO_590 = DENDRO_115*(DENDRO_500 + DENDRO_586) - DENDRO_154*(DENDRO_489 + DENDRO_492) - DENDRO_154*(-DENDRO_188*DENDRO_53 + DENDRO_493) + DENDRO_160*(DENDRO_113 + DENDRO_516) + DENDRO_160*(DENDRO_587 + DENDRO_589) - DENDRO_270*(DENDRO_344 + DENDRO_479) - DENDRO_274*(DENDRO_449 + DENDRO_484) - DENDRO_283*(0.5*DENDRO_308 + DENDRO_487);
		   double 		DENDRO_591 = DENDRO_130*DENDRO_172;
		   double 		DENDRO_592 = DENDRO_206*DENDRO_92;
		   double 		DENDRO_593 = 0.25*DENDRO_393;
		   double 		DENDRO_594 = DENDRO_188*DENDRO_236;
		   double 		DENDRO_595 = -DENDRO_594;
		   double 		DENDRO_596 = DENDRO_135*DENDRO_211 + DENDRO_218*DENDRO_417;
		   double 		DENDRO_597 = DENDRO_197*DENDRO_200;
		   double 		DENDRO_598 = DENDRO_230*DENDRO_391;
		   double 		DENDRO_599 = DENDRO_221*DENDRO_365;
		   double 		DENDRO_600 = DENDRO_211*DENDRO_272 + DENDRO_599;
		   double 		DENDRO_601 = DENDRO_206*DENDRO_295;
		   double 		DENDRO_602 = DENDRO_523 + DENDRO_601;
		   double 		DENDRO_603 = DENDRO_218*DENDRO_44 + 0.5*DENDRO_358;
		   double 		DENDRO_604 = DENDRO_101*DENDRO_206;
		   double 		DENDRO_605 = 0.25*DENDRO_604;
		   double 		DENDRO_606 = DENDRO_178*DENDRO_504 + DENDRO_502;
		   double 		DENDRO_607 = DENDRO_236*DENDRO_417;
		   double 		DENDRO_608 = DENDRO_130*DENDRO_342;
		   double 		DENDRO_609 = -DENDRO_608;
		   double 		DENDRO_610 = DENDRO_182*DENDRO_239;
		   double 		DENDRO_611 = -DENDRO_230*DENDRO_342 + DENDRO_610;
		   double 		DENDRO_612 = DENDRO_117*DENDRO_221;
		   double 		DENDRO_613 = DENDRO_101*DENDRO_521 + DENDRO_612;
		   double 		DENDRO_614 = DENDRO_211*DENDRO_519;
		   double 		DENDRO_615 = DENDRO_211*DENDRO_504 + DENDRO_218*DENDRO_93;
		   double 		DENDRO_616 = DENDRO_178*DENDRO_423;
		   double 		DENDRO_617 = DENDRO_189*DENDRO_192;
		   double 		DENDRO_618 = DENDRO_178*DENDRO_391 + DENDRO_617;
		   double 		DENDRO_619 = -DENDRO_206*DENDRO_419;
		   double 		DENDRO_620 = DENDRO_221*DENDRO_49;
		   double 		DENDRO_621 = 0.5*DENDRO_410 + DENDRO_620;
		   double 		DENDRO_622 = DENDRO_130*DENDRO_423;
		   double 		DENDRO_623 = 0.25*DENDRO_101;
		   double 		DENDRO_624 = DENDRO_117*DENDRO_239;
		   double 		DENDRO_625 = DENDRO_230*DENDRO_623 + DENDRO_624;
		   double 		DENDRO_626 = DENDRO_191*DENDRO_488;
		   double 		DENDRO_627 = DENDRO_450 + DENDRO_626;
		   double 		DENDRO_628 = DENDRO_200*DENDRO_365;
		   double 		DENDRO_629 = DENDRO_101*DENDRO_130;
		   double 		DENDRO_630 = 1.0*DENDRO_282;
		   double 		DENDRO_631 = -DENDRO_253;
		   double 		DENDRO_632 = DENDRO_18*gt4[pp];
		   double 		DENDRO_633 = DENDRO_297*grad2_0_2_gt4[pp] + DENDRO_302*grad2_2_2_gt4[pp] + DENDRO_303*grad2_1_1_gt4[pp] + DENDRO_304*grad2_0_0_gt4[pp] - DENDRO_310*grad2_1_2_gt4[pp] - DENDRO_311*grad2_0_1_gt4[pp] - DENDRO_33*DENDRO_545 + DENDRO_386*DENDRO_541 + DENDRO_446*DENDRO_538 + DENDRO_447*DENDRO_541 + DENDRO_448*DENDRO_543 + DENDRO_534*gt1[pp] + DENDRO_536*gt3[pp];
		   double 		DENDRO_634 = DENDRO_185*DENDRO_369 + DENDRO_194*DENDRO_368 + DENDRO_370*DENDRO_98 + DENDRO_373*DENDRO_632 + DENDRO_633 - DENDRO_91*(DENDRO_531*(DENDRO_137*DENDRO_76 + DENDRO_174*DENDRO_331 + DENDRO_227) + DENDRO_532*(DENDRO_172*DENDRO_341 + DENDRO_177) + DENDRO_533*(DENDRO_137*DENDRO_78 + DENDRO_174*DENDRO_76 + DENDRO_208) + DENDRO_631);
		   double 		DENDRO_635 = grad2_1_2_alpha[pp];
		   double 		DENDRO_636 = DENDRO_18*DENDRO_227;
		   double 		DENDRO_637 = DENDRO_18*DENDRO_228;
		   double 		DENDRO_638 = DENDRO_18*DENDRO_229;
		   double 		DENDRO_639 = -DENDRO_33;
		   double 		DENDRO_640 = DENDRO_32*(DENDRO_332*DENDRO_632 + DENDRO_639);
		   double 		DENDRO_641 = -DENDRO_173*DENDRO_18 + DENDRO_175*DENDRO_18 + DENDRO_176*DENDRO_18;
		   double 		DENDRO_642 = DENDRO_324*gt4[pp];
		   double 		DENDRO_643 = DENDRO_18*DENDRO_567*(DENDRO_211 + DENDRO_642) + DENDRO_561*(DENDRO_636 - DENDRO_637 - DENDRO_638 + DENDRO_640) + DENDRO_568*(DENDRO_32*(DENDRO_403*DENDRO_632 + DENDRO_565) + DENDRO_641) - 4*DENDRO_635;
		   double 		DENDRO_644 = 0.5*DENDRO_355;
		   double 		DENDRO_645 = 1.0*DENDRO_437;
		   double 		DENDRO_646 = 0.5*DENDRO_436;
		   double 		DENDRO_647 = 0.25*DENDRO_629;
		   double 		DENDRO_648 = DENDRO_363 + DENDRO_512;
		   double 		DENDRO_649 = DENDRO_121*DENDRO_221;
		   double 		DENDRO_650 = DENDRO_616 + DENDRO_617;
		   double 		DENDRO_651 = DENDRO_230*DENDRO_361;
		   double 		DENDRO_652 = DENDRO_221*DENDRO_48;
		   double 		DENDRO_653 = DENDRO_206*DENDRO_272 + DENDRO_652;
		   double 		DENDRO_654 = DENDRO_130*DENDRO_391 + DENDRO_624;
		   double 		DENDRO_655 = DENDRO_449 + DENDRO_450;
		   double 		DENDRO_656 = DENDRO_200*DENDRO_417 + DENDRO_626;
		   double 		DENDRO_657 = 1.0*DENDRO_153;
		   double 		DENDRO_658 = -DENDRO_154*(DENDRO_577 + DENDRO_606) - DENDRO_270*(DENDRO_189*DENDRO_196 + DENDRO_387 + DENDRO_593) - DENDRO_630*(DENDRO_112 + DENDRO_475) - DENDRO_657*(DENDRO_389 + DENDRO_586);
		   double 		DENDRO_659 = DENDRO_510 + DENDRO_609;
		   double 		DENDRO_660 = 0.5*DENDRO_433;
		   double 		DENDRO_661 = DENDRO_200*DENDRO_97;
		   double 		DENDRO_662 = -DENDRO_661;
		   double 		DENDRO_663 = DENDRO_239*DENDRO_299;
		   double 		DENDRO_664 = DENDRO_125*DENDRO_391 + DENDRO_663;
		   double 		DENDRO_665 = DENDRO_213*DENDRO_272;
		   double 		DENDRO_666 = DENDRO_221*DENDRO_43;
		   double 		DENDRO_667 = DENDRO_44*DENDRO_89;
		   double 		DENDRO_668 = DENDRO_125*DENDRO_144 + DENDRO_417*DENDRO_86;
		   double 		DENDRO_669 = DENDRO_188*DENDRO_86;
		   double 		DENDRO_670 = 0.5*DENDRO_126;
		   double 		DENDRO_671 = -DENDRO_669 - DENDRO_670;
		   double 		DENDRO_672 = DENDRO_417*DENDRO_89 + DENDRO_460;
		   double 		DENDRO_673 = DENDRO_522 + DENDRO_601;
		   double 		DENDRO_674 = DENDRO_121*DENDRO_239;
		   double 		DENDRO_675 = 0.5*DENDRO_413;
		   double 		DENDRO_676 = -DENDRO_674 - DENDRO_675;
		   double 		DENDRO_677 = DENDRO_213*DENDRO_623 + DENDRO_652;
		   double 		DENDRO_678 = DENDRO_200*DENDRO_299;
		   double 		DENDRO_679 = DENDRO_449 + DENDRO_626;
		   double 		DENDRO_680 = DENDRO_239*DENDRO_48;
		   double 		DENDRO_681 = DENDRO_101*DENDRO_511 + DENDRO_680;
		   double 		DENDRO_682 = DENDRO_221*DENDRO_51;
		   double 		DENDRO_683 = DENDRO_213*DENDRO_295 + DENDRO_682;
		   double 		DENDRO_684 = DENDRO_125*DENDRO_504;
		   double 		DENDRO_685 = DENDRO_137*DENDRO_511 + DENDRO_196*DENDRO_86;
		   double 		DENDRO_686 = DENDRO_192*DENDRO_53;
		   double 		DENDRO_687 = DENDRO_111*DENDRO_272 + DENDRO_686;
		   double 		DENDRO_688 = 1.0*DENDRO_269;
		   double 		DENDRO_689 = -DENDRO_258;
		   double 		DENDRO_690 = 2.0*DENDRO_446*gt0[pp];
		   double 		DENDRO_691 = 2.0*gt1[pp];
		   double 		DENDRO_692 = DENDRO_290*DENDRO_691;
		   double 		DENDRO_693 = DENDRO_447*DENDRO_691;
		   double 		DENDRO_694 = DENDRO_448*DENDRO_538;
		   double 		DENDRO_695 = 2.0*DENDRO_291*gt3[pp];
		   double 		DENDRO_696 = DENDRO_293*DENDRO_541;
		   double 		DENDRO_697 = -DENDRO_259*DENDRO_289;
		   double 		DENDRO_698 = DENDRO_297*grad2_0_2_gt1[pp];
		   double 		DENDRO_699 = DENDRO_302*grad2_2_2_gt1[pp];
		   double 		DENDRO_700 = DENDRO_303*grad2_1_1_gt1[pp];
		   double 		DENDRO_701 = DENDRO_304*grad2_0_0_gt1[pp];
		   double 		DENDRO_702 = -DENDRO_310*grad2_1_2_gt1[pp];
		   double 		DENDRO_703 = -DENDRO_311*grad2_0_1_gt1[pp];
		   double 		DENDRO_704 = DENDRO_18*gt1[pp];
		   double 		DENDRO_705 = DENDRO_368*DENDRO_94 + DENDRO_369*DENDRO_99 + DENDRO_370*DENDRO_40 + DENDRO_373*DENDRO_704 + DENDRO_690 + DENDRO_692 + DENDRO_693 + DENDRO_694 + DENDRO_695 + DENDRO_696 + DENDRO_697 + DENDRO_698 + DENDRO_699 + DENDRO_700 + DENDRO_701 + DENDRO_702 + DENDRO_703 - DENDRO_91*(DENDRO_531*(DENDRO_107*DENDRO_331 + DENDRO_122 + DENDRO_42*DENDRO_76) + DENDRO_532*(DENDRO_110 + DENDRO_341*DENDRO_92) + DENDRO_533*(DENDRO_107*DENDRO_76 + DENDRO_140 + DENDRO_42*DENDRO_78) + DENDRO_689);
		   double 		DENDRO_706 = 0.25*DENDRO_305;
		   double 		DENDRO_707 = DENDRO_111*DENDRO_519 + DENDRO_588;
		   double 		DENDRO_708 = -DENDRO_111*DENDRO_419;
		   double 		DENDRO_709 = DENDRO_116*(DENDRO_483 + DENDRO_679) - DENDRO_154*(DENDRO_298 + DENDRO_589) - DENDRO_154*(DENDRO_298 + DENDRO_707) + DENDRO_160*(DENDRO_687 + DENDRO_708) - DENDRO_270*(DENDRO_104*DENDRO_196 + DENDRO_501) - DENDRO_283*(1.0*DENDRO_306 + DENDRO_706);
		   double 		DENDRO_710 = grad2_0_1_alpha[pp];
		   double 		DENDRO_711 = -DENDRO_106*DENDRO_18 + DENDRO_108*DENDRO_18 + DENDRO_109*DENDRO_18;
		   double 		DENDRO_712 = DENDRO_140*DENDRO_18;
		   double 		DENDRO_713 = DENDRO_141*DENDRO_18;
		   double 		DENDRO_714 = DENDRO_142*DENDRO_18;
		   double 		DENDRO_715 = DENDRO_32*(DENDRO_639 + DENDRO_704*DENDRO_79);
		   double 		DENDRO_716 = DENDRO_61*gt1[pp];
		   double 		DENDRO_717 = DENDRO_18*DENDRO_561*(DENDRO_125 + DENDRO_716) + DENDRO_567*(DENDRO_712 - DENDRO_713 - DENDRO_714 + DENDRO_715) + DENDRO_568*(DENDRO_32*(DENDRO_403*DENDRO_704 + DENDRO_559) + DENDRO_711) - 4*DENDRO_710;
		   double 		DENDRO_718 = DENDRO_150*DENDRO_213;
		   double 		DENDRO_719 = -DENDRO_10*(DENDRO_643 + alpha[pp]*(DENDRO_116*(DENDRO_611 + DENDRO_651) + DENDRO_116*(DENDRO_613 + DENDRO_614) + DENDRO_116*(DENDRO_615 - DENDRO_649) + DENDRO_116*(-DENDRO_188*DENDRO_200 + DENDRO_650) + DENDRO_116*(DENDRO_196*DENDRO_236 + DENDRO_610 + DENDRO_651) - DENDRO_154*(DENDRO_578 + DENDRO_603) - DENDRO_154*(DENDRO_607 + DENDRO_648) - DENDRO_154*(DENDRO_609 + DENDRO_648) + DENDRO_160*(DENDRO_412 + DENDRO_621) + DENDRO_160*(DENDRO_416 + DENDRO_625) + DENDRO_160*(DENDRO_416 + DENDRO_654) + DENDRO_160*(DENDRO_481 + DENDRO_653) + DENDRO_160*(DENDRO_482 + DENDRO_656) + DENDRO_160*(DENDRO_628 + DENDRO_655) - DENDRO_270*(DENDRO_353 + DENDRO_596) - DENDRO_270*(DENDRO_595 + DENDRO_644) - DENDRO_274*(DENDRO_598 + DENDRO_645) - DENDRO_274*(DENDRO_600 + DENDRO_646) - DENDRO_274*(DENDRO_196*DENDRO_200 + DENDRO_427 + DENDRO_597) - DENDRO_283*(DENDRO_460 + DENDRO_602) - DENDRO_283*(DENDRO_117*DENDRO_125 + DENDRO_647) + DENDRO_367*(DENDRO_174*DENDRO_200 + DENDRO_451) + DENDRO_634 - DENDRO_657*(DENDRO_572 + DENDRO_604) + DENDRO_658)) - DENDRO_10*(DENDRO_643 + alpha[pp]*(DENDRO_116*(DENDRO_614 + DENDRO_615) + DENDRO_116*(DENDRO_616 + DENDRO_618) + DENDRO_116*(DENDRO_184*DENDRO_200 + DENDRO_618) + DENDRO_116*(DENDRO_197*DENDRO_236 + DENDRO_611) + DENDRO_116*(-DENDRO_218*DENDRO_97 + DENDRO_613) - DENDRO_154*(DENDRO_360 + DENDRO_603) - DENDRO_154*(DENDRO_392 + DENDRO_503) - DENDRO_154*(DENDRO_392 + DENDRO_606) - DENDRO_154*(DENDRO_508 + DENDRO_607) - DENDRO_154*(DENDRO_513 + DENDRO_609) - DENDRO_154*(DENDRO_514 + DENDRO_605) + DENDRO_159*(DENDRO_528 + DENDRO_591) + DENDRO_159*(DENDRO_584 + DENDRO_592) + DENDRO_160*(DENDRO_482 + DENDRO_627) + DENDRO_160*(DENDRO_619 + DENDRO_621) + DENDRO_160*(DENDRO_622 + DENDRO_625) + DENDRO_160*(DENDRO_627 + DENDRO_628) - DENDRO_270*(0.5*DENDRO_366 + DENDRO_596) - DENDRO_270*(1.0*DENDRO_394 + DENDRO_593) - DENDRO_270*(DENDRO_184*DENDRO_236 + DENDRO_356 + DENDRO_595) - DENDRO_274*(DENDRO_421 + DENDRO_600) - DENDRO_274*(0.5*DENDRO_426 + DENDRO_597) - DENDRO_274*(DENDRO_184*DENDRO_239 + DENDRO_424 + DENDRO_598) - DENDRO_283*(DENDRO_459 + DENDRO_602) - DENDRO_283*(DENDRO_104*DENDRO_93 + DENDRO_587) + DENDRO_367*(DENDRO_172*DENDRO_236 + DENDRO_379) - DENDRO_630*(DENDRO_471 + DENDRO_629) + DENDRO_634)) + DENDRO_13*(DENDRO_320*(DENDRO_32*(DENDRO_402 + DENDRO_403*DENDRO_405) + DENDRO_406) + DENDRO_327*(DENDRO_221 + DENDRO_324*DENDRO_400) - 4*DENDRO_399 + DENDRO_401*(DENDRO_239 + DENDRO_400*DENDRO_61) + alpha[pp]*(DENDRO_116*(DENDRO_421 + DENDRO_422) + DENDRO_116*(DENDRO_424 - DENDRO_425) + DENDRO_116*(DENDRO_427 + 1.0*DENDRO_428) - DENDRO_125*DENDRO_445 - DENDRO_154*(DENDRO_410 + DENDRO_412) - DENDRO_154*(-1.0*DENDRO_413 + DENDRO_415) - DENDRO_154*(DENDRO_213*DENDRO_417 + DENDRO_418) - DENDRO_154*(DENDRO_230*DENDRO_417 + DENDRO_416) + DENDRO_160*(DENDRO_429 + DENDRO_430) + DENDRO_160*(DENDRO_431 + DENDRO_432) + DENDRO_160*(DENDRO_434 + 1.0*DENDRO_435) + DENDRO_170*(DENDRO_433 + DENDRO_435) + DENDRO_170*(DENDRO_125*DENDRO_172 + DENDRO_438) + DENDRO_170*(DENDRO_213*DENDRO_92 + DENDRO_439) + DENDRO_172*DENDRO_369 - DENDRO_191*DENDRO_201*DENDRO_382 + DENDRO_191*DENDRO_368 - DENDRO_211*DENDRO_442 - DENDRO_213*DENDRO_444 + DENDRO_367*(DENDRO_426 + DENDRO_428) + DENDRO_367*(DENDRO_172*DENDRO_230 + DENDRO_437) + DENDRO_367*(DENDRO_211*DENDRO_92 + DENDRO_436) + DENDRO_370*DENDRO_92 + DENDRO_373*DENDRO_404 - DENDRO_440*(DENDRO_186 - DENDRO_361) - DENDRO_443*(DENDRO_93 + DENDRO_95) + DENDRO_453 - DENDRO_91*(DENDRO_407 + DENDRO_87*(DENDRO_197*DENDRO_331 + DENDRO_238 + DENDRO_409*DENDRO_76) + DENDRO_88*(DENDRO_192*DENDRO_341 + DENDRO_198 + DENDRO_409*DENDRO_9) + DENDRO_90*(DENDRO_197*DENDRO_76 + DENDRO_220 + DENDRO_409*DENDRO_78)))) + DENDRO_23*(DENDRO_570 + alpha[pp]*(DENDRO_115*(DENDRO_359 + DENDRO_572) + DENDRO_116*(DENDRO_499 + DENDRO_577) + DENDRO_116*(DENDRO_506 + DENDRO_578) + DENDRO_116*(DENDRO_507 + DENDRO_579) + DENDRO_116*(DENDRO_510 + DENDRO_579) - DENDRO_154*(DENDRO_491 + DENDRO_575) - DENDRO_154*(-DENDRO_121*DENDRO_89 + DENDRO_496) - DENDRO_154*(DENDRO_236*DENDRO_48 + DENDRO_575) + DENDRO_160*(DENDRO_460 + DENDRO_525) + DENDRO_160*(DENDRO_520 + DENDRO_580) + DENDRO_160*(DENDRO_524 + DENDRO_582) + DENDRO_160*(DENDRO_580 + DENDRO_581) - DENDRO_167*(DENDRO_102*DENDRO_89 + DENDRO_467) - DENDRO_270*(DENDRO_478 + DENDRO_573) - DENDRO_270*(DENDRO_218*DENDRO_48 + DENDRO_347 + DENDRO_476) - DENDRO_274*(DENDRO_125*DENDRO_184 + DENDRO_574) - DENDRO_283*(1.0*DENDRO_466 + DENDRO_486) - DENDRO_283*(DENDRO_456 + DENDRO_48*DENDRO_89 + DENDRO_485) - DENDRO_529*(DENDRO_411 + DENDRO_584) + DENDRO_554 + DENDRO_590)) + DENDRO_23*(DENDRO_570 + alpha[pp]*(DENDRO_116*(DENDRO_364 + DENDRO_506) + DENDRO_116*(DENDRO_364 + DENDRO_514) + DENDRO_116*(DENDRO_390 + DENDRO_499) + DENDRO_116*(DENDRO_501 + DENDRO_503) + DENDRO_116*(DENDRO_507 + DENDRO_508) + DENDRO_116*(DENDRO_510 + DENDRO_513) - DENDRO_154*(DENDRO_492 + DENDRO_493) - DENDRO_154*(DENDRO_494 + DENDRO_496) - DENDRO_154*(DENDRO_189*DENDRO_44 + DENDRO_489) - DENDRO_154*(DENDRO_117*DENDRO_89 + DENDRO_494 + DENDRO_495) - DENDRO_154*(DENDRO_236*DENDRO_49 + DENDRO_490 + DENDRO_491) + DENDRO_159*(DENDRO_469 + DENDRO_471) + DENDRO_159*(DENDRO_472 + DENDRO_475) + DENDRO_160*(DENDRO_459 + DENDRO_524) + DENDRO_160*(DENDRO_515 + DENDRO_516) + DENDRO_160*(DENDRO_522 + DENDRO_525) + DENDRO_160*(DENDRO_517 + DENDRO_518 + DENDRO_520) - DENDRO_167*(DENDRO_236*DENDRO_47 + DENDRO_380) - DENDRO_270*(1.0*DENDRO_371 + DENDRO_476) - DENDRO_270*(0.5*DENDRO_396 + DENDRO_479) - DENDRO_270*(DENDRO_117*DENDRO_236 + DENDRO_350 + DENDRO_478) - DENDRO_274*(DENDRO_450 + DENDRO_484) - DENDRO_274*(DENDRO_211*DENDRO_43 + DENDRO_481) - DENDRO_283*(DENDRO_296 + DENDRO_487) - DENDRO_283*(0.5*DENDRO_455 + DENDRO_485) - DENDRO_283*(DENDRO_117*DENDRO_86 + DENDRO_454 + DENDRO_486) - DENDRO_529*(DENDRO_526 + DENDRO_528) + DENDRO_554)) + DENDRO_25*(-4*DENDRO_31 + DENDRO_321*DENDRO_54 + DENDRO_326*(-DENDRO_71 - DENDRO_73 + DENDRO_75 + DENDRO_81) + DENDRO_401*(DENDRO_62 + DENDRO_86) + alpha[pp]*(-DENDRO_114*DENDRO_223*DENDRO_288 + DENDRO_116*(-1.0*DENDRO_105 + DENDRO_113) + DENDRO_116*(-1.0*DENDRO_126 + DENDRO_132) + DENDRO_116*(DENDRO_130*DENDRO_299 + DENDRO_458) + DENDRO_116*(DENDRO_206*DENDRO_43 + DENDRO_460) + DENDRO_116*(DENDRO_213*DENDRO_48 + DENDRO_459) - DENDRO_125*DENDRO_280 - DENDRO_154*(DENDRO_456 + 1.0*DENDRO_457) - DENDRO_154*(-DENDRO_152*DENDRO_86 + DENDRO_454) + DENDRO_160*(DENDRO_463 + 1.0*DENDRO_464) + DENDRO_160*(DENDRO_137*DENDRO_86 + DENDRO_461) - DENDRO_167*(DENDRO_455 + DENDRO_457) - DENDRO_167*(DENDRO_130*DENDRO_47 + DENDRO_466) + DENDRO_170*(DENDRO_462 + DENDRO_464) + DENDRO_170*(DENDRO_125*DENDRO_47 + DENDRO_465) + DENDRO_205*DENDRO_261 + DENDRO_225*DENDRO_265 - DENDRO_241*DENDRO_281*DENDRO_314 + DENDRO_243*DENDRO_263 + DENDRO_268*DENDRO_372 - DENDRO_271*(DENDRO_119 - DENDRO_135) - DENDRO_275*(-DENDRO_272 + DENDRO_95) - DENDRO_285*DENDRO_467 - DENDRO_287*DENDRO_468 + DENDRO_315 - DENDRO_91*(DENDRO_85 + DENDRO_87*(DENDRO_331*DENDRO_49 + DENDRO_51*DENDRO_76 + DENDRO_65) + DENDRO_88*(DENDRO_341*DENDRO_44 + DENDRO_52) + DENDRO_90*(DENDRO_49*DENDRO_76 + DENDRO_51*DENDRO_78 + DENDRO_74)))) + DENDRO_29*(-4*DENDRO_317 + DENDRO_319*DENDRO_321 + DENDRO_327*(DENDRO_218 + DENDRO_325) + DENDRO_335*(-DENDRO_328 + DENDRO_329 - DENDRO_330 + DENDRO_334) + alpha[pp]*(DENDRO_102*DENDRO_370 + DENDRO_116*(DENDRO_353 + DENDRO_354) + DENDRO_116*(DENDRO_356 + 1.0*DENDRO_357) - DENDRO_154*(DENDRO_344 + DENDRO_345) - DENDRO_154*(DENDRO_350 + 1.0*DENDRO_351) - DENDRO_154*(DENDRO_218*DENDRO_348 + DENDRO_347) + DENDRO_160*(DENDRO_358 + DENDRO_360) + DENDRO_160*(DENDRO_117*DENDRO_230 + DENDRO_362) + DENDRO_160*(DENDRO_130*DENDRO_184 + DENDRO_363) + DENDRO_160*(DENDRO_206*DENDRO_365 + DENDRO_364) - DENDRO_167*(DENDRO_349 + DENDRO_351) - DENDRO_167*(DENDRO_102*DENDRO_206 + DENDRO_371) + DENDRO_174*DENDRO_368 - DENDRO_181*DENDRO_237*DENDRO_382 + DENDRO_181*DENDRO_369 - DENDRO_206*DENDRO_378 - DENDRO_211*DENDRO_377 - DENDRO_287*DENDRO_379 + DENDRO_333*DENDRO_373 + DENDRO_367*(DENDRO_355 + DENDRO_357) + DENDRO_367*(DENDRO_102*DENDRO_211 + DENDRO_366) - DENDRO_374*(DENDRO_117 + DENDRO_119) - DENDRO_375*(DENDRO_184 + DENDRO_186) - DENDRO_380*DENDRO_381 + DENDRO_398 - DENDRO_91*(DENDRO_336 + DENDRO_87*(DENDRO_10*DENDRO_338 + DENDRO_182*DENDRO_331 + DENDRO_340*DENDRO_76) + DENDRO_88*(DENDRO_183 + DENDRO_338*DENDRO_341 + DENDRO_340*DENDRO_9) + DENDRO_90*(DENDRO_182*DENDRO_76 + DENDRO_338*DENDRO_9 + DENDRO_340*DENDRO_78)))) - DENDRO_9*(DENDRO_717 + alpha[pp]*(DENDRO_115*(DENDRO_411 + DENDRO_583 + DENDRO_592) + DENDRO_115*(DENDRO_526 + DENDRO_527 + DENDRO_591) + DENDRO_116*(DENDRO_619 + DENDRO_677) + DENDRO_116*(DENDRO_622 + DENDRO_676) + DENDRO_116*(DENDRO_678 + DENDRO_679) - DENDRO_154*(DENDRO_132 + DENDRO_671) - DENDRO_154*(DENDRO_459 + DENDRO_672) - DENDRO_154*(DENDRO_582 + DENDRO_673) - DENDRO_154*(DENDRO_517 + DENDRO_581 + DENDRO_647) + DENDRO_160*(DENDRO_683 - DENDRO_89*DENDRO_97) + DENDRO_160*(DENDRO_684 + DENDRO_685) + DENDRO_160*(DENDRO_197*DENDRO_86 + DENDRO_681) + DENDRO_160*(DENDRO_200*DENDRO_43 + DENDRO_687) + DENDRO_170*(DENDRO_468 + DENDRO_89*DENDRO_92) - DENDRO_270*(DENDRO_362 + DENDRO_659) - DENDRO_274*(DENDRO_429 + DENDRO_664) - DENDRO_274*(DENDRO_660 + DENDRO_662) - DENDRO_274*(DENDRO_431 + DENDRO_665 + DENDRO_666) - DENDRO_283*(0.5*DENDRO_465 + DENDRO_668) - DENDRO_283*(DENDRO_43*DENDRO_89 + DENDRO_463 + DENDRO_667) - DENDRO_688*(DENDRO_359 + DENDRO_571 + DENDRO_604) + DENDRO_705 + DENDRO_709)) - DENDRO_9*(DENDRO_717 + alpha[pp]*(DENDRO_116*(DENDRO_415 + DENDRO_676) + DENDRO_116*(DENDRO_418 + DENDRO_653) + DENDRO_116*(DENDRO_418 + DENDRO_677) + DENDRO_116*(DENDRO_483 + DENDRO_656) + DENDRO_116*(DENDRO_574 + DENDRO_654) + DENDRO_116*(DENDRO_655 + DENDRO_678) - DENDRO_154*(DENDRO_460 + DENDRO_673) - DENDRO_154*(DENDRO_515 + DENDRO_707) - DENDRO_154*(DENDRO_518 + DENDRO_671) - DENDRO_154*(DENDRO_522 + DENDRO_672) + DENDRO_160*(DENDRO_681 + DENDRO_684) + DENDRO_160*(DENDRO_683 + DENDRO_718) + DENDRO_160*(DENDRO_239*DENDRO_49 + DENDRO_685) + DENDRO_160*(DENDRO_682 + DENDRO_718 + DENDRO_89*DENDRO_93) + DENDRO_160*(DENDRO_200*DENDRO_44 + DENDRO_686 + DENDRO_708) + DENDRO_170*(DENDRO_200*DENDRO_42 + DENDRO_452) - DENDRO_270*(DENDRO_363 + DENDRO_659) - DENDRO_270*(DENDRO_211*DENDRO_48 + DENDRO_605) - DENDRO_274*(0.5*DENDRO_438 + DENDRO_664) - DENDRO_274*(1.0*DENDRO_439 + DENDRO_665) - DENDRO_274*(DENDRO_200*DENDRO_93 + DENDRO_434 + DENDRO_662) - DENDRO_283*(DENDRO_461 + DENDRO_668) - DENDRO_283*(0.5*DENDRO_462 + DENDRO_667) - DENDRO_283*(DENDRO_300 + DENDRO_53*DENDRO_93 + DENDRO_706) - DENDRO_657*(DENDRO_112 + DENDRO_472 + DENDRO_474) - DENDRO_657*(DENDRO_469 + DENDRO_470 + DENDRO_629) - DENDRO_688*(DENDRO_389 + DENDRO_500 + DENDRO_585) + DENDRO_705));
		   double 		DENDRO_720 = DENDRO_18*DENDRO_719;
		   double 		DENDRO_721 = (1.0/12.0)*chi[pp];
		   double 		DENDRO_722 = grad_1_beta0[pp];
		   double 		DENDRO_723 = grad_1_beta2[pp];
		   double 		DENDRO_724 = (1.0/3.0)*At1[pp];
		   double 		DENDRO_725 = (2.0/3.0)*DENDRO_3;
		   double 		DENDRO_726 = At4[pp]*DENDRO_10;
		   double 		DENDRO_727 = -At3[pp]*DENDRO_13 + DENDRO_20 + DENDRO_726;
		   double 		DENDRO_728 = -At1[pp]*DENDRO_25 + At3[pp]*DENDRO_9 - At4[pp]*DENDRO_23;
		   double 		DENDRO_729 = -At1[pp]*DENDRO_23 + At3[pp]*DENDRO_10 - At4[pp]*DENDRO_29;
		   double 		DENDRO_730 = 6.0*DENDRO_67;
		   double 		DENDRO_731 = 6.0*DENDRO_82;
		   double 		DENDRO_732 = 6.0*DENDRO_55;
		   double 		DENDRO_733 = DENDRO_101*DENDRO_149;
		   double 		DENDRO_734 = DENDRO_137*DENDRO_149;
		   double 		DENDRO_735 = -DENDRO_208 + DENDRO_209 + DENDRO_210;
		   double 		DENDRO_736 = DENDRO_47*DENDRO_735;
		   double 		DENDRO_737 = DENDRO_734 + DENDRO_736;
		   double 		DENDRO_738 = DENDRO_143*DENDRO_419;
		   double 		DENDRO_739 = -DENDRO_134*DENDRO_423;
		   double 		DENDRO_740 = DENDRO_193 - DENDRO_198 + DENDRO_199;
		   double 		DENDRO_741 = DENDRO_138*DENDRO_623;
		   double 		DENDRO_742 = -DENDRO_227 + DENDRO_228 + DENDRO_229;
		   double 		DENDRO_743 = DENDRO_184*DENDRO_66;
		   double 		DENDRO_744 = DENDRO_144*DENDRO_742 + DENDRO_743;
		   double 		DENDRO_745 = DENDRO_149*DENDRO_295;
		   double 		DENDRO_746 = DENDRO_157*DENDRO_299 + 0.25*DENDRO_50*DENDRO_735;
		   double 		DENDRO_747 = DENDRO_145 + DENDRO_151;
		   double 		DENDRO_748 = DENDRO_137*DENDRO_742;
		   double 		DENDRO_749 = 1.0*DENDRO_115;
		   double 		DENDRO_750 = DENDRO_137*DENDRO_143;
		   double 		DENDRO_751 = DENDRO_42*DENDRO_735 + DENDRO_750;
		   double 		DENDRO_752 = DENDRO_203*DENDRO_204;
		   double 		DENDRO_753 = DENDRO_204*DENDRO_224;
		   double 		DENDRO_754 = DENDRO_204*DENDRO_242;
		   double 		DENDRO_755 = DENDRO_267*DENDRO_32;
		   double 		DENDRO_756 = grad_2_beta0[pp];
		   double 		DENDRO_757 = grad_2_beta1[pp];
		   double 		DENDRO_758 = (1.0/3.0)*At2[pp];
		   double 		DENDRO_759 = (2.0/3.0)*DENDRO_1;
		   double 		DENDRO_760 = At2[pp]*DENDRO_9 - At4[pp]*DENDRO_13 + At5[pp]*DENDRO_10;
		   double 		DENDRO_761 = -At2[pp]*DENDRO_25 + At4[pp]*DENDRO_9 - At5[pp]*DENDRO_23;
		   double 		DENDRO_762 = -At5[pp]*DENDRO_29 + DENDRO_24 + DENDRO_726;
		   double 		DENDRO_763 = DENDRO_107*DENDRO_143;
		   double 		DENDRO_764 = DENDRO_149*DENDRO_346;
		   double 		DENDRO_765 = DENDRO_215 + DENDRO_216 - DENDRO_217;
		   double 		DENDRO_766 = 0.25*DENDRO_134*DENDRO_181;
		   double 		DENDRO_767 = DENDRO_138*DENDRO_361;
		   double 		DENDRO_768 = DENDRO_233 - DENDRO_234 + DENDRO_235;
		   double 		DENDRO_769 = DENDRO_135*DENDRO_138;
		   double 		DENDRO_770 = DENDRO_182*DENDRO_66;
		   double 		DENDRO_771 = DENDRO_143*DENDRO_161;
		   double 		DENDRO_772 = -DENDRO_766;
		   double 		DENDRO_773 = DENDRO_143*DENDRO_346;
		   double 		DENDRO_774 = DENDRO_102*DENDRO_143;
		   double 		DENDRO_775 = (2.0/3.0)*DENDRO_0;
		   double 		DENDRO_776 = 2*At4[pp];
		   double 		DENDRO_777 = At3[pp]*DENDRO_26;
		   double 		DENDRO_778 = DENDRO_18*DENDRO_776;
		   double 		DENDRO_779 = DENDRO_32*DENDRO_400;
		   double 		DENDRO_780 = DENDRO_18*DENDRO_83;
		   double 		DENDRO_781 = DENDRO_172*DENDRO_740;
		   double 		DENDRO_782 = 1.0*DENDRO_735;
		   double 		DENDRO_783 = 0.25*DENDRO_750;
		   double 		DENDRO_784 = DENDRO_134*DENDRO_361;
		   double 		DENDRO_785 = DENDRO_740*DENDRO_92;
		   double 		DENDRO_786 = (1.0/3.0)*At4[pp];
		   double 		DENDRO_787 = DENDRO_135*DENDRO_742;
		   double 		DENDRO_788 = -DENDRO_361*DENDRO_742 + DENDRO_610;
		   double 		DENDRO_789 = DENDRO_624 - DENDRO_784;
		   double 		DENDRO_790 = DENDRO_181*DENDRO_742;
		   double 		DENDRO_791 = DENDRO_174*DENDRO_768;
		   double 		DENDRO_792 = DENDRO_138*DENDRO_181;
		   double 		DENDRO_793 = DENDRO_102*DENDRO_768;
		      // Dendro: printing variables

		      At_rhs00[pp] = (4.0/3.0)*At0[pp]*DENDRO_0 - DENDRO_1*DENDRO_2 - DENDRO_2*DENDRO_3 + DENDRO_4*DENDRO_5 + DENDRO_6*DENDRO_7 + DENDRO_721*(-12*DENDRO_31 + DENDRO_316*(-DENDRO_116*(DENDRO_105 - DENDRO_113) - DENDRO_116*(DENDRO_126 + DENDRO_133) - DENDRO_116*(DENDRO_136 + DENDRO_137*DENDRO_139) - DENDRO_116*(DENDRO_145 + DENDRO_149*DENDRO_43) - DENDRO_116*(DENDRO_143*DENDRO_48 + DENDRO_151) + DENDRO_134*DENDRO_280 + DENDRO_154*(DENDRO_163 + 1.0*DENDRO_164) - DENDRO_154*(-DENDRO_139*DENDRO_49 + DENDRO_152*DENDRO_66) + DENDRO_157*DENDRO_282*DENDRO_288 - DENDRO_160*(DENDRO_156 + 1.0*DENDRO_158) - DENDRO_160*(DENDRO_134*DENDRO_161 + 1.0*DENDRO_137*DENDRO_66) + DENDRO_167*(DENDRO_162 + DENDRO_164) + DENDRO_167*(DENDRO_165 + DENDRO_166) - DENDRO_170*(DENDRO_155 + DENDRO_158) - DENDRO_170*(DENDRO_168 + DENDRO_169) - DENDRO_203*DENDRO_205 - DENDRO_224*DENDRO_225 - DENDRO_242*DENDRO_243 - DENDRO_267*DENDRO_268 + DENDRO_271*(DENDRO_120 + DENDRO_135) + DENDRO_275*(DENDRO_272 + DENDRO_96) + DENDRO_281*DENDRO_283*DENDRO_66 + DENDRO_284*DENDRO_285 + DENDRO_286*DENDRO_287 + DENDRO_315 - DENDRO_91*(DENDRO_53*DENDRO_88 + DENDRO_85 + DENDRO_86*DENDRO_87 + DENDRO_89*DENDRO_90)) + DENDRO_54*DENDRO_57 - DENDRO_69*(-DENDRO_62 + DENDRO_66) + DENDRO_720*gt0[pp] - DENDRO_83*(DENDRO_71 + DENDRO_73 - DENDRO_75 - DENDRO_81)) - alpha[pp]*(-At0[pp]*K[pp] + DENDRO_19*(At0[pp]*DENDRO_9 - At1[pp]*DENDRO_13 + At2[pp]*DENDRO_10) + DENDRO_27*(-At0[pp]*DENDRO_25 + DENDRO_20 + DENDRO_24) + DENDRO_30*(-At0[pp]*DENDRO_23 + At1[pp]*DENDRO_10 - At2[pp]*DENDRO_29)) + beta0[pp]*agrad_0_At0[pp] + beta1[pp]*agrad_1_At0[pp] + beta2[pp]*agrad_2_At0[pp];
		      At_rhs01[pp] = At0[pp]*DENDRO_722 - At1[pp]*DENDRO_725 + At2[pp]*DENDRO_723 + At3[pp]*DENDRO_4 + At4[pp]*DENDRO_6 + DENDRO_0*DENDRO_724 + DENDRO_1*DENDRO_724 + DENDRO_721*(-DENDRO_18*DENDRO_730*(DENDRO_134 - DENDRO_716) + DENDRO_316*(DENDRO_116*(-DENDRO_299*DENDRO_740 + DENDRO_679) - DENDRO_116*(-DENDRO_622 + DENDRO_674 + DENDRO_675) + DENDRO_116*(-DENDRO_143*DENDRO_623 + DENDRO_149*DENDRO_419 + DENDRO_652) + DENDRO_154*(DENDRO_741 + DENDRO_744) + DENDRO_154*(DENDRO_745 + DENDRO_746) + DENDRO_154*(DENDRO_157*DENDRO_417 + DENDRO_747) + DENDRO_154*(DENDRO_133 + DENDRO_669 + DENDRO_670) + DENDRO_160*(-DENDRO_43*DENDRO_740 + DENDRO_687) - DENDRO_160*(DENDRO_134*DENDRO_504 + DENDRO_134*DENDRO_519 + DENDRO_196*DENDRO_66) + DENDRO_160*(-DENDRO_134*DENDRO_623 - DENDRO_197*DENDRO_66 + DENDRO_680) + DENDRO_160*(-DENDRO_143*DENDRO_295 + DENDRO_157*DENDRO_97 + DENDRO_682) - DENDRO_170*(DENDRO_157*DENDRO_92 + DENDRO_286) + DENDRO_269*(DENDRO_733 + DENDRO_737) + DENDRO_270*(-DENDRO_362 + DENDRO_509 + DENDRO_608) + DENDRO_274*(-DENDRO_660 + DENDRO_661) - DENDRO_274*(-DENDRO_134*DENDRO_391 + DENDRO_663 + DENDRO_739) - DENDRO_274*(-DENDRO_143*DENDRO_272 + DENDRO_666 + DENDRO_738) + DENDRO_283*(DENDRO_156 + DENDRO_157*DENDRO_43 + DENDRO_157*DENDRO_44) + DENDRO_283*(0.25*DENDRO_168 + 0.5*DENDRO_169 + DENDRO_417*DENDRO_66) - DENDRO_40*DENDRO_753 + DENDRO_690 + DENDRO_692 + DENDRO_693 + DENDRO_694 + DENDRO_695 + DENDRO_696 + DENDRO_697 + DENDRO_698 + DENDRO_699 + DENDRO_700 + DENDRO_701 + DENDRO_702 + DENDRO_703 - DENDRO_704*DENDRO_755 + DENDRO_709 - DENDRO_749*(DENDRO_149*DENDRO_92 + DENDRO_751) - DENDRO_749*(DENDRO_134*DENDRO_174 + DENDRO_138*DENDRO_172 + DENDRO_748) - DENDRO_752*DENDRO_94 - DENDRO_754*DENDRO_99 - DENDRO_91*(DENDRO_111*DENDRO_532 + DENDRO_125*DENDRO_531 + DENDRO_213*DENDRO_533 + DENDRO_689)) + DENDRO_704*DENDRO_719 - 12*DENDRO_710 - DENDRO_731*(-DENDRO_712 + DENDRO_713 + DENDRO_714 - DENDRO_715) + DENDRO_732*(DENDRO_32*(DENDRO_37*DENDRO_704 + DENDRO_559) + DENDRO_711)) - alpha[pp]*(-At1[pp]*K[pp] + DENDRO_19*DENDRO_727 + DENDRO_27*DENDRO_728 + DENDRO_30*DENDRO_729) + beta0[pp]*agrad_0_At1[pp] + beta1[pp]*agrad_1_At1[pp] + beta2[pp]*agrad_2_At1[pp];
		      At_rhs02[pp] = At0[pp]*DENDRO_756 + At1[pp]*DENDRO_757 - At2[pp]*DENDRO_759 + At4[pp]*DENDRO_4 + At5[pp]*DENDRO_6 + DENDRO_0*DENDRO_758 + DENDRO_3*DENDRO_758 + DENDRO_721*(DENDRO_316*(-DENDRO_100*DENDRO_752 - DENDRO_116*(DENDRO_497 - DENDRO_498 + DENDRO_576) + DENDRO_116*(-DENDRO_149*DENDRO_504 - DENDRO_43*DENDRO_765 + DENDRO_773) - DENDRO_116*(DENDRO_299*DENDRO_768 + DENDRO_766 + DENDRO_767) + DENDRO_116*(DENDRO_346*DENDRO_742 - DENDRO_767 + DENDRO_772) - DENDRO_118*DENDRO_754 - DENDRO_154*(DENDRO_121*DENDRO_139 - DENDRO_769 - DENDRO_770) - DENDRO_154*(DENDRO_121*DENDRO_157 - DENDRO_149*DENDRO_161 - DENDRO_51*DENDRO_765) + DENDRO_154*(DENDRO_48*DENDRO_768 + DENDRO_769 + DENDRO_770) - DENDRO_160*(DENDRO_136 + DENDRO_744) - DENDRO_160*(DENDRO_746 + DENDRO_771) - DENDRO_160*(DENDRO_157*DENDRO_365 + DENDRO_747) - DENDRO_160*(DENDRO_136 + DENDRO_138*DENDRO_519 + DENDRO_743) + DENDRO_167*(DENDRO_102*DENDRO_157 + DENDRO_284) + DENDRO_270*(DENDRO_477 - DENDRO_573) - DENDRO_270*(-DENDRO_135*DENDRO_149 - DENDRO_48*DENDRO_765 + DENDRO_764) + DENDRO_273*(DENDRO_751 + DENDRO_763) + DENDRO_274*(DENDRO_134*DENDRO_184 + 0.25*DENDRO_748) + DENDRO_283*(0.25*DENDRO_165 + 1.0*DENDRO_166) + DENDRO_283*(DENDRO_157*DENDRO_48 + DENDRO_157*DENDRO_49 + DENDRO_163) - DENDRO_45*DENDRO_753 + DENDRO_535 + DENDRO_537 + DENDRO_539 + DENDRO_540 + DENDRO_542 + DENDRO_544 + DENDRO_546 + DENDRO_547 + DENDRO_548 + DENDRO_549 + DENDRO_550 + DENDRO_551 + DENDRO_552 - DENDRO_553*DENDRO_755 + DENDRO_590 - DENDRO_749*(DENDRO_737 + DENDRO_774) - DENDRO_91*(DENDRO_104*DENDRO_532 + DENDRO_130*DENDRO_531 + DENDRO_206*DENDRO_533 + DENDRO_530)) + DENDRO_553*DENDRO_719 - 12*DENDRO_555 + DENDRO_569*DENDRO_732 - DENDRO_730*(DENDRO_556 + DENDRO_557 - DENDRO_558 - DENDRO_560) - DENDRO_731*(DENDRO_562 + DENDRO_563 - DENDRO_564 - DENDRO_566)) - alpha[pp]*(-At2[pp]*K[pp] + DENDRO_19*DENDRO_760 + DENDRO_27*DENDRO_761 + DENDRO_30*DENDRO_762) + beta0[pp]*agrad_0_At2[pp] + beta1[pp]*agrad_1_At2[pp] + beta2[pp]*agrad_2_At2[pp];
		      At_rhs11[pp] = (4.0/3.0)*At3[pp]*DENDRO_1 - At3[pp]*DENDRO_725 - At3[pp]*DENDRO_775 + DENDRO_5*DENDRO_722 + DENDRO_721*(DENDRO_316*(-DENDRO_116*(DENDRO_420 - 1.0*DENDRO_422) + DENDRO_116*(DENDRO_427 - 1.0*DENDRO_781) - DENDRO_116*(DENDRO_423*DENDRO_742 + DENDRO_425) + DENDRO_134*DENDRO_445 + DENDRO_143*DENDRO_444 + DENDRO_154*(DENDRO_413 - DENDRO_415) + DENDRO_154*(DENDRO_143*DENDRO_417 + DENDRO_150*DENDRO_735) + DENDRO_154*(DENDRO_417*DENDRO_742 + DENDRO_784) + DENDRO_154*(DENDRO_44*DENDRO_782 + DENDRO_783) + DENDRO_160*(DENDRO_430 + DENDRO_739) + DENDRO_160*(DENDRO_432 + DENDRO_738) + DENDRO_160*(DENDRO_434 - 1.0*DENDRO_785) + DENDRO_170*(DENDRO_433 - DENDRO_785) + DENDRO_170*(-DENDRO_134*DENDRO_172 + DENDRO_438) + DENDRO_170*(-DENDRO_143*DENDRO_92 + DENDRO_439) - DENDRO_172*DENDRO_754 + 6.0*DENDRO_191*DENDRO_273*DENDRO_740 - DENDRO_191*DENDRO_752 + DENDRO_367*(DENDRO_426 - DENDRO_781) + DENDRO_367*(DENDRO_436 - DENDRO_735*DENDRO_92) + DENDRO_367*(-DENDRO_172*DENDRO_742 + DENDRO_437) - DENDRO_404*DENDRO_755 + DENDRO_440*(DENDRO_187 + DENDRO_361) + DENDRO_442*DENDRO_735 + DENDRO_443*(DENDRO_408 + DENDRO_96) + DENDRO_453 - DENDRO_753*DENDRO_92 - DENDRO_91*(DENDRO_200*DENDRO_88 + DENDRO_221*DENDRO_90 + DENDRO_239*DENDRO_87 + DENDRO_407)) - 12*DENDRO_399 + DENDRO_56*(DENDRO_32*(DENDRO_37*DENDRO_405 + DENDRO_402) + DENDRO_406) + DENDRO_69*(DENDRO_239 - DENDRO_779*(-DENDRO_58 + DENDRO_59 + DENDRO_60)) + DENDRO_720*gt3[pp] + DENDRO_780*(DENDRO_221 - DENDRO_779*(DENDRO_322 + DENDRO_323 - DENDRO_77))) + DENDRO_723*DENDRO_776 - alpha[pp]*(-At3[pp]*K[pp] + DENDRO_19*DENDRO_728 + DENDRO_727*DENDRO_777 + DENDRO_729*DENDRO_778) + beta0[pp]*agrad_0_At3[pp] + beta1[pp]*agrad_1_At3[pp] + beta2[pp]*agrad_2_At3[pp];
		      At_rhs12[pp] = At1[pp]*DENDRO_756 + At2[pp]*DENDRO_722 + At3[pp]*DENDRO_757 - At4[pp]*DENDRO_775 + At5[pp]*DENDRO_723 + DENDRO_1*DENDRO_786 + DENDRO_3*DENDRO_786 + DENDRO_721*(-DENDRO_18*DENDRO_731*(-DENDRO_642 + DENDRO_735) + DENDRO_316*(DENDRO_116*(DENDRO_188*DENDRO_740 + DENDRO_650) + DENDRO_116*(-DENDRO_196*DENDRO_768 + DENDRO_788) + DENDRO_116*(DENDRO_342*DENDRO_742 + DENDRO_788) - DENDRO_116*(DENDRO_504*DENDRO_735 + DENDRO_649 + DENDRO_765*DENDRO_93) + DENDRO_116*(-DENDRO_519*DENDRO_735 + DENDRO_612 - DENDRO_623*DENDRO_735) + DENDRO_153*(DENDRO_733 + DENDRO_736 + DENDRO_774) - DENDRO_154*(DENDRO_139*DENDRO_188 + DENDRO_772 - DENDRO_787) - DENDRO_154*(-DENDRO_161*DENDRO_735 - DENDRO_44*DENDRO_765 + DENDRO_773) + DENDRO_154*(DENDRO_417*DENDRO_768 + DENDRO_766 + DENDRO_787) + DENDRO_160*(-DENDRO_138*DENDRO_391 + DENDRO_789) + DENDRO_160*(-DENDRO_365*DENDRO_740 + DENDRO_655) + DENDRO_160*(-DENDRO_623*DENDRO_742 + DENDRO_789) + DENDRO_160*(-DENDRO_149*DENDRO_272 + DENDRO_652 - 0.25*DENDRO_763) + DENDRO_160*(-DENDRO_295*DENDRO_735 + DENDRO_620 - DENDRO_783) + DENDRO_160*(-DENDRO_417*DENDRO_740 + DENDRO_482 + DENDRO_626) - DENDRO_185*DENDRO_754 - DENDRO_194*DENDRO_752 + DENDRO_270*(DENDRO_594 - DENDRO_644) - DENDRO_270*(-DENDRO_135*DENDRO_735 + DENDRO_346*DENDRO_735 - DENDRO_417*DENDRO_765) - DENDRO_274*(-DENDRO_391*DENDRO_742 + DENDRO_645) - DENDRO_274*(-DENDRO_196*DENDRO_740 - DENDRO_197*DENDRO_740 + DENDRO_427) - DENDRO_274*(-DENDRO_272*DENDRO_735 + DENDRO_599 + DENDRO_646) + DENDRO_283*(DENDRO_117*DENDRO_134 + DENDRO_741) + DENDRO_283*(DENDRO_145 + DENDRO_745 + DENDRO_771) + DENDRO_367*(-DENDRO_174*DENDRO_740 + DENDRO_451) - DENDRO_632*DENDRO_755 + DENDRO_633 + DENDRO_658 - DENDRO_753*DENDRO_98 - DENDRO_91*(DENDRO_178*DENDRO_532 + DENDRO_211*DENDRO_533 + DENDRO_230*DENDRO_531 + DENDRO_631)) + DENDRO_632*DENDRO_719 - 12*DENDRO_635 - DENDRO_730*(-DENDRO_636 + DENDRO_637 + DENDRO_638 - DENDRO_640) + DENDRO_732*(DENDRO_32*(DENDRO_37*DENDRO_632 + DENDRO_565) + DENDRO_641)) - alpha[pp]*(-At4[pp]*K[pp] + DENDRO_19*DENDRO_761 + DENDRO_760*DENDRO_777 + DENDRO_762*DENDRO_778) + beta0[pp]*agrad_0_At4[pp] + beta1[pp]*agrad_1_At4[pp] + beta2[pp]*agrad_2_At4[pp];
		      At_rhs22[pp] = (4.0/3.0)*At5[pp]*DENDRO_3 - At5[pp]*DENDRO_759 - At5[pp]*DENDRO_775 + DENDRO_7*DENDRO_756 + DENDRO_721*(DENDRO_316*(DENDRO_102*DENDRO_138*DENDRO_381 - DENDRO_102*DENDRO_753 - DENDRO_116*(DENDRO_352 - 1.0*DENDRO_354) - DENDRO_116*(0.25*DENDRO_790 + 1.0*DENDRO_791) + DENDRO_149*DENDRO_378 + DENDRO_154*(DENDRO_343 - 1.0*DENDRO_345) + DENDRO_154*(0.25*DENDRO_792 + 1.0*DENDRO_793) - DENDRO_154*(-DENDRO_348*DENDRO_765 + DENDRO_764) - DENDRO_160*(DENDRO_117*DENDRO_742 + DENDRO_767) - DENDRO_160*(DENDRO_138*DENDRO_184 + DENDRO_787) - DENDRO_160*(DENDRO_144*DENDRO_735 + DENDRO_149*DENDRO_365) - DENDRO_160*(DENDRO_49*DENDRO_782 + 0.25*DENDRO_734) + DENDRO_167*(DENDRO_792 + DENDRO_793) + DENDRO_167*(DENDRO_102*DENDRO_149 + DENDRO_47*DENDRO_765) + DENDRO_174*DENDRO_287*DENDRO_742 - DENDRO_174*DENDRO_752 + 6.0*DENDRO_181*DENDRO_269*DENDRO_768 - DENDRO_181*DENDRO_754 - DENDRO_333*DENDRO_755 - DENDRO_367*(DENDRO_790 + DENDRO_791) - DENDRO_367*(DENDRO_102*DENDRO_735 + DENDRO_137*DENDRO_765) + DENDRO_374*(DENDRO_120 + DENDRO_339) + DENDRO_375*(DENDRO_187 + DENDRO_337) + DENDRO_377*DENDRO_735 + DENDRO_398 - DENDRO_91*(DENDRO_189*DENDRO_88 + DENDRO_218*DENDRO_90 + DENDRO_236*DENDRO_87 + DENDRO_336)) - 12*DENDRO_317 + DENDRO_319*DENDRO_57 - DENDRO_68*(DENDRO_328 - DENDRO_329 + DENDRO_330 - DENDRO_334) + DENDRO_720*gt5[pp] - DENDRO_780*(-DENDRO_325 + DENDRO_765)) + DENDRO_757*DENDRO_776 - alpha[pp]*(At5[pp]*DENDRO_26*DENDRO_762 - At5[pp]*K[pp] + DENDRO_30*DENDRO_761 + DENDRO_760*DENDRO_778) + beta0[pp]*agrad_0_At5[pp] + beta1[pp]*agrad_1_At5[pp] + beta2[pp]*agrad_2_At5[pp];
		      // Dendro: reduced ops: 3279
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(At_rhs11, &__unzipOutVar[cuda::VAR::U_SYMAT3][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(At_rhs00, &__unzipOutVar[cuda::VAR::U_SYMAT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(At_rhs01, &__unzipOutVar[cuda::VAR::U_SYMAT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(At_rhs02, &__unzipOutVar[cuda::VAR::U_SYMAT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(At_rhs12, &__unzipOutVar[cuda::VAR::U_SYMAT4][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(At_rhs22, &__unzipOutVar[cuda::VAR::U_SYMAT5][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
/** computes rhs K_rhs*/
__global__ void __compute_K_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={4,4,4};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double K[64];
	__shared__ double gt3[64];
	__shared__ double gt2[64];
	__shared__ double At3[64];
	__shared__ double gt1[64];
	__shared__ double alpha[64];
	__shared__ double At0[64];
	__shared__ double At4[64];
	__shared__ double beta2[64];
	__shared__ double chi[64];
	__shared__ double At2[64];
	__shared__ double beta0[64];
	__shared__ double At1[64];
	__shared__ double gt4[64];
	__shared__ double beta1[64];
	__shared__ double gt5[64];
	__shared__ double At5[64];
	__shared__ double gt0[64];
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	__shared__ double grad_0_alpha[64];
	__shared__ double grad2_2_2_alpha[64];
	__shared__ double grad_0_gt4[64];
	__shared__ double grad2_0_0_alpha[64];
	__shared__ double grad_1_gt2[64];
	__shared__ double grad_2_gt0[64];
	__shared__ double grad_1_gt3[64];
	__shared__ double grad2_0_1_alpha[64];
	__shared__ double grad_0_gt5[64];
	__shared__ double grad_2_gt2[64];
	__shared__ double grad_0_gt2[64];
	__shared__ double grad_2_gt4[64];
	__shared__ double grad_1_alpha[64];
	__shared__ double grad2_1_1_alpha[64];
	__shared__ double grad2_0_2_alpha[64];
	__shared__ double grad_1_gt0[64];
	__shared__ double grad_2_gt3[64];
	__shared__ double grad_0_gt1[64];
	__shared__ double grad_0_gt0[64];
	__shared__ double grad_1_gt4[64];
	__shared__ double grad_2_alpha[64];
	__shared__ double agrad_0_K[64];
	__shared__ double grad_1_gt5[64];
	__shared__ double agrad_1_K[64];
	__shared__ double grad_2_gt1[64];
	__shared__ double grad2_1_2_alpha[64];
	__shared__ double grad_1_gt1[64];
	__shared__ double grad_2_gt5[64];
	__shared__ double agrad_2_K[64];
	__shared__ double grad_2_chi[64];
	__shared__ double grad_0_chi[64];
	__shared__ double grad_1_chi[64];
	__shared__ double grad_0_gt3[64];
	 // deriv vars end
	 // output vars begin
	__shared__ double K_rhs[64];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_K][offset],(double *) K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_alpha[offset]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_alpha[offset]),(double *) grad2_2_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt4[offset]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_alpha[offset]),(double *) grad2_0_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt2[offset]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt0[offset]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt3[offset]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_alpha[offset]),(double *) grad2_0_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt5[offset]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt2[offset]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt2[offset]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt4[offset]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_alpha[offset]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_alpha[offset]),(double *) grad2_1_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_alpha[offset]),(double *) grad2_0_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt0[offset]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt3[offset]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt1[offset]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt0[offset]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt4[offset]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_alpha[offset]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_K[offset]),(double *) agrad_0_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt5[offset]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_K[offset]),(double *) agrad_1_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt1[offset]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_alpha[offset]),(double *) grad2_1_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt1[offset]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt5[offset]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_K[offset]),(double *) agrad_2_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_chi[offset]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_chi[offset]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_chi[offset]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt3[offset]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 3960
		      // Dendro: printing temp variables
		   double 		DENDRO_0 = gt0[pp]*gt3[pp];
		   double 		DENDRO_1 = pow(gt1[pp], 2);
		   double 		DENDRO_2 = DENDRO_0 - DENDRO_1;
		   double 		DENDRO_3 = gt0[pp]*gt4[pp] - gt1[pp]*gt2[pp];
		   double 		DENDRO_4 = 0.5*grad_2_gt5[pp];
		   double 		DENDRO_5 = pow(gt2[pp], 2);
		   double 		DENDRO_6 = gt0[pp]*gt5[pp];
		   double 		DENDRO_7 = DENDRO_5 - DENDRO_6;
		   double 		DENDRO_8 = grad_1_gt5[pp];
		   double 		DENDRO_9 = -0.5*DENDRO_8 + 1.0*grad_2_gt4[pp];
		   double 		DENDRO_10 = gt2[pp]*gt4[pp];
		   double 		DENDRO_11 = -DENDRO_10 + gt1[pp]*gt5[pp];
		   double 		DENDRO_12 = grad_0_gt5[pp];
		   double 		DENDRO_13 = -0.5*DENDRO_12 + 1.0*grad_2_gt2[pp];
		   double 		DENDRO_14 = 1.0/chi[pp];
		   double 		DENDRO_15 = grad_2_chi[pp];
		   double 		DENDRO_16 = grad_1_chi[pp];
		   double 		DENDRO_17 = grad_0_chi[pp];
		   double 		DENDRO_18 = DENDRO_11*DENDRO_17 + DENDRO_15*DENDRO_3 + DENDRO_16*DENDRO_7;
		   double 		DENDRO_19 = DENDRO_14*DENDRO_18;
		   double 		DENDRO_20 = 0.5*gt5[pp];
		   double 		DENDRO_21 = grad_1_alpha[pp];
		   double 		DENDRO_22 = pow(gt4[pp], 2);
		   double 		DENDRO_23 = gt3[pp]*gt5[pp];
		   double 		DENDRO_24 = DENDRO_1*gt5[pp] - 2*DENDRO_10*gt1[pp] + DENDRO_22*gt0[pp] - DENDRO_23*gt0[pp] + DENDRO_5*gt3[pp];
		   double 		DENDRO_25 = 1.0/DENDRO_24;
		   double 		DENDRO_26 = DENDRO_21*DENDRO_25;
		   double 		DENDRO_27 = gt2[pp]*gt3[pp];
		   double 		DENDRO_28 = gt1[pp]*gt4[pp];
		   double 		DENDRO_29 = DENDRO_27 - DENDRO_28;
		   double 		DENDRO_30 = DENDRO_22 - DENDRO_23;
		   double 		DENDRO_31 = DENDRO_11*DENDRO_16 + DENDRO_15*DENDRO_29 + DENDRO_17*DENDRO_30;
		   double 		DENDRO_32 = DENDRO_14*DENDRO_31;
		   double 		DENDRO_33 = grad_0_alpha[pp];
		   double 		DENDRO_34 = DENDRO_25*DENDRO_33;
		   double 		DENDRO_35 = grad_2_alpha[pp];
		   double 		DENDRO_36 = -DENDRO_0 + DENDRO_1;
		   double 		DENDRO_37 = DENDRO_25*DENDRO_36;
		   double 		DENDRO_38 = DENDRO_25*DENDRO_3;
		   double 		DENDRO_39 = DENDRO_25*DENDRO_29;
		   double 		DENDRO_40 = DENDRO_15*DENDRO_36 + DENDRO_16*DENDRO_3 + DENDRO_17*DENDRO_29;
		   double 		DENDRO_41 = DENDRO_25*chi[pp];
		   double 		DENDRO_42 = -DENDRO_5 + DENDRO_6;
		   double 		DENDRO_43 = 0.5*grad_1_gt3[pp];
		   double 		DENDRO_44 = grad_2_gt3[pp];
		   double 		DENDRO_45 = -0.5*DENDRO_44 + 1.0*grad_1_gt4[pp];
		   double 		DENDRO_46 = grad_0_gt3[pp];
		   double 		DENDRO_47 = -0.5*DENDRO_46 + 1.0*grad_1_gt1[pp];
		   double 		DENDRO_48 = DENDRO_14*DENDRO_40;
		   double 		DENDRO_49 = 0.5*gt3[pp];
		   double 		DENDRO_50 = DENDRO_25*DENDRO_35;
		   double 		DENDRO_51 = DENDRO_25*DENDRO_7;
		   double 		DENDRO_52 = DENDRO_11*DENDRO_25;
		   double 		DENDRO_53 = -DENDRO_22 + DENDRO_23;
		   double 		DENDRO_54 = 0.5*grad_0_gt0[pp];
		   double 		DENDRO_55 = grad_2_gt0[pp];
		   double 		DENDRO_56 = -0.5*DENDRO_55 + 1.0*grad_0_gt2[pp];
		   double 		DENDRO_57 = grad_1_gt0[pp];
		   double 		DENDRO_58 = -0.5*DENDRO_57 + 1.0*grad_0_gt1[pp];
		   double 		DENDRO_59 = 0.5*gt0[pp];
		   double 		DENDRO_60 = DENDRO_25*DENDRO_30;
		   double 		DENDRO_61 = grad_1_gt2[pp];
		   double 		DENDRO_62 = grad_2_gt1[pp];
		   double 		DENDRO_63 = grad_0_gt4[pp];
		   double 		DENDRO_64 = DENDRO_61 + DENDRO_62 - DENDRO_63;
		   double 		DENDRO_65 = DENDRO_25*gt4[pp];
		   double 		DENDRO_66 = 0.5*DENDRO_35;
		   double 		DENDRO_67 = 0.5*DENDRO_21;
		   double 		DENDRO_68 = 2*chi[pp];
		   double 		DENDRO_69 = -DENDRO_61 + DENDRO_62 + DENDRO_63;
		   double 		DENDRO_70 = DENDRO_25*gt2[pp];
		   double 		DENDRO_71 = 0.5*DENDRO_33;
		   double 		DENDRO_72 = -DENDRO_27 + DENDRO_28;
		   double 		DENDRO_73 = 2*DENDRO_72;
		   double 		DENDRO_74 = DENDRO_61 - DENDRO_62 + DENDRO_63;
		   double 		DENDRO_75 = DENDRO_25*gt1[pp];
		   double 		DENDRO_76 = pow(DENDRO_11, 2);
		   double 		DENDRO_77 = pow(DENDRO_72, 2);
		   double 		DENDRO_78 = At4[pp]*DENDRO_72;
		   double 		DENDRO_79 = 2*DENDRO_11;
		   double 		DENDRO_80 = At1[pp]*DENDRO_53;
		   double 		DENDRO_81 = At2[pp]*DENDRO_53;
		   double 		DENDRO_82 = pow(DENDRO_24, -2);
		   double 		DENDRO_83 = 3*DENDRO_82;
		   double 		DENDRO_84 = pow(DENDRO_3, 2);
		   double 		DENDRO_85 = DENDRO_11*DENDRO_3;
		   double 		DENDRO_86 = At1[pp]*DENDRO_42;
		   double 		DENDRO_87 = 2*DENDRO_3;
		   double 		DENDRO_88 = DENDRO_3*DENDRO_72;
		   double 		DENDRO_89 = At2[pp]*DENDRO_2;
		   double 		DENDRO_90 = At4[pp]*DENDRO_2;
		   double 		DENDRO_91 = At0[pp]*DENDRO_53;
		   double 		DENDRO_92 = DENDRO_11*DENDRO_72;
		   double 		DENDRO_93 = At5[pp]*DENDRO_72;
		   double 		DENDRO_94 = 6*DENDRO_82;
		   double 		DENDRO_95 = At3[pp]*DENDRO_42;
		      // Dendro: printing variables

		      K_rhs[pp] = -DENDRO_2*DENDRO_41*(DENDRO_26*(DENDRO_11*DENDRO_13 + DENDRO_19*DENDRO_20 + DENDRO_3*DENDRO_4 + DENDRO_7*DENDRO_9) + DENDRO_34*(DENDRO_11*DENDRO_9 + DENDRO_13*DENDRO_30 + DENDRO_20*DENDRO_32 + DENDRO_29*DENDRO_4) + DENDRO_35*(DENDRO_13*DENDRO_39 - DENDRO_14*(1.0*DENDRO_15 - DENDRO_20*DENDRO_25*DENDRO_40) + DENDRO_37*DENDRO_4 + DENDRO_38*DENDRO_9) - grad2_2_2_alpha[pp]) + DENDRO_38*DENDRO_68*(0.5*DENDRO_34*(DENDRO_11*DENDRO_44 + DENDRO_29*DENDRO_8 + DENDRO_30*DENDRO_64 + DENDRO_32*gt4[pp]) + DENDRO_66*(-DENDRO_14*(DENDRO_16 - DENDRO_40*DENDRO_65) + DENDRO_37*DENDRO_8 + DENDRO_38*DENDRO_44 + DENDRO_39*DENDRO_64) + DENDRO_67*(-DENDRO_14*(DENDRO_15 - DENDRO_18*DENDRO_65) + DENDRO_38*DENDRO_8 + DENDRO_44*DENDRO_51 + DENDRO_52*DENDRO_64) - grad2_1_2_alpha[pp]) - DENDRO_41*DENDRO_42*(DENDRO_21*(-DENDRO_14*(1.0*DENDRO_16 - DENDRO_18*DENDRO_25*DENDRO_49) + DENDRO_38*DENDRO_45 + DENDRO_43*DENDRO_51 + DENDRO_47*DENDRO_52) + DENDRO_34*(DENDRO_11*DENDRO_43 + DENDRO_29*DENDRO_45 + DENDRO_30*DENDRO_47 + DENDRO_32*DENDRO_49) + DENDRO_50*(DENDRO_29*DENDRO_47 + DENDRO_3*DENDRO_43 + DENDRO_36*DENDRO_45 + DENDRO_48*DENDRO_49) - grad2_1_1_alpha[pp]) - DENDRO_41*DENDRO_53*(DENDRO_26*(DENDRO_11*DENDRO_54 + DENDRO_19*DENDRO_59 + DENDRO_3*DENDRO_56 + DENDRO_58*DENDRO_7) + DENDRO_33*(-DENDRO_14*(1.0*DENDRO_17 - DENDRO_25*DENDRO_31*DENDRO_59) + DENDRO_39*DENDRO_56 + DENDRO_52*DENDRO_58 + DENDRO_54*DENDRO_60) + DENDRO_50*(DENDRO_29*DENDRO_54 + DENDRO_3*DENDRO_58 + DENDRO_36*DENDRO_56 + DENDRO_48*DENDRO_59) - grad2_0_0_alpha[pp]) - DENDRO_41*DENDRO_73*(0.5*DENDRO_26*(DENDRO_11*DENDRO_55 + DENDRO_12*DENDRO_3 + DENDRO_19*gt2[pp] + DENDRO_69*DENDRO_7) + DENDRO_66*(DENDRO_12*DENDRO_37 - DENDRO_14*(DENDRO_17 - DENDRO_40*DENDRO_70) + DENDRO_38*DENDRO_69 + DENDRO_39*DENDRO_55) + DENDRO_71*(DENDRO_12*DENDRO_39 - DENDRO_14*(DENDRO_15 - DENDRO_31*DENDRO_70) + DENDRO_52*DENDRO_69 + DENDRO_55*DENDRO_60) - grad2_0_2_alpha[pp]) + DENDRO_52*DENDRO_68*(0.5*DENDRO_50*(DENDRO_29*DENDRO_57 + DENDRO_3*DENDRO_46 + DENDRO_36*DENDRO_74 + DENDRO_48*gt1[pp]) + DENDRO_67*(-DENDRO_14*(DENDRO_17 - DENDRO_18*DENDRO_75) + DENDRO_38*DENDRO_74 + DENDRO_46*DENDRO_51 + DENDRO_52*DENDRO_57) + DENDRO_71*(-DENDRO_14*(DENDRO_16 - DENDRO_31*DENDRO_75) + DENDRO_39*DENDRO_74 + DENDRO_46*DENDRO_52 + DENDRO_57*DENDRO_60) - grad2_0_1_alpha[pp]) + (1.0/3.0)*alpha[pp]*(At0[pp]*DENDRO_83*(At0[pp]*pow(DENDRO_53, 2) + At3[pp]*DENDRO_76 + At5[pp]*DENDRO_77 + DENDRO_73*DENDRO_81 - DENDRO_78*DENDRO_79 - DENDRO_79*DENDRO_80) + At1[pp]*DENDRO_94*(At1[pp]*DENDRO_76 - At2[pp]*DENDRO_92 + At4[pp]*DENDRO_85 - DENDRO_11*DENDRO_91 - DENDRO_11*DENDRO_95 - DENDRO_3*DENDRO_81 - DENDRO_3*DENDRO_93 + DENDRO_42*DENDRO_78 + DENDRO_42*DENDRO_80) + At2[pp]*DENDRO_94*(-At1[pp]*DENDRO_92 + At2[pp]*DENDRO_77 + At3[pp]*DENDRO_85 - DENDRO_11*DENDRO_90 + DENDRO_2*DENDRO_81 + DENDRO_2*DENDRO_93 - DENDRO_3*DENDRO_78 - DENDRO_3*DENDRO_80 + DENDRO_72*DENDRO_91) + At3[pp]*DENDRO_83*(At0[pp]*DENDRO_76 + 2*At2[pp]*DENDRO_85 + At3[pp]*pow(DENDRO_42, 2) - At4[pp]*DENDRO_42*DENDRO_87 + At5[pp]*DENDRO_84 - DENDRO_79*DENDRO_86) + At4[pp]*DENDRO_94*(-At0[pp]*DENDRO_92 + At1[pp]*DENDRO_85 - At2[pp]*DENDRO_88 + At4[pp]*DENDRO_84 - At5[pp]*DENDRO_2*DENDRO_3 - DENDRO_11*DENDRO_89 - DENDRO_3*DENDRO_95 + DENDRO_42*DENDRO_90 + DENDRO_72*DENDRO_86) + At5[pp]*DENDRO_83*(At0[pp]*DENDRO_77 - 2*At1[pp]*DENDRO_88 + At3[pp]*DENDRO_84 + At5[pp]*pow(DENDRO_2, 2) + DENDRO_73*DENDRO_89 - DENDRO_87*DENDRO_90) + pow(K[pp], 2)) + beta0[pp]*agrad_0_K[pp] + beta1[pp]*agrad_1_K[pp] + beta2[pp]*agrad_2_K[pp];
		      // Dendro: reduced ops: 479
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(K_rhs, &__unzipOutVar[cuda::VAR::U_K][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
/** computes rhs Gt_rhs*/
__global__ void __compute_Gt_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={3,3,3};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double gt3[27];
	__shared__ double gt2[27];
	__shared__ double At3[27];
	__shared__ double gt1[27];
	__shared__ double alpha[27];
	__shared__ double At0[27];
	__shared__ double At4[27];
	__shared__ double chi[27];
	__shared__ double beta2[27];
	__shared__ double At2[27];
	__shared__ double beta0[27];
	__shared__ double At1[27];
	__shared__ double gt4[27];
	__shared__ double beta1[27];
	__shared__ double gt5[27];
	__shared__ double At5[27];
	__shared__ double gt0[27];
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	__shared__ double agrad_1_Gt1[27];
	__shared__ double grad2_0_2_beta1[27];
	__shared__ double grad_0_alpha[27];
	__shared__ double agrad_2_Gt0[27];
	__shared__ double agrad_0_Gt1[27];
	__shared__ double agrad_1_Gt2[27];
	__shared__ double grad_0_gt4[27];
	__shared__ double grad_1_beta2[27];
	__shared__ double grad_1_gt2[27];
	__shared__ double grad_0_gt2[27];
	__shared__ double grad_2_gt0[27];
	__shared__ double grad_1_gt3[27];
	__shared__ double grad_0_gt5[27];
	__shared__ double grad_2_gt2[27];
	__shared__ double grad2_0_1_beta1[27];
	__shared__ double agrad_1_Gt0[27];
	__shared__ double grad2_1_1_beta2[27];
	__shared__ double grad_0_beta2[27];
	__shared__ double agrad_0_Gt0[27];
	__shared__ double grad_2_gt4[27];
	__shared__ double grad_2_beta0[27];
	__shared__ double grad2_0_0_beta0[27];
	__shared__ double grad_1_alpha[27];
	__shared__ double grad_1_gt0[27];
	__shared__ double grad_2_gt3[27];
	__shared__ double grad2_2_2_beta1[27];
	__shared__ double grad2_0_0_beta1[27];
	__shared__ double grad_0_K[27];
	__shared__ double grad_1_beta1[27];
	__shared__ double grad_0_gt1[27];
	__shared__ double grad2_0_0_beta2[27];
	__shared__ double grad_0_gt0[27];
	__shared__ double grad2_1_2_beta2[27];
	__shared__ double grad_1_gt4[27];
	__shared__ double grad_0_beta0[27];
	__shared__ double grad2_1_2_beta0[27];
	__shared__ double grad_1_K[27];
	__shared__ double grad_2_beta2[27];
	__shared__ double grad_1_beta0[27];
	__shared__ double grad_2_alpha[27];
	__shared__ double grad2_2_2_beta0[27];
	__shared__ double grad_1_gt5[27];
	__shared__ double grad2_1_1_beta1[27];
	__shared__ double grad_2_gt1[27];
	__shared__ double agrad_0_Gt2[27];
	__shared__ double grad2_0_1_beta0[27];
	__shared__ double grad_1_gt1[27];
	__shared__ double grad_2_gt5[27];
	__shared__ double grad2_1_1_beta0[27];
	__shared__ double grad2_0_1_beta2[27];
	__shared__ double grad2_0_2_beta2[27];
	__shared__ double grad_2_chi[27];
	__shared__ double grad_0_chi[27];
	__shared__ double grad_0_beta1[27];
	__shared__ double grad_1_chi[27];
	__shared__ double grad2_1_2_beta1[27];
	__shared__ double grad2_0_2_beta0[27];
	__shared__ double agrad_2_Gt2[27];
	__shared__ double grad_2_beta1[27];
	__shared__ double grad_0_gt3[27];
	__shared__ double grad_2_K[27];
	__shared__ double agrad_2_Gt1[27];
	__shared__ double grad2_2_2_beta2[27];
	 // deriv vars end
	 // output vars begin
	__shared__ double Gt_rhs2[27];
	__shared__ double Gt_rhs1[27];
	__shared__ double Gt_rhs0[27];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_Gt1[offset]),(double *) agrad_1_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_beta1[offset]),(double *) grad2_0_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_alpha[offset]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_Gt0[offset]),(double *) agrad_2_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_Gt1[offset]),(double *) agrad_0_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_Gt2[offset]),(double *) agrad_1_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt4[offset]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta2[offset]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt2[offset]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt2[offset]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt0[offset]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt3[offset]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt5[offset]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt2[offset]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_beta1[offset]),(double *) grad2_0_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_Gt0[offset]),(double *) agrad_1_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_beta2[offset]),(double *) grad2_1_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta2[offset]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_Gt0[offset]),(double *) agrad_0_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt4[offset]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta0[offset]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_beta0[offset]),(double *) grad2_0_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_alpha[offset]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt0[offset]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt3[offset]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_beta1[offset]),(double *) grad2_2_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_beta1[offset]),(double *) grad2_0_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_K[offset]),(double *) grad_0_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta1[offset]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt1[offset]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_beta2[offset]),(double *) grad2_0_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt0[offset]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_beta2[offset]),(double *) grad2_1_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt4[offset]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta0[offset]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_beta0[offset]),(double *) grad2_1_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_K[offset]),(double *) grad_1_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta2[offset]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta0[offset]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_alpha[offset]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_beta0[offset]),(double *) grad2_2_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt5[offset]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_beta1[offset]),(double *) grad2_1_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt1[offset]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_Gt2[offset]),(double *) agrad_0_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_beta0[offset]),(double *) grad2_0_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt1[offset]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt5[offset]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_beta0[offset]),(double *) grad2_1_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_beta2[offset]),(double *) grad2_0_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_beta2[offset]),(double *) grad2_0_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_chi[offset]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_chi[offset]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta1[offset]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_chi[offset]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_beta1[offset]),(double *) grad2_1_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_beta0[offset]),(double *) grad2_0_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_Gt2[offset]),(double *) agrad_2_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta1[offset]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt3[offset]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_K[offset]),(double *) grad_2_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_Gt1[offset]),(double *) agrad_2_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_beta2[offset]),(double *) grad2_2_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 16710
		      // Dendro: printing temp variables
		   double 		DENDRO_0 = pow(gt4[pp], 2);
		   double 		DENDRO_1 = pow(gt1[pp], 2);
		   double 		DENDRO_2 = pow(gt2[pp], 2);
		   double 		DENDRO_3 = gt0[pp]*gt3[pp];
		   double 		DENDRO_4 = gt1[pp]*gt2[pp];
		   double 		DENDRO_5 = DENDRO_0*gt0[pp] + DENDRO_1*gt5[pp] + DENDRO_2*gt3[pp] - DENDRO_3*gt5[pp] - 2*DENDRO_4*gt4[pp];
		   double 		DENDRO_6 = 1.0/DENDRO_5;
		   double 		DENDRO_7 = -DENDRO_4 + gt0[pp]*gt4[pp];
		   double 		DENDRO_8 = 2*DENDRO_7;
		   double 		DENDRO_9 = grad2_0_2_beta0[pp];
		   double 		DENDRO_10 = gt1[pp]*gt4[pp] - gt2[pp]*gt3[pp];
		   double 		DENDRO_11 = DENDRO_10*DENDRO_6;
		   double 		DENDRO_12 = (7.0/3.0)*DENDRO_11;
		   double 		DENDRO_13 = grad2_1_2_beta1[pp];
		   double 		DENDRO_14 = (1.0/3.0)*DENDRO_11;
		   double 		DENDRO_15 = grad2_2_2_beta2[pp];
		   double 		DENDRO_16 = grad2_0_1_beta0[pp];
		   double 		DENDRO_17 = gt1[pp]*gt5[pp] - gt2[pp]*gt4[pp];
		   double 		DENDRO_18 = (7.0/3.0)*DENDRO_6;
		   double 		DENDRO_19 = DENDRO_17*DENDRO_18;
		   double 		DENDRO_20 = grad2_1_1_beta1[pp];
		   double 		DENDRO_21 = (1.0/3.0)*DENDRO_6;
		   double 		DENDRO_22 = DENDRO_17*DENDRO_21;
		   double 		DENDRO_23 = grad2_1_2_beta2[pp];
		   double 		DENDRO_24 = -DENDRO_1 + DENDRO_3;
		   double 		DENDRO_25 = DENDRO_24*DENDRO_6;
		   double 		DENDRO_26 = -DENDRO_2 + gt0[pp]*gt5[pp];
		   double 		DENDRO_27 = DENDRO_26*DENDRO_6;
		   double 		DENDRO_28 = grad2_0_0_beta0[pp];
		   double 		DENDRO_29 = -DENDRO_0 + gt3[pp]*gt5[pp];
		   double 		DENDRO_30 = DENDRO_29*DENDRO_6;
		   double 		DENDRO_31 = grad2_0_1_beta1[pp];
		   double 		DENDRO_32 = (1.0/3.0)*DENDRO_30;
		   double 		DENDRO_33 = grad2_0_2_beta2[pp];
		   double 		DENDRO_34 = pow(DENDRO_17, 2);
		   double 		DENDRO_35 = pow(DENDRO_10, 2);
		   double 		DENDRO_36 = At4[pp]*DENDRO_10;
		   double 		DENDRO_37 = 2*DENDRO_17;
		   double 		DENDRO_38 = At1[pp]*DENDRO_29;
		   double 		DENDRO_39 = At2[pp]*DENDRO_29;
		   double 		DENDRO_40 = 2*DENDRO_10;
		   double 		DENDRO_41 = At0[pp]*pow(DENDRO_29, 2) + At3[pp]*DENDRO_34 + At5[pp]*DENDRO_35 - DENDRO_36*DENDRO_37 - DENDRO_37*DENDRO_38 + DENDRO_39*DENDRO_40;
		   double 		DENDRO_42 = pow(DENDRO_5, -2);
		   double 		DENDRO_43 = 2*DENDRO_42;
		   double 		DENDRO_44 = DENDRO_43*grad_0_alpha[pp];
		   double 		DENDRO_45 = 4*grad_0_K[pp];
		   double 		DENDRO_46 = 9*DENDRO_6/chi[pp];
		   double 		DENDRO_47 = DENDRO_46*grad_0_chi[pp];
		   double 		DENDRO_48 = DENDRO_21*alpha[pp];
		   double 		DENDRO_49 = 0.5*grad_0_gt0[pp];
		   double 		DENDRO_50 = grad_1_gt0[pp];
		   double 		DENDRO_51 = -0.5*DENDRO_50 + 1.0*grad_0_gt1[pp];
		   double 		DENDRO_52 = grad_2_gt0[pp];
		   double 		DENDRO_53 = -0.5*DENDRO_52 + 1.0*grad_0_gt2[pp];
		   double 		DENDRO_54 = -DENDRO_10*DENDRO_53 + DENDRO_17*DENDRO_51 - DENDRO_29*DENDRO_49;
		   double 		DENDRO_55 = alpha[pp]/pow(DENDRO_5, 3);
		   double 		DENDRO_56 = 2*DENDRO_55;
		   double 		DENDRO_57 = DENDRO_41*DENDRO_56;
		   double 		DENDRO_58 = 0.5*grad_1_gt3[pp];
		   double 		DENDRO_59 = grad_2_gt3[pp];
		   double 		DENDRO_60 = -0.5*DENDRO_59 + 1.0*grad_1_gt4[pp];
		   double 		DENDRO_61 = grad_0_gt3[pp];
		   double 		DENDRO_62 = 0.5*DENDRO_61 - 1.0*grad_1_gt1[pp];
		   double 		DENDRO_63 = -DENDRO_10*DENDRO_60 + DENDRO_17*DENDRO_58 + DENDRO_29*DENDRO_62;
		   double 		DENDRO_64 = pow(DENDRO_7, 2);
		   double 		DENDRO_65 = DENDRO_17*DENDRO_7;
		   double 		DENDRO_66 = At1[pp]*DENDRO_26;
		   double 		DENDRO_67 = At0[pp]*DENDRO_34 + 2*At2[pp]*DENDRO_65 + At3[pp]*pow(DENDRO_26, 2) - At4[pp]*DENDRO_26*DENDRO_8 + At5[pp]*DENDRO_64 - DENDRO_37*DENDRO_66;
		   double 		DENDRO_68 = DENDRO_56*DENDRO_67;
		   double 		DENDRO_69 = 0.5*grad_2_gt5[pp];
		   double 		DENDRO_70 = grad_1_gt5[pp];
		   double 		DENDRO_71 = 0.5*DENDRO_70 - 1.0*grad_2_gt4[pp];
		   double 		DENDRO_72 = grad_0_gt5[pp];
		   double 		DENDRO_73 = 0.5*DENDRO_72 - 1.0*grad_2_gt2[pp];
		   double 		DENDRO_74 = -DENDRO_10*DENDRO_69 - DENDRO_17*DENDRO_71 + DENDRO_29*DENDRO_73;
		   double 		DENDRO_75 = DENDRO_10*DENDRO_7;
		   double 		DENDRO_76 = At2[pp]*DENDRO_24;
		   double 		DENDRO_77 = At4[pp]*DENDRO_24;
		   double 		DENDRO_78 = At0[pp]*DENDRO_35 - 2*At1[pp]*DENDRO_75 + At3[pp]*DENDRO_64 + At5[pp]*pow(DENDRO_24, 2) + DENDRO_40*DENDRO_76 - DENDRO_77*DENDRO_8;
		   double 		DENDRO_79 = DENDRO_56*DENDRO_78;
		   double 		DENDRO_80 = At0[pp]*DENDRO_29;
		   double 		DENDRO_81 = DENDRO_10*DENDRO_17;
		   double 		DENDRO_82 = At5[pp]*DENDRO_10;
		   double 		DENDRO_83 = -At1[pp]*DENDRO_81 + At2[pp]*DENDRO_35 + At3[pp]*DENDRO_65 + DENDRO_10*DENDRO_80 - DENDRO_17*DENDRO_77 + DENDRO_24*DENDRO_39 + DENDRO_24*DENDRO_82 - DENDRO_36*DENDRO_7 - DENDRO_38*DENDRO_7;
		   double 		DENDRO_84 = DENDRO_43*grad_2_alpha[pp];
		   double 		DENDRO_85 = At1[pp]*DENDRO_34;
		   double 		DENDRO_86 = At4[pp]*DENDRO_65;
		   double 		DENDRO_87 = At2[pp]*DENDRO_81;
		   double 		DENDRO_88 = DENDRO_26*DENDRO_36;
		   double 		DENDRO_89 = DENDRO_7*DENDRO_82;
		   double 		DENDRO_90 = DENDRO_17*DENDRO_80;
		   double 		DENDRO_91 = DENDRO_26*DENDRO_38;
		   double 		DENDRO_92 = DENDRO_39*DENDRO_7;
		   double 		DENDRO_93 = At3[pp]*DENDRO_26;
		   double 		DENDRO_94 = DENDRO_17*DENDRO_93;
		   double 		DENDRO_95 = DENDRO_85 + DENDRO_86 - DENDRO_87 + DENDRO_88 - DENDRO_89 - DENDRO_90 + DENDRO_91 - DENDRO_92 - DENDRO_94;
		   double 		DENDRO_96 = DENDRO_43*grad_1_alpha[pp];
		   double 		DENDRO_97 = grad_0_gt4[pp];
		   double 		DENDRO_98 = grad_2_gt1[pp];
		   double 		DENDRO_99 = grad_1_gt2[pp];
		   double 		DENDRO_100 = DENDRO_97 + DENDRO_98 - DENDRO_99;
		   double 		DENDRO_101 = -DENDRO_10*DENDRO_72 + DENDRO_100*DENDRO_17 - DENDRO_29*DENDRO_52;
		   double 		DENDRO_102 = 2.0*DENDRO_55;
		   double 		DENDRO_103 = DENDRO_102*DENDRO_83;
		   double 		DENDRO_104 = 4*grad_2_K[pp];
		   double 		DENDRO_105 = DENDRO_46*grad_2_chi[pp];
		   double 		DENDRO_106 = DENDRO_97 - DENDRO_98 + DENDRO_99;
		   double 		DENDRO_107 = -DENDRO_10*DENDRO_106 + DENDRO_17*DENDRO_61 - DENDRO_29*DENDRO_50;
		   double 		DENDRO_108 = DENDRO_102*DENDRO_95;
		   double 		DENDRO_109 = -DENDRO_97 + DENDRO_98 + DENDRO_99;
		   double 		DENDRO_110 = -DENDRO_10*DENDRO_70 - DENDRO_109*DENDRO_29 + DENDRO_17*DENDRO_59;
		   double 		DENDRO_111 = At4[pp]*DENDRO_64;
		   double 		DENDRO_112 = At1[pp]*DENDRO_65;
		   double 		DENDRO_113 = At0[pp]*DENDRO_81;
		   double 		DENDRO_114 = DENDRO_10*DENDRO_66;
		   double 		DENDRO_115 = At2[pp]*DENDRO_75;
		   double 		DENDRO_116 = DENDRO_17*DENDRO_76;
		   double 		DENDRO_117 = DENDRO_7*DENDRO_93;
		   double 		DENDRO_118 = DENDRO_26*DENDRO_77;
		   double 		DENDRO_119 = At5[pp]*DENDRO_24*DENDRO_7;
		   double 		DENDRO_120 = DENDRO_111 + DENDRO_112 - DENDRO_113 + DENDRO_114 - DENDRO_115 - DENDRO_116 - DENDRO_117 + DENDRO_118 - DENDRO_119;
		   double 		DENDRO_121 = DENDRO_102*DENDRO_120;
		   double 		DENDRO_122 = 4*grad_1_K[pp];
		   double 		DENDRO_123 = DENDRO_46*grad_1_chi[pp];
		   double 		DENDRO_124 = DENDRO_109*DENDRO_17 - DENDRO_26*DENDRO_59 + DENDRO_7*DENDRO_70;
		   double 		DENDRO_125 = DENDRO_124*DENDRO_7;
		   double 		DENDRO_126 = DENDRO_106*DENDRO_7 + DENDRO_17*DENDRO_50 - DENDRO_26*DENDRO_61;
		   double 		DENDRO_127 = DENDRO_126*DENDRO_17;
		   double 		DENDRO_128 = -DENDRO_100*DENDRO_26 + DENDRO_17*DENDRO_52 + DENDRO_7*DENDRO_72;
		   double 		DENDRO_129 = DENDRO_10*DENDRO_128;
		   double 		DENDRO_130 = -DENDRO_17*DENDRO_73 + DENDRO_26*DENDRO_71 + DENDRO_69*DENDRO_7;
		   double 		DENDRO_131 = DENDRO_130*DENDRO_24;
		   double 		DENDRO_132 = DENDRO_26*DENDRO_58;
		   double 		DENDRO_133 = DENDRO_60*DENDRO_7;
		   double 		DENDRO_134 = DENDRO_17*DENDRO_62;
		   double 		DENDRO_135 = DENDRO_26*(-DENDRO_132 + DENDRO_133 - DENDRO_134);
		   double 		DENDRO_136 = DENDRO_17*DENDRO_49 - DENDRO_26*DENDRO_51 + DENDRO_53*DENDRO_7;
		   double 		DENDRO_137 = DENDRO_136*DENDRO_29;
		   double 		DENDRO_138 = DENDRO_42*(DENDRO_125 + DENDRO_127 - 1.0*DENDRO_129 - DENDRO_131 - DENDRO_135 - DENDRO_137);
		   double 		DENDRO_139 = -DENDRO_10*DENDRO_109 - DENDRO_24*DENDRO_70 + DENDRO_59*DENDRO_7;
		   double 		DENDRO_140 = DENDRO_139*DENDRO_7;
		   double 		DENDRO_141 = -DENDRO_10*DENDRO_50 - DENDRO_106*DENDRO_24 + DENDRO_61*DENDRO_7;
		   double 		DENDRO_142 = DENDRO_141*DENDRO_17;
		   double 		DENDRO_143 = -DENDRO_10*DENDRO_52 + DENDRO_100*DENDRO_7 - DENDRO_24*DENDRO_72;
		   double 		DENDRO_144 = DENDRO_10*DENDRO_143;
		   double 		DENDRO_145 = DENDRO_10*DENDRO_73 - DENDRO_24*DENDRO_69 - DENDRO_7*DENDRO_71;
		   double 		DENDRO_146 = DENDRO_145*DENDRO_24;
		   double 		DENDRO_147 = DENDRO_10*DENDRO_62 - DENDRO_24*DENDRO_60 + DENDRO_58*DENDRO_7;
		   double 		DENDRO_148 = DENDRO_147*DENDRO_26;
		   double 		DENDRO_149 = -DENDRO_10*DENDRO_49 - DENDRO_24*DENDRO_53 + DENDRO_51*DENDRO_7;
		   double 		DENDRO_150 = DENDRO_149*DENDRO_29;
		   double 		DENDRO_151 = DENDRO_42*(DENDRO_140 + DENDRO_142 - 1.0*DENDRO_144 - DENDRO_146 - DENDRO_148 - DENDRO_150);
		   double 		DENDRO_152 = grad_0_beta0[pp];
		   double 		DENDRO_153 = DENDRO_110*DENDRO_7;
		   double 		DENDRO_154 = DENDRO_107*DENDRO_17;
		   double 		DENDRO_155 = DENDRO_10*DENDRO_101;
		   double 		DENDRO_156 = DENDRO_24*DENDRO_74;
		   double 		DENDRO_157 = DENDRO_26*DENDRO_63;
		   double 		DENDRO_158 = DENDRO_29*DENDRO_54;
		   double 		DENDRO_159 = DENDRO_42*(DENDRO_153 + DENDRO_154 - 1.0*DENDRO_155 - DENDRO_156 - DENDRO_157 - DENDRO_158);
		   double 		DENDRO_160 = grad_1_beta1[pp];
		   double 		DENDRO_161 = grad_2_beta2[pp];
		   double 		DENDRO_162 = (2.0/3.0)*DENDRO_152 + (2.0/3.0)*DENDRO_160 + (2.0/3.0)*DENDRO_161;
		   double 		DENDRO_163 = DENDRO_21*DENDRO_7;
		   double 		DENDRO_164 = DENDRO_18*DENDRO_7;
		   double 		DENDRO_165 = (1.0/3.0)*DENDRO_27;
		   double 		DENDRO_166 = -DENDRO_111 - DENDRO_112 + DENDRO_113 - DENDRO_114 + DENDRO_115 + DENDRO_116 + DENDRO_117 - DENDRO_118 + DENDRO_119;
		   double 		DENDRO_167 = -DENDRO_85 - DENDRO_86 + DENDRO_87 - DENDRO_88 + DENDRO_89 + DENDRO_90 - DENDRO_91 + DENDRO_92 + DENDRO_94;
		   double 		DENDRO_168 = DENDRO_42*(-1.0*DENDRO_125 - 1.0*DENDRO_127 + DENDRO_129 + DENDRO_131 + DENDRO_135 + DENDRO_137);
		   double 		DENDRO_169 = (1.0/3.0)*DENDRO_25;
		      // Dendro: printing variables

		      Gt_rhs0[pp] = DENDRO_101*DENDRO_103 + DENDRO_107*DENDRO_108 + DENDRO_110*DENDRO_121 - DENDRO_12*DENDRO_9 - DENDRO_13*DENDRO_14 - DENDRO_138*grad_1_beta0[pp] - DENDRO_14*DENDRO_15 - DENDRO_151*grad_2_beta0[pp] - DENDRO_152*DENDRO_159 + DENDRO_159*DENDRO_162 + DENDRO_16*DENDRO_19 + DENDRO_20*DENDRO_22 + DENDRO_22*DENDRO_23 - DENDRO_25*grad2_2_2_beta0[pp] - DENDRO_27*grad2_1_1_beta0[pp] - 4.0/3.0*DENDRO_28*DENDRO_30 - DENDRO_31*DENDRO_32 - DENDRO_32*DENDRO_33 - DENDRO_41*DENDRO_44 - DENDRO_48*(-DENDRO_10*DENDRO_104 + DENDRO_105*DENDRO_83) - DENDRO_48*(DENDRO_122*DENDRO_17 + DENDRO_123*DENDRO_95) - DENDRO_48*(-DENDRO_29*DENDRO_45 + DENDRO_41*DENDRO_47) + DENDRO_54*DENDRO_57 + DENDRO_6*DENDRO_8*grad2_1_2_beta0[pp] + DENDRO_63*DENDRO_68 + DENDRO_74*DENDRO_79 - DENDRO_83*DENDRO_84 - DENDRO_95*DENDRO_96 + beta0[pp]*agrad_0_Gt0[pp] + beta1[pp]*agrad_1_Gt0[pp] + beta2[pp]*agrad_2_Gt0[pp];
		      Gt_rhs1[pp] = -DENDRO_102*DENDRO_124*DENDRO_166 - DENDRO_102*DENDRO_126*DENDRO_167 + DENDRO_103*DENDRO_128 + DENDRO_13*DENDRO_164 + DENDRO_130*DENDRO_79 + DENDRO_136*DENDRO_57 + DENDRO_15*DENDRO_163 - DENDRO_16*DENDRO_165 + DENDRO_160*DENDRO_168 - DENDRO_162*DENDRO_168 + DENDRO_163*DENDRO_9 - DENDRO_165*DENDRO_23 + DENDRO_166*DENDRO_84 + DENDRO_167*DENDRO_44 + DENDRO_19*DENDRO_31 - 4.0/3.0*DENDRO_20*DENDRO_27 + DENDRO_22*DENDRO_28 + DENDRO_22*DENDRO_33 - DENDRO_25*grad2_2_2_beta1[pp] - DENDRO_30*grad2_0_0_beta1[pp] - DENDRO_40*DENDRO_6*grad2_0_2_beta1[pp] + DENDRO_42*(-1.0*DENDRO_140 - 1.0*DENDRO_142 + DENDRO_144 + DENDRO_146 + DENDRO_148 + DENDRO_150)*grad_2_beta1[pp] + DENDRO_42*(-1.0*DENDRO_153 - 1.0*DENDRO_154 + DENDRO_155 + DENDRO_156 + DENDRO_157 + DENDRO_158)*grad_0_beta1[pp] - DENDRO_48*(DENDRO_104*DENDRO_7 - DENDRO_105*DENDRO_166) + DENDRO_48*(DENDRO_122*DENDRO_26 - DENDRO_123*DENDRO_67) - DENDRO_48*(-DENDRO_167*DENDRO_47 + DENDRO_17*DENDRO_45) - DENDRO_67*DENDRO_96 - DENDRO_68*(DENDRO_132 - DENDRO_133 + DENDRO_134) + beta0[pp]*agrad_0_Gt1[pp] + beta1[pp]*agrad_1_Gt1[pp] + beta2[pp]*agrad_2_Gt1[pp];
		      Gt_rhs2[pp] = DENDRO_103*DENDRO_143 + DENDRO_108*DENDRO_141 - DENDRO_12*DENDRO_33 - DENDRO_120*DENDRO_96 + DENDRO_121*DENDRO_139 - DENDRO_13*DENDRO_169 - DENDRO_138*grad_1_beta2[pp] - DENDRO_14*DENDRO_28 - DENDRO_14*DENDRO_31 + DENDRO_145*DENDRO_79 + DENDRO_147*DENDRO_68 + DENDRO_149*DENDRO_57 - 4.0/3.0*DENDRO_15*DENDRO_25 - DENDRO_151*DENDRO_161 + DENDRO_151*DENDRO_162 - DENDRO_159*grad_0_beta2[pp] + DENDRO_16*DENDRO_163 + DENDRO_163*DENDRO_20 + DENDRO_164*DENDRO_23 - DENDRO_169*DENDRO_9 - DENDRO_27*grad2_1_1_beta2[pp] - DENDRO_30*grad2_0_0_beta2[pp] + DENDRO_37*DENDRO_6*grad2_0_1_beta2[pp] - DENDRO_44*DENDRO_83 - DENDRO_48*(-DENDRO_10*DENDRO_45 + DENDRO_47*DENDRO_83) - DENDRO_48*(-DENDRO_104*DENDRO_24 + DENDRO_105*DENDRO_78) - DENDRO_48*(DENDRO_120*DENDRO_123 + DENDRO_122*DENDRO_7) - DENDRO_78*DENDRO_84 + beta0[pp]*agrad_0_Gt2[pp] + beta1[pp]*agrad_1_Gt2[pp] + beta2[pp]*agrad_2_Gt2[pp];
		      // Dendro: reduced ops: 670
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(Gt_rhs2, &__unzipOutVar[cuda::VAR::U_GT2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(Gt_rhs1, &__unzipOutVar[cuda::VAR::U_GT1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(Gt_rhs0, &__unzipOutVar[cuda::VAR::U_GT0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
/** computes rhs B_rhs*/
__global__ void __compute_B_rhs(double** __unzipOutVar, const double**__unzipInVar, MemoryDerivs* __derivWorkspace, const cuda::_Block* __dendroBlkList, const BSSNComputeParams* __bssnPar, const cudaDeviceProp*__deviceProperties){
	const _Block dblock=__dendroBlkList[blockIdx.x];
	const unsigned int NUM_SM_UNITS=__deviceProperties->multiProcessorCount;
	const unsigned int SM_ID=blockIdx.x%NUM_SM_UNITS;
	const unsigned int offset=dblock.getOffset();
	const unsigned int *sz=dblock.getSz();
	const double* hx=dblock.getDx();
	const double* ptmin=dblock.getPtMin();
	const double* ptmax=dblock.getPtMax();
	// bssn compute parameters 
	const double lambda[4]={__bssnPar->BSSN_LAMBDA[0],__bssnPar->BSSN_LAMBDA[1],__bssnPar->BSSN_LAMBDA[2],__bssnPar->BSSN_LAMBDA[3]};
	const double lambda_f[2]={__bssnPar->BSSN_LAMBDA_F[0],__bssnPar->BSSN_LAMBDA_F[1]};
	const double kosigma=__bssnPar->KO_DISS_SIGMA;
	const double ETA_R0=__bssnPar->ETA_R0;
	const double R0=__bssnPar->ETA_R0;
	const double ETA_DAMPING=__bssnPar->ETA_DAMPING;
	const double ETA_DAMPING_EXP=__bssnPar->ETA_DAMPING_EXP;
	const double ETA_CONST=__bssnPar->ETA_CONST;
	const double eta_power[2]={__bssnPar->BSSN_ETA_POWER[0],__bssnPar->BSSN_ETA_POWER[1]};
	const double dx=hx[0];
	const double dy=hx[1];
	const double dz=hx[2];
	const unsigned int bflag=dblock.getBFlag();

	const unsigned int blkSz=sz[0]*sz[1]*sz[2];

	const unsigned int tile_sz[3]={3,3,3};
	const unsigned int TILE_SZ=tile_sz[0]*tile_sz[1]*tile_sz[2];
	
	const unsigned int Lb = 3;// load begin bound
	const unsigned int Le = sz[0]-3;// load end bound
	const unsigned int BLK_INTERATIONS = ((Le-Lb)<tile_sz[0])? 1: ((int)ceil((double)(Le-Lb-tile_sz[0])/(tile_sz[0]-2*0)))+1;

	unsigned int ijk_lm[3*2];
	//allocate memory for shared deriv variables. 


	 //input vars begin
	__shared__ double gt3[27];
	__shared__ double gt2[27];
	__shared__ double chi[27];
	__shared__ double gt1[27];
	__shared__ double alpha[27];
	__shared__ double At0[27];
	__shared__ double At3[27];
	__shared__ double At4[27];
	__shared__ double beta2[27];
	__shared__ double B2[27];
	__shared__ double At2[27];
	__shared__ double beta0[27];
	__shared__ double At1[27];
	__shared__ double gt4[27];
	__shared__ double B1[27];
	__shared__ double beta1[27];
	__shared__ double gt5[27];
	__shared__ double At5[27];
	__shared__ double gt0[27];
	__shared__ double B0[27];
	 //input vars end
	 // staged vars begin
	 // staged vars end
	 // deriv vars begin
	__shared__ double agrad_1_Gt1[27];
	__shared__ double grad2_0_2_beta1[27];
	__shared__ double grad_0_alpha[27];
	__shared__ double agrad_2_Gt0[27];
	__shared__ double agrad_0_Gt1[27];
	__shared__ double agrad_1_Gt2[27];
	__shared__ double grad_0_gt4[27];
	__shared__ double grad_1_beta2[27];
	__shared__ double grad_1_gt2[27];
	__shared__ double grad_0_gt2[27];
	__shared__ double grad_2_gt0[27];
	__shared__ double grad_1_gt3[27];
	__shared__ double grad_0_gt5[27];
	__shared__ double grad_2_gt2[27];
	__shared__ double grad2_0_1_beta1[27];
	__shared__ double agrad_1_Gt0[27];
	__shared__ double grad2_1_1_beta2[27];
	__shared__ double grad_0_beta2[27];
	__shared__ double agrad_0_Gt0[27];
	__shared__ double grad_2_gt4[27];
	__shared__ double grad_2_beta0[27];
	__shared__ double agrad_1_B0[27];
	__shared__ double grad2_0_0_beta0[27];
	__shared__ double grad_1_alpha[27];
	__shared__ double grad_1_gt0[27];
	__shared__ double grad_2_gt3[27];
	__shared__ double grad2_2_2_beta1[27];
	__shared__ double grad2_0_0_beta1[27];
	__shared__ double grad_0_K[27];
	__shared__ double grad_1_beta1[27];
	__shared__ double grad_0_gt1[27];
	__shared__ double grad2_0_0_beta2[27];
	__shared__ double grad_0_gt0[27];
	__shared__ double grad2_1_2_beta2[27];
	__shared__ double grad_1_gt4[27];
	__shared__ double grad_0_beta0[27];
	__shared__ double grad2_1_2_beta0[27];
	__shared__ double grad_1_K[27];
	__shared__ double grad_2_beta2[27];
	__shared__ double grad_1_beta0[27];
	__shared__ double grad_2_alpha[27];
	__shared__ double agrad_2_B2[27];
	__shared__ double grad2_2_2_beta0[27];
	__shared__ double grad_1_gt5[27];
	__shared__ double agrad_2_B1[27];
	__shared__ double grad2_1_1_beta1[27];
	__shared__ double grad_2_gt1[27];
	__shared__ double agrad_1_B1[27];
	__shared__ double grad2_0_1_beta0[27];
	__shared__ double grad_1_gt1[27];
	__shared__ double grad_2_gt5[27];
	__shared__ double grad2_1_1_beta0[27];
	__shared__ double agrad_0_Gt2[27];
	__shared__ double grad2_0_2_beta2[27];
	__shared__ double agrad_0_B2[27];
	__shared__ double grad2_0_1_beta2[27];
	__shared__ double grad_2_chi[27];
	__shared__ double grad_0_chi[27];
	__shared__ double grad_0_beta1[27];
	__shared__ double grad_1_chi[27];
	__shared__ double grad2_1_2_beta1[27];
	__shared__ double agrad_0_B1[27];
	__shared__ double grad2_0_2_beta0[27];
	__shared__ double agrad_2_Gt2[27];
	__shared__ double agrad_2_B0[27];
	__shared__ double grad_2_beta1[27];
	__shared__ double grad_0_gt3[27];
	__shared__ double agrad_0_B0[27];
	__shared__ double agrad_1_B2[27];
	__shared__ double grad_2_K[27];
	__shared__ double agrad_2_Gt1[27];
	__shared__ double grad2_2_2_beta2[27];
	 // deriv vars end
	 // output vars begin
	__shared__ double B_rhs2[27];
	__shared__ double B_rhs0[27];
	__shared__ double B_rhs1[27];
	 // output vars end
	for(unsigned int iter=0;iter<BLK_INTERATIONS;iter++){

		 ijk_lm[2*0+0]=max(3,(int)(3 + tile_sz[0]*iter -2*iter*0));
		 ijk_lm[2*0+1]=min(ijk_lm[2*0+0]+tile_sz[0],sz[0]-3);
		 ijk_lm[2*1+0]=max(3,(int)(3 + tile_sz[1]*iter -2*iter*0));
		 ijk_lm[2*1+1]=min(ijk_lm[2*1+0]+tile_sz[1],sz[1]-3);
		 ijk_lm[2*2+0]=max(3,(int)(3 + tile_sz[2]*iter -2*iter*0));
		 ijk_lm[2*2+1]=min(ijk_lm[2*2+0]+tile_sz[2],sz[2]-3);
		 //printf(" iter : %d threadid (%d,%d,%d) tile begin: (%d,%d,%d) tile end: (%d,%d,%d) \n",iter, threadIdx.x,threadIdx.y,threadIdx.z,ijk_lm[0],ijk_lm[2],ijk_lm[4],ijk_lm[1],ijk_lm[3],ijk_lm[5]);


		//load data from global to shared memory
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT3][offset],(double *) gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT2][offset],(double *) gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_CHI][offset],(double *) chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT1][offset],(double *) gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_ALPHA][offset],(double *) alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT0][offset],(double *) At0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT3][offset],(double *) At3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT4][offset],(double *) At4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA2][offset],(double *) beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_B2][offset],(double *) B2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT2][offset],(double *) At2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA0][offset],(double *) beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT1][offset],(double *) At1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT4][offset],(double *) gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_B1][offset],(double *) B1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_BETA1][offset],(double *) beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT5][offset],(double *) gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMAT5][offset],(double *) At5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_SYMGT0][offset],(double *) gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&__unzipInVar[cuda::VAR::U_B0][offset],(double *) B0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_Gt1[offset]),(double *) agrad_1_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_beta1[offset]),(double *) grad2_0_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_alpha[offset]),(double *) grad_0_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_Gt0[offset]),(double *) agrad_2_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_Gt1[offset]),(double *) agrad_0_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_Gt2[offset]),(double *) agrad_1_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt4[offset]),(double *) grad_0_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta2[offset]),(double *) grad_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt2[offset]),(double *) grad_1_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt2[offset]),(double *) grad_0_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt0[offset]),(double *) grad_2_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt3[offset]),(double *) grad_1_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt5[offset]),(double *) grad_0_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt2[offset]),(double *) grad_2_gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_beta1[offset]),(double *) grad2_0_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_Gt0[offset]),(double *) agrad_1_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_beta2[offset]),(double *) grad2_1_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta2[offset]),(double *) grad_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_Gt0[offset]),(double *) agrad_0_Gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt4[offset]),(double *) grad_2_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta0[offset]),(double *) grad_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_B0[offset]),(double *) agrad_1_B0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_beta0[offset]),(double *) grad2_0_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_alpha[offset]),(double *) grad_1_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt0[offset]),(double *) grad_1_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt3[offset]),(double *) grad_2_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_beta1[offset]),(double *) grad2_2_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_beta1[offset]),(double *) grad2_0_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_K[offset]),(double *) grad_0_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta1[offset]),(double *) grad_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt1[offset]),(double *) grad_0_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_0_beta2[offset]),(double *) grad2_0_0_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt0[offset]),(double *) grad_0_gt0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_beta2[offset]),(double *) grad2_1_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt4[offset]),(double *) grad_1_gt4,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta0[offset]),(double *) grad_0_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_beta0[offset]),(double *) grad2_1_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_K[offset]),(double *) grad_1_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta2[offset]),(double *) grad_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_beta0[offset]),(double *) grad_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_alpha[offset]),(double *) grad_2_alpha,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_B2[offset]),(double *) agrad_2_B2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_beta0[offset]),(double *) grad2_2_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt5[offset]),(double *) grad_1_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_B1[offset]),(double *) agrad_2_B1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_beta1[offset]),(double *) grad2_1_1_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt1[offset]),(double *) grad_2_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_B1[offset]),(double *) agrad_1_B1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_beta0[offset]),(double *) grad2_0_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_gt1[offset]),(double *) grad_1_gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_gt5[offset]),(double *) grad_2_gt5,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_1_beta0[offset]),(double *) grad2_1_1_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_Gt2[offset]),(double *) agrad_0_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_beta2[offset]),(double *) grad2_0_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_B2[offset]),(double *) agrad_0_B2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_1_beta2[offset]),(double *) grad2_0_1_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_chi[offset]),(double *) grad_2_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_chi[offset]),(double *) grad_0_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_beta1[offset]),(double *) grad_0_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_1_chi[offset]),(double *) grad_1_chi,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_1_2_beta1[offset]),(double *) grad2_1_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_B1[offset]),(double *) agrad_0_B1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_0_2_beta0[offset]),(double *) grad2_0_2_beta0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_Gt2[offset]),(double *) agrad_2_Gt2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_B0[offset]),(double *) agrad_2_B0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_beta1[offset]),(double *) grad_2_beta1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_0_gt3[offset]),(double *) grad_0_gt3,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_0_B0[offset]),(double *) agrad_0_B0,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_1_B2[offset]),(double *) agrad_1_B2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad_2_K[offset]),(double *) grad_2_K,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__agrad_2_Gt1[offset]),(double *) agrad_2_Gt1,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__loadGlobalToShared<double>(&(__derivWorkspace->__grad2_2_2_beta2[offset]),(double *) grad2_2_2_beta2,(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();

		const unsigned int i_b=ijk_lm[2*0+0];
		const unsigned int i_e=ijk_lm[2*0+1];
		const unsigned int j_b=ijk_lm[2*1+0];
		const unsigned int j_e=ijk_lm[2*1+1];
		const unsigned int k_b=ijk_lm[2*2+0];
		const unsigned int k_e=ijk_lm[2*2+1];
		unsigned int l_x=i_e-i_b;
		unsigned int l_y=j_e-j_b;
		unsigned int l_z=k_e-k_b;
		if(threadIdx.x>=l_x || threadIdx.y >= l_y || threadIdx.z>=l_z) return;
		if(l_x<blockDim.x) l_x=blockDim.x;
		if(l_y<blockDim.y) l_y=blockDim.y;
		if(l_z<blockDim.z) l_z=blockDim.z;
		const unsigned int ix_b= (i_b + (threadIdx.x * l_x)/blockDim.x)-ijk_lm[0];
		const unsigned int ix_e= (i_b + ((threadIdx.x +1)* l_x)/blockDim.x)-ijk_lm[0];

		const unsigned int jy_b= (j_b + (threadIdx.y * l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int jy_e= (j_b + ((threadIdx.y+1)* l_y)/blockDim.y)-ijk_lm[2];
		const unsigned int kz_b= (k_b + (threadIdx.x * l_z)/blockDim.z)-ijk_lm[4];
		const unsigned int kz_e= (k_b + ((threadIdx.x+1)* l_z)/blockDim.z)-ijk_lm[4];


		 double x,y,z,r_coord,eta;
		 for (unsigned int k=kz_b;k<kz_e;k++){
		  z = ptmin[2] + (k+ijk_lm[4])*dz;
		    for (unsigned int j=jy_b;j<jy_e;j++){
		     y = ptmin[1] + (j+ijk_lm[2])*dy;
		      for (unsigned int i=ix_b;i<ix_e;i++){
		       x = ptmin[0] + (i+ijk_lm[0])*dx;
		

		       r_coord = sqrt(x*x + y*y + z*z);
		       eta=ETA_CONST;
		       if (r_coord >= ETA_R0) {
		          eta *= pow( (ETA_R0/r_coord), ETA_DAMPING_EXP);
		       }

		      const unsigned int pp=k*tile_sz[0]*tile_sz[1]+j*tile_sz[1]+i;
		      // Dendro: {{{ 
		      // Dendro: original ops: 17226
		      // Dendro: printing temp variables
		   double 		DENDRO_0 = beta0[pp]*agrad_0_Gt0[pp] + beta1[pp]*agrad_1_Gt0[pp] + beta2[pp]*agrad_2_Gt0[pp];
		   double 		DENDRO_1 = gt0[pp]*gt3[pp];
		   double 		DENDRO_2 = pow(gt1[pp], 2);
		   double 		DENDRO_3 = DENDRO_1 - DENDRO_2;
		   double 		DENDRO_4 = pow(gt4[pp], 2);
		   double 		DENDRO_5 = pow(gt2[pp], 2);
		   double 		DENDRO_6 = gt1[pp]*gt2[pp];
		   double 		DENDRO_7 = -DENDRO_1*gt5[pp] + DENDRO_2*gt5[pp] + DENDRO_4*gt0[pp] + DENDRO_5*gt3[pp] - 2*DENDRO_6*gt4[pp];
		   double 		DENDRO_8 = 1.0/DENDRO_7;
		   double 		DENDRO_9 = DENDRO_3*DENDRO_8;
		   double 		DENDRO_10 = -DENDRO_5 + gt0[pp]*gt5[pp];
		   double 		DENDRO_11 = DENDRO_10*DENDRO_8;
		   double 		DENDRO_12 = pow(DENDRO_7, -2);
		   double 		DENDRO_13 = -DENDRO_6 + gt0[pp]*gt4[pp];
		   double 		DENDRO_14 = grad_1_gt5[pp];
		   double 		DENDRO_15 = grad_2_gt3[pp];
		   double 		DENDRO_16 = gt1[pp]*gt5[pp] - gt2[pp]*gt4[pp];
		   double 		DENDRO_17 = grad_1_gt2[pp];
		   double 		DENDRO_18 = grad_2_gt1[pp];
		   double 		DENDRO_19 = grad_0_gt4[pp];
		   double 		DENDRO_20 = DENDRO_17 + DENDRO_18 - DENDRO_19;
		   double 		DENDRO_21 = -DENDRO_10*DENDRO_15 + DENDRO_13*DENDRO_14 + DENDRO_16*DENDRO_20;
		   double 		DENDRO_22 = grad_1_gt0[pp];
		   double 		DENDRO_23 = grad_0_gt3[pp];
		   double 		DENDRO_24 = DENDRO_17 - DENDRO_18 + DENDRO_19;
		   double 		DENDRO_25 = -DENDRO_10*DENDRO_23 + DENDRO_13*DENDRO_24 + DENDRO_16*DENDRO_22;
		   double 		DENDRO_26 = grad_0_gt5[pp];
		   double 		DENDRO_27 = grad_2_gt0[pp];
		   double 		DENDRO_28 = -DENDRO_17 + DENDRO_18 + DENDRO_19;
		   double 		DENDRO_29 = -DENDRO_10*DENDRO_28 + DENDRO_13*DENDRO_26 + DENDRO_16*DENDRO_27;
		   double 		DENDRO_30 = gt1[pp]*gt4[pp] - gt2[pp]*gt3[pp];
		   double 		DENDRO_31 = 1.0*DENDRO_30;
		   double 		DENDRO_32 = 0.5*grad_2_gt5[pp];
		   double 		DENDRO_33 = 0.5*DENDRO_14 - 1.0*grad_2_gt4[pp];
		   double 		DENDRO_34 = 0.5*DENDRO_26 - 1.0*grad_2_gt2[pp];
		   double 		DENDRO_35 = DENDRO_10*DENDRO_33 + DENDRO_13*DENDRO_32 - DENDRO_16*DENDRO_34;
		   double 		DENDRO_36 = 0.5*grad_1_gt3[pp];
		   double 		DENDRO_37 = -0.5*DENDRO_15 + 1.0*grad_1_gt4[pp];
		   double 		DENDRO_38 = 0.5*DENDRO_23 - 1.0*grad_1_gt1[pp];
		   double 		DENDRO_39 = -DENDRO_10*DENDRO_36 + DENDRO_13*DENDRO_37 - DENDRO_16*DENDRO_38;
		   double 		DENDRO_40 = -DENDRO_4 + gt3[pp]*gt5[pp];
		   double 		DENDRO_41 = 0.5*grad_0_gt0[pp];
		   double 		DENDRO_42 = -0.5*DENDRO_27 + 1.0*grad_0_gt2[pp];
		   double 		DENDRO_43 = -0.5*DENDRO_22 + 1.0*grad_0_gt1[pp];
		   double 		DENDRO_44 = -DENDRO_10*DENDRO_43 + DENDRO_13*DENDRO_42 + DENDRO_16*DENDRO_41;
		   double 		DENDRO_45 = DENDRO_12*(-DENDRO_10*DENDRO_39 + DENDRO_13*DENDRO_21 + DENDRO_16*DENDRO_25 - DENDRO_29*DENDRO_31 - DENDRO_3*DENDRO_35 - DENDRO_40*DENDRO_44);
		   double 		DENDRO_46 = DENDRO_13*DENDRO_15 - DENDRO_14*DENDRO_3 - DENDRO_20*DENDRO_30;
		   double 		DENDRO_47 = DENDRO_13*DENDRO_23 - DENDRO_22*DENDRO_30 - DENDRO_24*DENDRO_3;
		   double 		DENDRO_48 = DENDRO_13*DENDRO_28 - DENDRO_26*DENDRO_3 - DENDRO_27*DENDRO_30;
		   double 		DENDRO_49 = -DENDRO_13*DENDRO_33 - DENDRO_3*DENDRO_32 + DENDRO_30*DENDRO_34;
		   double 		DENDRO_50 = DENDRO_13*DENDRO_36 - DENDRO_3*DENDRO_37 + DENDRO_30*DENDRO_38;
		   double 		DENDRO_51 = DENDRO_13*DENDRO_43 - DENDRO_3*DENDRO_42 - DENDRO_30*DENDRO_41;
		   double 		DENDRO_52 = DENDRO_12*(-DENDRO_10*DENDRO_50 + DENDRO_13*DENDRO_46 + DENDRO_16*DENDRO_47 - DENDRO_3*DENDRO_49 - DENDRO_31*DENDRO_48 - DENDRO_40*DENDRO_51);
		   double 		DENDRO_53 = grad_0_beta0[pp];
		   double 		DENDRO_54 = -DENDRO_14*DENDRO_30 + DENDRO_15*DENDRO_16 - DENDRO_20*DENDRO_40;
		   double 		DENDRO_55 = DENDRO_16*DENDRO_23 - DENDRO_22*DENDRO_40 - DENDRO_24*DENDRO_30;
		   double 		DENDRO_56 = DENDRO_16*DENDRO_28 - DENDRO_26*DENDRO_30 - DENDRO_27*DENDRO_40;
		   double 		DENDRO_57 = -DENDRO_16*DENDRO_33 - DENDRO_30*DENDRO_32 + DENDRO_34*DENDRO_40;
		   double 		DENDRO_58 = DENDRO_16*DENDRO_36 - DENDRO_30*DENDRO_37 + DENDRO_38*DENDRO_40;
		   double 		DENDRO_59 = DENDRO_16*DENDRO_43 - DENDRO_30*DENDRO_42 - DENDRO_40*DENDRO_41;
		   double 		DENDRO_60 = DENDRO_12*(-DENDRO_10*DENDRO_58 + DENDRO_13*DENDRO_54 + DENDRO_16*DENDRO_55 - DENDRO_3*DENDRO_57 - DENDRO_31*DENDRO_56 - DENDRO_40*DENDRO_59);
		   double 		DENDRO_61 = pow(DENDRO_16, 2);
		   double 		DENDRO_62 = pow(DENDRO_30, 2);
		   double 		DENDRO_63 = At4[pp]*DENDRO_30;
		   double 		DENDRO_64 = 2*DENDRO_16;
		   double 		DENDRO_65 = At1[pp]*DENDRO_40;
		   double 		DENDRO_66 = At2[pp]*DENDRO_40;
		   double 		DENDRO_67 = 2*DENDRO_30;
		   double 		DENDRO_68 = At0[pp]*pow(DENDRO_40, 2) + At3[pp]*DENDRO_61 + At5[pp]*DENDRO_62 - DENDRO_63*DENDRO_64 - DENDRO_64*DENDRO_65 + DENDRO_66*DENDRO_67;
		   double 		DENDRO_69 = 2*DENDRO_12;
		   double 		DENDRO_70 = DENDRO_69*grad_0_alpha[pp];
		   double 		DENDRO_71 = DENDRO_13*DENDRO_16;
		   double 		DENDRO_72 = DENDRO_16*DENDRO_30;
		   double 		DENDRO_73 = At5[pp]*DENDRO_30;
		   double 		DENDRO_74 = At0[pp]*DENDRO_40;
		   double 		DENDRO_75 = At3[pp]*DENDRO_10;
		   double 		DENDRO_76 = At1[pp]*DENDRO_61 - At2[pp]*DENDRO_72 + At4[pp]*DENDRO_71 + DENDRO_10*DENDRO_63 + DENDRO_10*DENDRO_65 - DENDRO_13*DENDRO_66 - DENDRO_13*DENDRO_73 - DENDRO_16*DENDRO_74 - DENDRO_16*DENDRO_75;
		   double 		DENDRO_77 = DENDRO_69*grad_1_alpha[pp];
		   double 		DENDRO_78 = At4[pp]*DENDRO_3;
		   double 		DENDRO_79 = -At1[pp]*DENDRO_72 + At2[pp]*DENDRO_62 + At3[pp]*DENDRO_71 - DENDRO_13*DENDRO_63 - DENDRO_13*DENDRO_65 - DENDRO_16*DENDRO_78 + DENDRO_3*DENDRO_66 + DENDRO_3*DENDRO_73 + DENDRO_30*DENDRO_74;
		   double 		DENDRO_80 = DENDRO_69*grad_2_alpha[pp];
		   double 		DENDRO_81 = 2*DENDRO_13;
		   double 		DENDRO_82 = grad2_0_2_beta0[pp];
		   double 		DENDRO_83 = DENDRO_30*DENDRO_8;
		   double 		DENDRO_84 = (7.0/3.0)*DENDRO_83;
		   double 		DENDRO_85 = grad2_0_0_beta0[pp];
		   double 		DENDRO_86 = DENDRO_40*DENDRO_8;
		   double 		DENDRO_87 = 4*grad_0_K[pp];
		   double 		DENDRO_88 = grad_0_chi[pp];
		   double 		DENDRO_89 = 9*DENDRO_8/chi[pp];
		   double 		DENDRO_90 = DENDRO_88*DENDRO_89;
		   double 		DENDRO_91 = (1.0/3.0)*DENDRO_8;
		   double 		DENDRO_92 = DENDRO_91*alpha[pp];
		   double 		DENDRO_93 = 4*grad_2_K[pp];
		   double 		DENDRO_94 = grad_2_chi[pp];
		   double 		DENDRO_95 = DENDRO_89*DENDRO_94;
		   double 		DENDRO_96 = 4*grad_1_K[pp];
		   double 		DENDRO_97 = grad_1_chi[pp];
		   double 		DENDRO_98 = DENDRO_89*DENDRO_97;
		   double 		DENDRO_99 = grad2_0_1_beta1[pp];
		   double 		DENDRO_100 = (1.0/3.0)*DENDRO_86;
		   double 		DENDRO_101 = grad2_0_2_beta2[pp];
		   double 		DENDRO_102 = grad2_1_2_beta1[pp];
		   double 		DENDRO_103 = (1.0/3.0)*DENDRO_83;
		   double 		DENDRO_104 = grad2_2_2_beta2[pp];
		   double 		DENDRO_105 = grad2_1_1_beta1[pp];
		   double 		DENDRO_106 = DENDRO_16*DENDRO_91;
		   double 		DENDRO_107 = grad2_1_2_beta2[pp];
		   double 		DENDRO_108 = grad_1_beta1[pp];
		   double 		DENDRO_109 = grad_2_beta2[pp];
		   double 		DENDRO_110 = (2.0/3.0)*DENDRO_108 + (2.0/3.0)*DENDRO_109 + (2.0/3.0)*DENDRO_53;
		   double 		DENDRO_111 = grad2_0_1_beta0[pp];
		   double 		DENDRO_112 = (7.0/3.0)*DENDRO_8;
		   double 		DENDRO_113 = DENDRO_112*DENDRO_16;
		   double 		DENDRO_114 = R0*sqrt(DENDRO_8*(-DENDRO_10*pow(DENDRO_97, 2) - DENDRO_3*pow(DENDRO_94, 2) - DENDRO_40*pow(DENDRO_88, 2) + DENDRO_64*DENDRO_88*DENDRO_97 - DENDRO_67*DENDRO_88*DENDRO_94 + DENDRO_81*DENDRO_94*DENDRO_97))*pow(-pow(chi[pp], eta_power[0]) + 1, -eta_power[1]);
		   double 		DENDRO_115 = pow(DENDRO_13, 2);
		   double 		DENDRO_116 = At1[pp]*DENDRO_10;
		   double 		DENDRO_117 = At0[pp]*DENDRO_61 + 2*At2[pp]*DENDRO_71 + At3[pp]*pow(DENDRO_10, 2) - At4[pp]*DENDRO_10*DENDRO_81 + At5[pp]*DENDRO_115 - DENDRO_116*DENDRO_64;
		   double 		DENDRO_118 = alpha[pp]/pow(DENDRO_7, 3);
		   double 		DENDRO_119 = 2*DENDRO_118;
		   double 		DENDRO_120 = DENDRO_117*DENDRO_119;
		   double 		DENDRO_121 = DENDRO_13*DENDRO_30;
		   double 		DENDRO_122 = At2[pp]*DENDRO_3;
		   double 		DENDRO_123 = At0[pp]*DENDRO_62 - 2*At1[pp]*DENDRO_121 + At3[pp]*DENDRO_115 + At5[pp]*pow(DENDRO_3, 2) + DENDRO_122*DENDRO_67 - DENDRO_78*DENDRO_81;
		   double 		DENDRO_124 = DENDRO_119*DENDRO_123;
		   double 		DENDRO_125 = DENDRO_119*DENDRO_68;
		   double 		DENDRO_126 = 2.0*DENDRO_118;
		   double 		DENDRO_127 = DENDRO_126*DENDRO_79;
		   double 		DENDRO_128 = DENDRO_126*DENDRO_76;
		   double 		DENDRO_129 = -At0[pp]*DENDRO_72 + At1[pp]*DENDRO_71 - At2[pp]*DENDRO_121 + At4[pp]*DENDRO_115 - At5[pp]*DENDRO_13*DENDRO_3 + DENDRO_10*DENDRO_78 + DENDRO_116*DENDRO_30 - DENDRO_122*DENDRO_16 - DENDRO_13*DENDRO_75;
		   double 		DENDRO_130 = DENDRO_126*DENDRO_129;
		   double 		DENDRO_131 = beta0[pp]*agrad_0_Gt1[pp] + beta1[pp]*agrad_1_Gt1[pp] + beta2[pp]*agrad_2_Gt1[pp];
		   double 		DENDRO_132 = (1.0/3.0)*DENDRO_11;
		   double 		DENDRO_133 = DENDRO_13*DENDRO_91;
		   double 		DENDRO_134 = DENDRO_112*DENDRO_13;
		   double 		DENDRO_135 = beta0[pp]*agrad_0_Gt2[pp] + beta1[pp]*agrad_1_Gt2[pp] + beta2[pp]*agrad_2_Gt2[pp];
		   double 		DENDRO_136 = (1.0/3.0)*DENDRO_9;
		      // Dendro: printing variables

		      B_rhs0[pp] = -B0[pp]*DENDRO_114 - DENDRO_0*lambda[3] + DENDRO_0 - DENDRO_100*DENDRO_101 - DENDRO_100*DENDRO_99 - DENDRO_102*DENDRO_103 - DENDRO_103*DENDRO_104 + DENDRO_105*DENDRO_106 + DENDRO_106*DENDRO_107 - DENDRO_11*grad2_1_1_beta0[pp] + DENDRO_110*DENDRO_60 + DENDRO_111*DENDRO_113 + DENDRO_120*DENDRO_58 + DENDRO_124*DENDRO_57 + DENDRO_125*DENDRO_59 + DENDRO_127*DENDRO_56 + DENDRO_128*DENDRO_55 + DENDRO_130*DENDRO_54 - DENDRO_45*grad_1_beta0[pp] - DENDRO_52*grad_2_beta0[pp] - DENDRO_53*DENDRO_60 - DENDRO_68*DENDRO_70 - DENDRO_76*DENDRO_77 - DENDRO_79*DENDRO_80 + DENDRO_8*DENDRO_81*grad2_1_2_beta0[pp] - DENDRO_82*DENDRO_84 - 4.0/3.0*DENDRO_85*DENDRO_86 - DENDRO_9*grad2_2_2_beta0[pp] - DENDRO_92*(DENDRO_16*DENDRO_96 + DENDRO_76*DENDRO_98) - DENDRO_92*(-DENDRO_30*DENDRO_93 + DENDRO_79*DENDRO_95) - DENDRO_92*(-DENDRO_40*DENDRO_87 + DENDRO_68*DENDRO_90) + lambda[2]*(beta0[pp]*agrad_0_B0[pp] + beta1[pp]*agrad_1_B0[pp] + beta2[pp]*agrad_2_B0[pp]);
		      B_rhs1[pp] = -B1[pp]*DENDRO_114 + DENDRO_101*DENDRO_106 + DENDRO_102*DENDRO_134 + DENDRO_104*DENDRO_133 - 4.0/3.0*DENDRO_105*DENDRO_11 + DENDRO_106*DENDRO_85 - DENDRO_107*DENDRO_132 - DENDRO_108*DENDRO_45 + DENDRO_110*DENDRO_45 - DENDRO_111*DENDRO_132 + DENDRO_113*DENDRO_99 - DENDRO_117*DENDRO_77 + DENDRO_120*DENDRO_39 + DENDRO_124*DENDRO_35 + DENDRO_125*DENDRO_44 + DENDRO_127*DENDRO_29 + DENDRO_128*DENDRO_25 - DENDRO_129*DENDRO_80 + DENDRO_130*DENDRO_21 - DENDRO_131*lambda[3] + DENDRO_131 + DENDRO_133*DENDRO_82 - DENDRO_52*grad_2_beta1[pp] - DENDRO_60*grad_0_beta1[pp] - DENDRO_67*DENDRO_8*grad2_0_2_beta1[pp] - DENDRO_70*DENDRO_76 - DENDRO_86*grad2_0_0_beta1[pp] - DENDRO_9*grad2_2_2_beta1[pp] - DENDRO_92*(-DENDRO_10*DENDRO_96 + DENDRO_117*DENDRO_98) - DENDRO_92*(DENDRO_129*DENDRO_95 + DENDRO_13*DENDRO_93) - DENDRO_92*(DENDRO_16*DENDRO_87 + DENDRO_76*DENDRO_90) + lambda[2]*(beta0[pp]*agrad_0_B1[pp] + beta1[pp]*agrad_1_B1[pp] + beta2[pp]*agrad_2_B1[pp]);
		      B_rhs2[pp] = -B2[pp]*DENDRO_114 - DENDRO_101*DENDRO_84 - DENDRO_102*DENDRO_136 - DENDRO_103*DENDRO_85 - DENDRO_103*DENDRO_99 - 4.0/3.0*DENDRO_104*DENDRO_9 + DENDRO_105*DENDRO_133 + DENDRO_107*DENDRO_134 - DENDRO_109*DENDRO_52 - DENDRO_11*grad2_1_1_beta2[pp] + DENDRO_110*DENDRO_52 + DENDRO_111*DENDRO_133 + DENDRO_120*DENDRO_50 - DENDRO_123*DENDRO_80 + DENDRO_124*DENDRO_49 + DENDRO_125*DENDRO_51 + DENDRO_127*DENDRO_48 + DENDRO_128*DENDRO_47 - DENDRO_129*DENDRO_77 + DENDRO_130*DENDRO_46 - DENDRO_135*lambda[3] + DENDRO_135 - DENDRO_136*DENDRO_82 - DENDRO_45*grad_1_beta2[pp] - DENDRO_60*grad_0_beta2[pp] + DENDRO_64*DENDRO_8*grad2_0_1_beta2[pp] - DENDRO_70*DENDRO_79 - DENDRO_86*grad2_0_0_beta2[pp] - DENDRO_92*(DENDRO_123*DENDRO_95 - DENDRO_3*DENDRO_93) - DENDRO_92*(DENDRO_129*DENDRO_98 + DENDRO_13*DENDRO_96) - DENDRO_92*(-DENDRO_30*DENDRO_87 + DENDRO_79*DENDRO_90) + lambda[2]*(beta0[pp]*agrad_0_B2[pp] + beta1[pp]*agrad_1_B2[pp] + beta2[pp]*agrad_2_B2[pp]);
		      // Dendro: reduced ops: 691
		      // Dendro: }}} 
		    }
		  }
		}
	__syncthreads();

	// sotre computed variables

		cuda::__storeSharedToGlobal<double>(B_rhs2, &__unzipOutVar[cuda::VAR::U_B2][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(B_rhs0, &__unzipOutVar[cuda::VAR::U_B0][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
		cuda::__storeSharedToGlobal<double>(B_rhs1, &__unzipOutVar[cuda::VAR::U_B1][offset],(const unsigned int *) ijk_lm,(const unsigned int *) sz,(const unsigned int *) tile_sz);
	__syncthreads();
	}

}
} // end of namespace cuda 



