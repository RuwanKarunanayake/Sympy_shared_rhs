As we go through a period of rapid architectural changes, an important fact to keep in mind is that applications far outlive any computer system. The latest %next generation 
supercomputing architectures (Aurora, Gyoukou, Summit, Sunway TaihuLight, TianHe-2~\cite{aurora,summit,gyoukou,top500}) are different from the previous generation of leadership architectures and becoming increasingly complex and heterogeneous. These machines are characterized by extremely high levels of parallelism and deep and non-uniform memory hierarchies. This makes it difficult to develop applications that are able to achieve good performance on one of these machines, leave alone several of these. While it might be reasonable to optimize basic libraries like BLAS for each such machine, manually optimizing application codes for each machine is time consuming and expensive. This is particularly true for complex applications like computational relativity involving thousands of coupled equations. Manually re-writing code for each new machine also increases the possibility of introducing new bugs and makes the task of code reproducibility difficult. Automatic code generation is attractive in increasing the code portability, i.e., in ensuring the code is able to run on different hardware, but the challenge in the HPC context has been of achieving good performance, especially for complex applications. Automatic code-generation for complex applications, targeting high levels of parallelism and deep memory hierarchies are essential to developing high-performance and sustainable codes. %Developing such a framework is the key contribution of this work.

This work focuses on automatically generating high performance codes targeting heterogeneous clusters with GPUs for one such challenging application, computational relativity. We focus on computational relativity applications as these are complex and in most cases manually writing efficient codes for such applications is very time consuming and expensive. Consequently these applications can benefit a lot from more efficient implementations. These are also extremely complex and large-scale requiring to be run on our largest machines. While there is significant variety in the largest machines, a significant portion of the top500 \cite{top500} machines rely on GPUs to achieve their performance. Therefore we limit our initial focus to auto-generation of efficient GPU code, specifically CUDA code. We will develop additional code generators targeting other architectures in future work. Finally, our approaches and framework are general enough to be useful to a wider range of applications with minimal changes as the core ideas are applicable beyond computational relativity.

Code portability and high-performance typically are antagonistic to each other, with hand-written code by expert programmer usually achieving high-performance with low portability. At the other end, generated code usually has high portability but usually with lower performance, especially on high-throughput hardware such as GPUs. A good compromise for many cases is to use optimized libraries for core functionality like BLAS, LAPACK \cite{blas,clawpack} such that the benefits of hand optimizing code are available to a wide range of applications. While this is a good strategy for many applications, complex applications that deviate significantly from functionality provided by standard libraries are unable to benefit from these. An alternative, especially for numerical codes is to use symbolic interfaces like Mathematica \cite{mathematica} or SymPy \cite{sympy} to write the mathematical expressions, and generate the corresponding code for the preferred programming language. For example, SymPy supports generating code for \texttt{C/C++}, \texttt{Fortran77/90}, \texttt{Julia}, \texttt{Rust} and \texttt{Octave/Matlab}. While this provides great portability, the performance is lacking and generators for GPUs using CUDA or OpenCL are lacking. The key contribution of this work is to add CUDA code generator for SymPy and developing routines and strategy to ensure that the generated CUDA code is able to achieve good performance (as percentage of peak) on modern GPUs. This is achieved by efficient use of caches, asynchronous data transfers and architecture specific optimizations. In order to maximize portability and performance, we use a two-fold approach. First, we identify several key kernels that are commonly used and create a hand-optimized library for these. All additional functions are auto-generated. Note that it is possible to auto-generate the entire code, but such an approach provides a good balance between portability and performance. In our target application of binary black hole mergers, we were able to achieve a speedup of $X$ over CPU code and a peak performance of $30\%$ on Y GPUs. \mf{add provide the correct highlight result here.} 

% \begin{enumerate}
% %\item Computational relativity is a challenging application. Lots of unknowns and lots of equations. 
% %\item Architectures are getting more complex and rapidly evolving. This makes it harder to write and maintain efficient codes, especially in complex application domains like computational relativity
% %\item Since most modern supercomputers rely heavily on GPUs for most of their computational abilities, we focus on automatically generating CUDA code.
% \item Our approach is a combination of highly tuned CUDA kernels for common functions such as stencil operations combined with an SymPy based auto-generation routine for handling all other code unique to the application. 
% \end{enumerate}

\noindent{\bf Contributions:}  The key contributions of this work include:

\begin{enumerate}
\item \texttt{CUDA} code generation functionality added to SymPY
\item Efficient utilization of GPU resources by cache optimizations, asynchronous data transfers and architecture specific optimizations to achieve high performance on modern GPUs.
\item Demonstrated performance of xxxx. \mf{add this.}
\item Code will be made available on \texttt{github}.
\end{enumerate}

The rest of the paper is organized as follows. In \S\ref{sec:bg}, we provide a brief introduction to our target application, motivating the need for automatic code generation. In \S\ref{sec:methods}, we present our methods both for code generating and strategies for achieving good performance. We describe our experimental setup in \S\ref{sec:exper} and present results in \S\ref{sec:results}. Finally, we conclude in \S\ref{sec:conclude} with directions for future research. 



